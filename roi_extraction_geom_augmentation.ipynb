{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "import pydicom as dicom\n",
    "from skimage.util import view_as_windows\n",
    "from skimage import exposure, io, filters\n",
    "import scipy\n",
    "from scipy.linalg import svd\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from skimage.feature import local_binary_pattern\n",
    "import pandas as pd\n",
    "from typing import AnyStr, BinaryIO, Dict, List, NamedTuple, Optional, Union\n",
    "from skimage.exposure import rescale_intensity\n",
    "import pydicom\n",
    "import pydicom.encaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_image_laterality(pixel_array: np.ndarray) -> str:\n",
    "    left_edge = np.sum(pixel_array[:, 0])  # sum of left edge pixels\n",
    "    right_edge = np.sum(pixel_array[:, -1])  # sum of right edge pixels\n",
    "    return \"R\" if left_edge < right_edge else \"L\"\n",
    "\n",
    "\n",
    "def _get_window_center(ds: dicom.dataset.FileDataset) -> np.float32:\n",
    "    return np.float32(ds[0x5200, 0x9229][0][0x0028, 0x9132][0][0x0028, 0x1050].value)\n",
    "\n",
    "\n",
    "def _get_window_width(ds: dicom.dataset.FileDataset) -> np.float32:\n",
    "    return np.float32(ds[0x5200, 0x9229][0][0x0028, 0x9132][0][0x0028, 0x1051].value)\n",
    "\n",
    "\n",
    "def read_cvs_file(path):\n",
    "    csv_matrix = np.genfromtxt(path, delimiter=',', skip_header=1)\n",
    "    return csv_matrix\n",
    "\n",
    "def dcmread_image(\n",
    "    fp: Union[str, \"os.PathLike[AnyStr]\", BinaryIO],\n",
    "    view: str, paziente: str, \n",
    "    index: Optional[np.uint] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Read pixel array from DBT DICOM file\"\"\"\n",
    "    ds = dicom.dcmread(fp)\n",
    "    print(\"considero: \", ds.PatientID, paziente)\n",
    "    ds.decompress(handler_name=\"pylibjpeg\")\n",
    "    pixel_array = ds.pixel_array\n",
    "    view_laterality = view[0].upper()\n",
    "    print(\"view_laterality: \", view_laterality)\n",
    "    image_laterality = _get_image_laterality(pixel_array[index or 0])\n",
    "    print(\"image_laterality: \", image_laterality)\n",
    "\n",
    "    if index is not None:\n",
    "        pixel_array = pixel_array[index]\n",
    "    if image_laterality[0] != view_laterality[0]:\n",
    "        pixel_array = np.flip(pixel_array, axis=(-1, -2))\n",
    "        pixel_array = (pixel_array / np.max(pixel_array)) * 255.\n",
    "        print(\"flip\")# Normalizza i valori dei pixel\n",
    "    else:\n",
    "        pixel_array = (pixel_array / np.max(pixel_array)) * 255.\n",
    "        print(\"no flip\")\n",
    "    return pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_daAumentare = \"your path\"\n",
    "path_masse_dir = \"your path/\"\n",
    "path_label = \"your path to BCS-DBT boxes-train-v2.csv\"\n",
    "ext = \".png\"\n",
    "extension = \".dcm\"\n",
    "boxes_train_csv = pd.read_csv(path_label)\n",
    "row = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesFilenames(rootdir):\n",
    "    filelist = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                filelist.append(filepath)\n",
    "\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf36d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_directory(path):\n",
    "    if os.path.exists(path):\n",
    "        # Cancella la directory esistente e tutti i suoi contenuti\n",
    "        for root, dirs, files in os.walk(path, topdown=False):\n",
    "            for file in files:\n",
    "                os.remove(os.path.join(root, file))\n",
    "            for dir in dirs:\n",
    "                os.rmdir(os.path.join(root, dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7384cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncation_normalization(img, mask):\n",
    "    \"\"\"\n",
    "    Clip and normalize pixels in the breast ROI.\n",
    "    @img : numpy array image\n",
    "    @mask : numpy array mask of the breast\n",
    "    return: numpy array of the normalized image\n",
    "    \"\"\"\n",
    "    Pmin = np.percentile(img[mask!=0], 0.1)\n",
    "    Pmax = np.percentile(img[mask!=0], 99)\n",
    "    truncated = np.clip(img,Pmin, Pmax)  \n",
    "    normalized = (truncated - Pmin)/(Pmax - Pmin)\n",
    "    normalized[mask==0]=0\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def select_mass(filename):\n",
    "    output_folder = \"your path\"  # Aggiorna con il percorso della cartella in cui salvare le slice_prep\n",
    "    empty_directory(output_folder)\n",
    "    number_of_Frames=[]\n",
    "    index = 0\n",
    "    \n",
    "    for file in filename:\n",
    "        slices_prep = []\n",
    "        immagini = []\n",
    "        try:\n",
    "            print(\"file: \", file)\n",
    "            ds = dicom.dcmread(file)\n",
    "            #rimuovo l'indice nell'ipotesi che se ho due immagini nella stessa view, mi serve un solo flip\n",
    "            patient_row = boxes_train_csv[(boxes_train_csv['PatientID'] == ds.PatientID) & (boxes_train_csv['VolumeSlices'] == ds.NumberOfFrames)]\n",
    "            view = patient_row['View'].values[0]\n",
    "            patient = patient_row['PatientID'].values[0]\n",
    "            data = dcmread_image(file, view, patient)\n",
    "\n",
    "            # data = np.uint8(data)\n",
    "            numSlice = data.shape[0]\n",
    "            slice_to_take = patient_row['Slice'].values\n",
    "            print('slice_to_take', slice_to_take)\n",
    "            original_coordinate = patient_row[['X', 'Y', 'Width', 'Height']].values[0]\n",
    "            x_r = original_coordinate[0]\n",
    "            y_r = original_coordinate[1]\n",
    "            w_r = original_coordinate[2]\n",
    "            h_r = original_coordinate[3]\n",
    "            target_width = 200\n",
    "            target_height = 100\n",
    "\n",
    "            for slices in slice_to_take:\n",
    "                for j in range(numSlice):    \n",
    "                    if j == slices-1:\n",
    "                        print(\"slice selected: \", j)\n",
    "                        data_jm1 = np.uint16(data[j-1])\n",
    "                        data_np_j = np.uint16(data[j])\n",
    "                        data_jp1 = np.uint16(data[j+1])\n",
    "                        data_jm1 = data_jm1[y_r:y_r+h_r, x_r:x_r+w_r]\n",
    "                        data_np_j = data_np_j[y_r:y_r+h_r, x_r:x_r+w_r]\n",
    "                        data_jp1 = data_jp1[y_r:y_r+h_r, x_r:x_r+w_r]\n",
    "                        print(data_np_j.shape)\n",
    "\n",
    "                        immagini.append(data_jm1)\n",
    "                        immagini.append(data_np_j)\n",
    "                        immagini.append(data_jp1)\n",
    "                        for img in immagini:\n",
    "                            if w_r > 200 or h_r > 100:\n",
    "                                _, binary_image = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                                print(binary_image.shape)\n",
    "                                norm = truncation_normalization(img, binary_image)\n",
    "                                norm = tf.expand_dims(norm, axis=-1)\n",
    "                                norm = tf.image.resize(norm, [100, 200], method=tf.image.ResizeMethod.BICUBIC)\n",
    "                                norm = np.array(norm, dtype=np.float64)\n",
    "\n",
    "                                print(\"norm shape: \", norm.shape)\n",
    "\n",
    "                            else:\n",
    "                                # Calcola il padding orizzontale (se necessario)\n",
    "                                if w_r < target_width:\n",
    "                                    diff_width = target_width - w_r\n",
    "                                    left_padding = diff_width // 2\n",
    "                                    right_padding = diff_width - left_padding\n",
    "                                else:\n",
    "                                    left_padding = 0\n",
    "                                    right_padding = 0\n",
    "\n",
    "                                # Calcola il padding verticale (se necessario)\n",
    "                                if h_r < target_height:\n",
    "                                    diff_height = target_height - h_r\n",
    "                                    top_padding = diff_height // 2\n",
    "                                    bottom_padding = diff_height - top_padding\n",
    "                                else:\n",
    "                                    top_padding = 0\n",
    "                                    bottom_padding = 0\n",
    "\n",
    "                                # Applica il padding utilizzando la funzione cv2.copyMakeBorder\n",
    "                                norm = cv2.copyMakeBorder(img, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "                                norm = np.uint16(norm)\n",
    "                                _, binary_image = cv2.threshold(norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                                print(binary_image.shape)\n",
    "                                norm = truncation_normalization(norm, binary_image)\n",
    "                                norm = tf.expand_dims(norm, axis=-1)\n",
    "\n",
    "                            norm = tf.convert_to_tensor(norm, dtype=tf.float64)\n",
    "\n",
    "                            slices_prep.append(norm/255.)\n",
    "                            number_of_Frames.append((ds.PatientID, ds.NumberOfFrames,ds.ViewPosition))\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Crea una cartella distinta utilizzando il patientID come nome\n",
    "            patient_id = ds.PatientID\n",
    "            fol_name = f\"{patient_id}\"\n",
    "            output_folder_ = os.path.join(output_folder, fol_name)\n",
    "            os.makedirs(output_folder_, exist_ok=True)\n",
    "\n",
    "            for idx, slice_pr in enumerate(slices_prep):\n",
    "\n",
    "                timestamp = str(time.time())\n",
    "\n",
    "                file_name = f\"slice_{index}_{idx}_{timestamp}.png\"\n",
    "                index = index +1\n",
    "                # Convert the processed slice tensor to a NumPy array\n",
    "                image_data = (slice_pr.numpy()*65535).astype(np.float64)\n",
    "                plt.imshow(image_data, cmap='gray')\n",
    "\n",
    "                # Save the DICOM image\n",
    "                output_file_path = output_folder_ + \"/\" + file_name\n",
    "                cv2.imwrite(output_file_path, image_data)\n",
    "\n",
    "                print(f\"Saved processed slice {idx} as DICOM image: {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore: {str(e)}\")\n",
    "    return number_of_Frames        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffde55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_filenames = getImagesFilenames(path_masse_dir)\n",
    "dicom_informations = select_mass(mass_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dicom_informations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import math\n",
    "# Funzione per applicare l'augmentation all'immagine\n",
    "def apply_data_augmentation(image):\n",
    "    augmented_images = []\n",
    "    augmentation_types = []  # Aggiungi questa lista per tenere traccia del tipo di augmentation\n",
    "    angles = []\n",
    "    '''\n",
    "    # Esegui il flip orizzontale\n",
    "    flipped_image = cv2.flip(image, 0)\n",
    "    augmented_images.append(flipped_image)\n",
    "    augmentation_types.append('flip_horizontal')  # Aggiungi il tipo di augmentation\n",
    "    '''\n",
    "    # Esegui la rotazione \n",
    "   \n",
    "    angle = 30  # Angolo di rotazione casuale tra -30 e 30 gradi\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] // 2, image.shape[0] // 2), angle, 1)\n",
    "    rotated_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "    augmented_images.append(rotated_image)\n",
    "    augmentation_types.append('rotate_random')\n",
    "    print(\"ruoto\")\n",
    "    angles.append(angle)\n",
    "    \n",
    "    print(\"aumento\")\n",
    "    return augmented_images, augmentation_types, angles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_update_csv(rootdir, nof):\n",
    "    augmented_data = []\n",
    "    index = 200\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        files = sorted(files, key=extract_numbers)\n",
    "        # PER OGNI IMMAGINE\n",
    "        for file in files:\n",
    "            if file.endswith(ext):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                img = Image.open(filepath)\n",
    "                patientID = nof[0][0]\n",
    "                nOFrames = nof[0][1]\n",
    "                viewPosition = nof[0][2]\n",
    "                print(\"considero: \", patientID)\n",
    "                # Converte l'immagine in un array NumPy\n",
    "                data = np.array(img)\n",
    "                patient_row = boxes_train_csv[(boxes_train_csv['PatientID'] == patientID)]\n",
    "                print(\"noframes: \", nOFrames)\n",
    "                print(patient_row)\n",
    "                nof.pop(0)\n",
    "\n",
    "                if not patient_row.empty:\n",
    "                    label = patient_row['Class'].values[0]\n",
    "                    print(\"label: \", label)                        \n",
    "                    # Applica la data augmentation all'immagine\n",
    "                    augmented_images, augmentation_type, angles  = apply_data_augmentation(data)\n",
    "                    augmented_data.append([patientID,viewPosition, label])\n",
    "\n",
    "                    # Aggiungi i dati originali alla lista\n",
    "                    for i in range(len(augmented_images)):\n",
    "                        augmented_data.append([patientID,viewPosition, label])\n",
    "\n",
    "                    \n",
    "                    for idx, augmented_image in enumerate(augmented_images):\n",
    "                        file_name = f\"{index}.png\"\n",
    "                        index = index+1\n",
    "                        output_file_path = os.path.join(subdir, file_name)  # Percorso completo del file di output\n",
    "                        augmented_image = Image.fromarray(augmented_image)  # Converti l'array NumPy in un oggetto immagine\n",
    "                        augmented_image.save(output_file_path)\n",
    "                        print(f\"Saved processed slice {idx} as DICOM image: {output_file_path}\")\n",
    "                           \n",
    "                    \n",
    "    #augmented_data = [list(t) for t in augmented_data]\n",
    "    \n",
    "    # Crea un nuovo DataFrame con i dati aumentati\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    # Salva il nuovo DataFrame in un nuovo CSV\n",
    "    augmented_df.to_csv('your path to ROI_AUGMENTED.csv', index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d79451a",
   "metadata": {},
   "source": [
    "lista_tuple = dicom_informations\n",
    "lista_tupledf = pd.DataFrame(dicom_informations)\n",
    "lista_tupledf.to_csv('C:/Users/Utente/Desktop/manifest-1617905855234/info_dicom_roi.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFr = pd.read_csv('your path to info_dicom_roi.csv')\n",
    "list_of_tuples = [tuple(x) for x in numberOfFr.to_records(index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71027dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_of_tuples:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5346ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_masse_da_aumentare = \"E:/ROI_Slices/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "augment_and_update_csv(training_daAumentare, list_of_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_labels = pd.read_csv('your path to ROI_AUGMENTED.csv')\n",
    "aug_tuples = [tuple(x) for x in data_and_labels.to_records(index=False)]\n",
    "dir_masse_aumentate = \"your path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4763fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in aug_tuples:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb27854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_separability(rootdir, nof):\n",
    "    dataset = []\n",
    "    index_csv = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "            # PER OGNI IMMAGINE\n",
    "            for file in files:\n",
    "                if file.endswith(ext):\n",
    "                    filepath = os.path.join(subdir, file)\n",
    "                    img = Image.open(filepath)\n",
    "                    patientID = nof[0][0]\n",
    "                    nOFrames = nof[0][1]\n",
    "                    viewPosition = nof[0][2]\n",
    "                    print(\"considero: \", patientID)\n",
    "                    # Converte l'immagine in un array NumPy\n",
    "                    data = np.array(img)\n",
    "                    patient_row = data_and_labels[(data_and_labels['PatientID'] == patientID) &(data_and_labels['INDEX'] == index_csv)]\n",
    "                    print(\"indice csv: \", index_csv)\n",
    "                    print(patient_row)\n",
    "                    index_csv = index_csv + 1\n",
    "                    nof.pop(0)\n",
    "\n",
    "                    if not patient_row.empty:\n",
    "                        label = patient_row['Class'].values[0]\n",
    "                        dataset.append((patientID, label, data))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a709d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_complete = check_for_separability(dir_masse_aumentate, aug_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset_complete[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [item[2] for item in dataset_complete]\n",
    "train_labels = [item[1] for item in dataset_complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eae57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARABILITA' TRA MASSE BENIGNE E MALIGNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "coordinates = []\n",
    "\n",
    "for img in train_images:\n",
    "    img_array = np.array(img)  # Converti l'immagine in un array NumPy\n",
    "    coords = img_array.flatten()  # Appiattisci l'immagine in un singolo array di coordinate\n",
    "    coordinates.extend(coords.tolist())  # Aggiungi le coordinate alla lista\n",
    "\n",
    "# Separazione delle coordinate per classe\n",
    "class_0_coords = [coordinates[i] for i in range(len(train_labels)) if train_labels[i] == 0]\n",
    "class_1_coords = [coordinates[i] for i in range(len(train_labels)) if train_labels[i] == 1]\n",
    "\n",
    "# Ora puoi creare il grafico di dispersione\n",
    "plt.scatter(class_0_coords, class_0_coords, label='Classe 0', c='blue')\n",
    "plt.scatter(class_1_coords, class_1_coords, label='Classe 1', c='red')\n",
    "\n",
    "plt.xlabel('Coordinate X e Y')\n",
    "plt.ylabel('Coordinate X e Y')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def extract_ROI_nomass(filename):\n",
    "    output_folder = \"your path\"  # Aggiorna con il percorso della cartella in cui salvare le slice_prep\n",
    "    empty_directory(output_folder)\n",
    "    number_of_Frames=[]\n",
    "    index = 100\n",
    "    for file in filename:\n",
    "        if file.endswith(extension):\n",
    "            slices_prep = []\n",
    "            immagini = []\n",
    "            try:\n",
    "                print(\"file: \", file)\n",
    "                ds = dicom.dcmread(file)\n",
    "                #rimuovo l'indice nell'ipotesi che se ho due immagini nella stessa view, mi serve un solo flip\n",
    "                ds = dicom.dcmread(file)        \n",
    "                print(f'considero: {ds.PatientID}')\n",
    "                ds.decompress(handler_name=\"pylibjpeg\")\n",
    "                numSlice = ds.NumberOfFrames\n",
    "                data = ds.pixel_array\n",
    "                data = data.astype(np.float32)\n",
    "                data_jm1 = data[19]\n",
    "                data_np_j = data[20]\n",
    "                data_jp1 = data[21]\n",
    "                data_jm1 = np.uint16(data_jm1)\n",
    "                data_np_j = np.uint16(data_np_j)\n",
    "                data_jp1 = np.uint16(data_jp1)\n",
    "                \n",
    "                immagini.append(data_jm1)\n",
    "                immagini.append(data_np_j)\n",
    "                immagini.append(data_jp1)\n",
    "                x_r = random.randint(0, 100)\n",
    "                y_r = random.randint(0,200)\n",
    "                for img in immagini:\n",
    "                    _, binary_image = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    contours, _ = cv2.findContours(np.uint8(binary_image), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    breast_contour = max(contours, key=cv2.contourArea)\n",
    "                    x, y, w, h = cv2.boundingRect(breast_contour)\n",
    "                    w = w-100\n",
    "                    h = h-900\n",
    "                    cropped_image = img[y:y + h, x:x + w]\n",
    "                    binary_image = binary_image[y:y + h, x:x + w]\n",
    "                    cropped_image = truncation_normalization(cropped_image, binary_image)\n",
    "                    width, height = cropped_image.shape\n",
    "\n",
    "                    \n",
    "\n",
    "                    rect = cropped_image[y_r:y_r+100, x_r:x_r+200]\n",
    "\n",
    "\n",
    "\n",
    "                    norm = tf.expand_dims(rect, axis=-1)\n",
    "\n",
    "                    norm = tf.convert_to_tensor(norm, dtype=tf.float64)\n",
    "                    norm = tf.image.resize(norm, [100,200])\n",
    "\n",
    "                    slices_prep.append(norm/255.)\n",
    "\n",
    "\n",
    "\n",
    "                # Crea una cartella distinta utilizzando il patientID come nome\n",
    "                patient_id = ds.PatientID\n",
    "                fol_name = f\"{patient_id}\"\n",
    "                output_folder_ = os.path.join(output_folder, fol_name)\n",
    "                os.makedirs(output_folder_, exist_ok=True)\n",
    "\n",
    "                for idx, slice_pr in enumerate(slices_prep):\n",
    "\n",
    "                    timestamp = str(time.time())\n",
    "\n",
    "                    file_name = f\"{index}.png\"\n",
    "                    index = index +1\n",
    "                    # Convert the processed slice tensor to a NumPy array\n",
    "                    image_data = (slice_pr.numpy()*65535).astype(np.float64)\n",
    "                    # Save the DICOM image\n",
    "                    output_file_path = output_folder_ + \"/\" + file_name\n",
    "                    cv2.imwrite(output_file_path, image_data)\n",
    "\n",
    "                    print(f\"Saved processed slice {idx} as PNG image: {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Errore: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd642d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_nomass = \"your path\"\n",
    "if os.path.exists(path_nomass):\n",
    "    print(f\"Il percorso {path_nomass} esiste.\")\n",
    "else:\n",
    "    print(f\"Il percorso {path_nomass} non esiste.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_filenames = getImagesFilenames(path_nomass)\n",
    "extract_ROI_nomass(mass_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab942e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import math\n",
    "# Funzione per applicare l'augmentation all'immagine\n",
    "def apply_data_augmentation(image):\n",
    "    augmented_images = []\n",
    "    augmentation_types = []  # Aggiungi questa lista per tenere traccia del tipo di augmentation\n",
    "    kernel_size = (5, 5)  # Dimensione del kernel del filtro gaussiano\n",
    "    sigma = random.uniform(3, 6.0)  # Valore casuale per la deviazione standard\n",
    "    blurred_image = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    augmented_images.append(blurred_image)\n",
    "    augmentation_types.append('gaussian_blur')\n",
    "    \n",
    "    print(\"aumento\")\n",
    "    return augmented_images, augmentation_types\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAUSSIANIZZO TUTTE LE IMMAGINI\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def augment_nomass(rootdir):\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        files = sorted(files, key=extract_numbers)\n",
    "        # PER OGNI IMMAGINE\n",
    "        for file in files:\n",
    "            if file.endswith(ext):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                paziente = os.path.basename(subdir)\n",
    "                img = Image.open(filepath)\n",
    "                \n",
    "                data = np.array(img)\n",
    "                               \n",
    "                # Applica la data augmentation all'immagine\n",
    "                augmented_images, augmentation_type  = apply_data_augmentation(data)\n",
    "                \n",
    "                for idx, augmented_image in enumerate(augmented_images):\n",
    "                    augmented_image = Image.fromarray(augmented_image)  # Converti l'array NumPy in un oggetto immagine\n",
    "                    augmented_image.save(filepath)  # Sovrascrivi l'immagine originale\n",
    "                    print(f\"Saved processed slice {idx} as PNG image: {filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47046833",
   "metadata": {},
   "source": [
    "import re\n",
    "def augment_nomass(rootdir):\n",
    "    augmented_data = []\n",
    "    index = 200\n",
    "\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        files = sorted(files, key=extract_numbers)\n",
    "        # PER OGNI IMMAGINE\n",
    "        for file in files:\n",
    "            if file.endswith(ext):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                paziente = os.path.basename(subdir)\n",
    "                img = Image.open(filepath)\n",
    "                \n",
    "                data = np.array(img)\n",
    "                               \n",
    "                # Applica la data augmentation all'immagine\n",
    "                augmented_images, augmentation_type, angles  = apply_data_augmentation(data)\n",
    "                augmented_data.append((paziente,0))\n",
    "                \n",
    "                for i in range(len(augmented_images)):\n",
    "                    augmented_data.append((paziente,0))\n",
    "\n",
    "                for idx, augmented_image in enumerate(augmented_images):\n",
    "                    file_name = f\"{index}.png\"\n",
    "                    index = index+1\n",
    "                    output_file_path = os.path.join(subdir, file_name)  # Percorso completo del file di output\n",
    "                    augmented_image = Image.fromarray(augmented_image)  # Converti l'array NumPy in un oggetto immagine\n",
    "                    augmented_image.save(output_file_path)\n",
    "                    print(f\"Saved processed slice {idx} as PNG image: {output_file_path}\")\n",
    "\n",
    "                 \n",
    "    #augmented_data = [list(t) for t in augmented_data]\n",
    "    \n",
    "    # Crea un nuovo DataFrame con i dati aumentati\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    # Salva il nuovo DataFrame in un nuovo CSV\n",
    "    augmented_df.to_csv('C:/Users/Utente/Desktop/manifest-1617905855234/ROI_AUGMENTED_NORMAL.csv', index=False)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(s):\n",
    "    numbers = re.findall(r'\\d+',s)\n",
    "    return[int(num)for num in numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"your path\"\n",
    "augment_nomass(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
