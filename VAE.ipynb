{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8443cf0b-7b9b-4024-97aa-04f00b158758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_cvs_file(path):\n",
    "    csv_matrix = np.genfromtxt(path, delimiter=',', skip_header=1)\n",
    "    return csv_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0851834-3c8c-4236-adbf-21c9531b3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(s):\n",
    "    numbers = re.findall(r'\\d+', s)\n",
    "    return [int(num) for num in numbers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4379b5b-81e7-4fc9-8cf5-18048ef5beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting preceding slice i-1 and current slice i\n",
    "def concatenate_images(directory):\n",
    "    dataset_list = []\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        files = sorted(files, key=extract_numbers)\n",
    "        print(\"files: \", files)\n",
    "        print(\"subdir: \", subdir)\n",
    "        \n",
    "        for i in range(0, len(files)-2,3):\n",
    "            print(\"file i: \", files[i])\n",
    "            print(\"file i+1: \", files[i+1])\n",
    "            \n",
    "            if files[i].endswith(extension) and files[i+1].endswith(extension):\n",
    "                filepath_i = os.path.join(subdir, files[i])\n",
    "                filepath_ip1 = os.path.join(subdir, files[i+1])\n",
    "            \n",
    "                img_i = Image.open(filepath_i)\n",
    "                img_ip1 = Image.open(filepath_ip1)\n",
    "            \n",
    "                data_i = np.array(img_i)\n",
    "                data_i = data_i / 255.\n",
    "\n",
    "                data_ip1 = np.array(img_ip1)\n",
    "                data_ip1 = data_ip1 / 255.\n",
    "\n",
    "                if data_i.shape == data_ip1.shape:\n",
    "                    # Concatena lungo la terza dimensione\n",
    "                    data = np.dstack((data_i, data_ip1))\n",
    "                    data = tf.convert_to_tensor(data, dtype=(tf.float32))\n",
    "                    print(data.shape)\n",
    "                    dataset_list.append(data)\n",
    "\n",
    "    return dataset_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Selecting current slice i and next slice i+1\n",
    "def concatenate_images(directory):\n",
    "    dataset_list = []\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        files = sorted(files, key=extract_numbers)\n",
    "        print(\"files: \", files)\n",
    "        print(\"subdir: \", subdir)\n",
    "        \n",
    "        for i in range(1, len(files)-1,3):\n",
    "            print(\"file i: \", files[i])\n",
    "            print(\"file i+1: \", files[i+1])\n",
    "            \n",
    "            if files[i].endswith(extension) and files[i+1].endswith(extension):\n",
    "                filepath_i = os.path.join(subdir, files[i])\n",
    "                filepath_ip1 = os.path.join(subdir, files[i+1])\n",
    "            \n",
    "                img_i = Image.open(filepath_i)\n",
    "                img_ip1 = Image.open(filepath_ip1)\n",
    "            \n",
    "                data_i = np.array(img_i)\n",
    "                data_i = data_i / 255.\n",
    "\n",
    "                data_ip1 = np.array(img_ip1)\n",
    "                data_ip1 = data_ip1 / 255.\n",
    "\n",
    "                if data_i.shape == data_ip1.shape:\n",
    "                    # Concatena lungo la terza dimensione\n",
    "                    data = np.dstack((data_i, data_ip1))\n",
    "                    data = tf.convert_to_tensor(data, dtype=(tf.float32))\n",
    "                    print(data.shape)\n",
    "                    dataset_list.append(data)\n",
    "\n",
    "    return dataset_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08993bef-457d-4d73-90e2-ae9872ca9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "         \n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3756ddad-f207-4095-ab9f-630cba7a50a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 200, 2)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 50, 100, 32)          608       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 50, 100, 32)          0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 50, 100, 32)          200       ['dropout[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 25, 50, 32)           0         ['batch_normalization[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 13, 25, 32)           9248      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 13, 25, 32)           0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 13, 25, 32)           52        ['dropout_1[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 13, 32)            0         ['batch_normalization_1[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 4, 7, 64)             18496     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 4, 7, 64)             0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 4, 7, 64)             16        ['dropout_2[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 4, 64)             0         ['batch_normalization_2[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 1, 2, 64)             36928     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 1, 2, 64)             0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 1, 2, 64)             4         ['dropout_3[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 64)             0         ['batch_normalization_3[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 64)                   0         ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " z_mean (Dense)              (None, 20)                   1300      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " z_log_var (Dense)           (None, 20)                   1300      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " sampling (Sampling)         (None, 20)                   0         ['z_mean[0][0]',              \n",
      "                                                                     'z_log_var[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68152 (266.22 KB)\n",
      "Trainable params: 68016 (265.69 KB)\n",
      "Non-trainable params: 136 (544.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " latent_dim = 20\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(100, 200, 2))\n",
    "#x = data_augmentation(encoder_inputs)\n",
    "x = layers.Conv2D(32, 3, activation=keras.layers.LeakyReLU(alpha=0.2), strides=2, padding=\"same\",\n",
    "                  kernel_initializer=keras.initializers.LecunNormal(),kernel_regularizer=l2(0.1))(encoder_inputs)\n",
    "x = layers.Dropout(0.7)(x)\n",
    "x = layers.BatchNormalization(axis=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation=keras.layers.LeakyReLU(alpha=0.2), strides=2, padding=\"same\",kernel_initializer=keras.initializers.LecunNormal(),\n",
    "                  kernel_regularizer=l2(0.1))(x)\n",
    "x = layers.Dropout(0.7)(x)\n",
    "x = layers.BatchNormalization(axis=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=keras.layers.LeakyReLU(alpha=0.2), strides=2, padding=\"same\",kernel_initializer=keras.initializers.LecunNormal(),\n",
    "                  kernel_regularizer=l2(0.1))(x)\n",
    "x = layers.Dropout(0.7)(x)\n",
    "x = layers.BatchNormalization(axis=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=keras.layers.LeakyReLU(alpha=0.2), strides=2, padding=\"same\",kernel_initializer=keras.initializers.LecunNormal(),\n",
    "                  kernel_regularizer=l2(0.1))(x)\n",
    "x = layers.Dropout(0.7)(x)\n",
    "x = layers.BatchNormalization(axis=1)(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\", activation= tf.identity,kernel_regularizer=l1(0.01), \n",
    "                      kernel_initializer=keras.initializers.RandomNormal())(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", activation= tf.identity,kernel_regularizer=l1(0.01),\n",
    "                         kernel_initializer=keras.initializers.RandomNormal())(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e900b83-6284-45e4-b9b3-3873e5efcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 80000)             1680000   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 25, 50, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 50, 100, 64)       331840    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50, 100, 64)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 50, 100, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 100, 200, 32)      100384    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100, 200, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 100, 200, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 100, 200, 16)      12816     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 200, 16)      0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 100, 200, 16)      64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 100, 200, 1)       145       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2125633 (8.11 MB)\n",
      "Trainable params: 2125409 (8.11 MB)\n",
      "Non-trainable params: 224 (896.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(25 * 50 * 64, activation=keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=keras.initializers.LecunNormal(), \n",
    "                 kernel_regularizer=l2(0.1))(latent_inputs)\n",
    "x = layers.Reshape((25, 50, 64))(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(64, 9, activation=keras.layers.LeakyReLU(alpha=0.2), strides=2, padding=\"same\",\n",
    "                           kernel_initializer=keras.initializers.LecunNormal(),kernel_regularizer=l2(0.1))(x)\n",
    "x = layers.Dropout(0.8)(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "\n",
    "x = layers.Conv2DTranspose(32, 7, activation=keras.layers.LeakyReLU(alpha=0.2), strides=2, padding=\"same\",\n",
    "                           kernel_initializer=keras.initializers.LecunNormal(),kernel_regularizer=l2(0.1))(x)\n",
    "x = layers.Dropout(0.8)(x)\n",
    "x = layers.BatchNormalization()(x)  \n",
    "\n",
    "x = layers.Conv2DTranspose(16, 5, activation=keras.layers.LeakyReLU(alpha=0.2), strides=1, padding=\"same\",\n",
    "                           kernel_initializer=keras.initializers.LecunNormal(),kernel_regularizer=l2(0.1))(x)\n",
    "x = layers.Dropout(0.7)(x)\n",
    "x = layers.BatchNormalization()(x) \n",
    "\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\", activation='sigmoid', \n",
    "                                         kernel_initializer =keras.initializers.RandomNormal(), kernel_regularizer=l2(0.1))(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a870db7-f1bb-43ef-9f79-5c5f713e1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vae training on generating preceding slice\n",
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.ssim_loss_tracker = keras.metrics.Mean(name=\"ssim_loss\")\n",
    "        \n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_total_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\"\n",
    "        )\n",
    "        self.val_kl_loss_tracker = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "        self.val_ssim_loss_tracker = keras.metrics.Mean(name=\"val_ssim_loss\")\n",
    "        \n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.ssim_loss_tracker\n",
    "        ]\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            data_i = data[..., 0]\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction = tf.squeeze(reconstruction, axis=-1)\n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.square(data_i - reconstruction), axis=(1, 2)))\n",
    "    \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            ssim_loss = tf.reduce_mean(tf.image.ssim(data_i, reconstruction, max_val=1.0))\n",
    "\n",
    "            total_loss = reconstruction_loss + 1.5*kl_loss -ssim_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.ssim_loss_tracker.update_state(ssim_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"ssim_loss\": self.ssim_loss_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            data_i = data[..., 0]\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction = tf.squeeze(reconstruction, axis=-1)\n",
    "            val_reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.square(data_i - reconstruction), axis=(1, 2)))\n",
    "            val_kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            val_kl_loss = tf.reduce_mean(tf.reduce_sum(val_kl_loss, axis=1))\n",
    "            val_ssim_loss=tf.reduce_mean(tf.image.ssim(data_i, reconstruction, max_val=1.0))\n",
    "\n",
    "            val_total_loss = val_reconstruction_loss + 1.5*val_kl_loss - val_ssim_loss\n",
    "        \n",
    "        self.val_total_loss_tracker.update_state(val_total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(val_reconstruction_loss)\n",
    "        self.val_kl_loss_tracker.update_state(val_kl_loss)\n",
    "        self.val_ssim_loss_tracker.update_state(val_ssim_loss)\n",
    "        return {\n",
    "            \"loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.val_kl_loss_tracker.result(),\n",
    "            \"ssim_loss\": self.val_ssim_loss_tracker.result(),\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b79538aa-7d96-41c3-a429-7d6e5924f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"path to training directory\"\n",
    "test_dir = \"path to test directory\"\n",
    "validation_dir = \"path to validation directory\"\n",
    "extension = \".png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images = concatenate_images(training_dir)\n",
    "validation_images = concatenate_images(validation_dir)\n",
    "test_images = concatenate_images(test_dir)\n",
    "\n",
    "\n",
    "\n",
    "buffer_size = 2000\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_images)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "validation_dataset = validation_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23c7a3e-45d8-4063-9f13-c280220079a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = CVAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc8b81f-ea24-4643-bf44-fc8ae2823261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "15/15 [==============================] - 74s 5s/step - loss: 1372.1993 - reconstruction_loss: 1362.3337 - kl_loss: 20.5673 - ssim_loss: 0.1849 - val_loss: 1702.2360 - val_reconstruction_loss: 1696.6437 - val_kl_loss: 3.7788 - val_ssim_loss: 0.0761\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 34s 2s/step - loss: 1274.6600 - reconstruction_loss: 1280.3997 - kl_loss: 22.9441 - ssim_loss: 0.2021 - val_loss: 1666.7234 - val_reconstruction_loss: 1659.1310 - val_kl_loss: 5.1202 - val_ssim_loss: 0.0882\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 1329.6160 - reconstruction_loss: 1222.0907 - kl_loss: 24.6229 - ssim_loss: 0.2189 - val_loss: 1632.5724 - val_reconstruction_loss: 1623.2083 - val_kl_loss: 6.3101 - val_ssim_loss: 0.1010\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 1230.6069 - reconstruction_loss: 1177.2747 - kl_loss: 24.3313 - ssim_loss: 0.2318 - val_loss: 1601.5963 - val_reconstruction_loss: 1590.5985 - val_kl_loss: 7.4063 - val_ssim_loss: 0.1118\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 1135.3780 - reconstruction_loss: 1134.3696 - kl_loss: 23.7176 - ssim_loss: 0.2497 - val_loss: 1573.4911 - val_reconstruction_loss: 1561.1313 - val_kl_loss: 8.3205 - val_ssim_loss: 0.1210\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 1202.4952 - reconstruction_loss: 1108.4108 - kl_loss: 23.3716 - ssim_loss: 0.2599 - val_loss: 1547.6857 - val_reconstruction_loss: 1534.1150 - val_kl_loss: 9.1337 - val_ssim_loss: 0.1299\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 1055.1035 - reconstruction_loss: 1067.0526 - kl_loss: 23.2597 - ssim_loss: 0.2606 - val_loss: 1523.1737 - val_reconstruction_loss: 1508.5388 - val_kl_loss: 9.8492 - val_ssim_loss: 0.1390\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 1096.6981 - reconstruction_loss: 1033.4652 - kl_loss: 21.8770 - ssim_loss: 0.2796 - val_loss: 1500.4824 - val_reconstruction_loss: 1485.0270 - val_kl_loss: 10.4023 - val_ssim_loss: 0.1482\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 93s 6s/step - loss: 1000.3859 - reconstruction_loss: 1010.6735 - kl_loss: 20.0031 - ssim_loss: 0.3074 - val_loss: 1481.1338 - val_reconstruction_loss: 1465.0662 - val_kl_loss: 10.8151 - val_ssim_loss: 0.1552\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 1054.1476 - reconstruction_loss: 967.7336 - kl_loss: 18.5083 - ssim_loss: 0.3107 - val_loss: 1460.5502 - val_reconstruction_loss: 1443.9861 - val_kl_loss: 11.1529 - val_ssim_loss: 0.1655\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 945.5705 - reconstruction_loss: 919.0331 - kl_loss: 17.5168 - ssim_loss: 0.3495 - val_loss: 1439.7255 - val_reconstruction_loss: 1422.7881 - val_kl_loss: 11.4081 - val_ssim_loss: 0.1751\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 958.1341 - reconstruction_loss: 879.0121 - kl_loss: 16.3168 - ssim_loss: 0.3670 - val_loss: 1419.5959 - val_reconstruction_loss: 1402.3816 - val_kl_loss: 11.5992 - val_ssim_loss: 0.1847\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 858.5665 - reconstruction_loss: 830.4150 - kl_loss: 15.7100 - ssim_loss: 0.3932 - val_loss: 1399.9784 - val_reconstruction_loss: 1382.5121 - val_kl_loss: 11.7739 - val_ssim_loss: 0.1948\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 807.5077 - reconstruction_loss: 783.4826 - kl_loss: 15.6729 - ssim_loss: 0.4197 - val_loss: 1380.2220 - val_reconstruction_loss: 1362.5269 - val_kl_loss: 11.9336 - val_ssim_loss: 0.2055\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 779.7543 - reconstruction_loss: 769.3249 - kl_loss: 15.5600 - ssim_loss: 0.4391 - val_loss: 1361.8228 - val_reconstruction_loss: 1343.9291 - val_kl_loss: 12.0727 - val_ssim_loss: 0.2155\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 765.0923 - reconstruction_loss: 755.0037 - kl_loss: 15.5394 - ssim_loss: 0.4426 - val_loss: 1344.0955 - val_reconstruction_loss: 1326.0181 - val_kl_loss: 12.2016 - val_ssim_loss: 0.2250\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 748.2014 - reconstruction_loss: 726.5540 - kl_loss: 15.7288 - ssim_loss: 0.4558 - val_loss: 1328.5813 - val_reconstruction_loss: 1310.3231 - val_kl_loss: 12.3280 - val_ssim_loss: 0.2337\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 711.0899 - reconstruction_loss: 722.3445 - kl_loss: 15.5344 - ssim_loss: 0.4607 - val_loss: 1311.2913 - val_reconstruction_loss: 1292.8743 - val_kl_loss: 12.4401 - val_ssim_loss: 0.2431\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 698.2760 - reconstruction_loss: 684.4997 - kl_loss: 15.7372 - ssim_loss: 0.4657 - val_loss: 1296.0927 - val_reconstruction_loss: 1277.5050 - val_kl_loss: 12.5593 - val_ssim_loss: 0.2511\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 736.9846 - reconstruction_loss: 671.6141 - kl_loss: 16.3208 - ssim_loss: 0.4802 - val_loss: 1280.6266 - val_reconstruction_loss: 1261.8630 - val_kl_loss: 12.6820 - val_ssim_loss: 0.2593\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 676.7180 - reconstruction_loss: 657.6050 - kl_loss: 16.5660 - ssim_loss: 0.4896 - val_loss: 1265.0681 - val_reconstruction_loss: 1246.1194 - val_kl_loss: 12.8111 - val_ssim_loss: 0.2679\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 680.6684 - reconstruction_loss: 644.3506 - kl_loss: 17.2337 - ssim_loss: 0.4906 - val_loss: 1250.8400 - val_reconstruction_loss: 1231.6777 - val_kl_loss: 12.9585 - val_ssim_loss: 0.2754\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 641.1981 - reconstruction_loss: 630.2725 - kl_loss: 17.6956 - ssim_loss: 0.5002 - val_loss: 1236.6273 - val_reconstruction_loss: 1217.2621 - val_kl_loss: 13.0989 - val_ssim_loss: 0.2830\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 647.3610 - reconstruction_loss: 634.9612 - kl_loss: 17.9713 - ssim_loss: 0.4948 - val_loss: 1223.6522 - val_reconstruction_loss: 1204.0708 - val_kl_loss: 13.2476 - val_ssim_loss: 0.2899\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 606.1233 - reconstruction_loss: 616.1564 - kl_loss: 18.4021 - ssim_loss: 0.5074 - val_loss: 1211.6119 - val_reconstruction_loss: 1191.8142 - val_kl_loss: 13.3962 - val_ssim_loss: 0.2965\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 658.3170 - reconstruction_loss: 621.4646 - kl_loss: 18.9330 - ssim_loss: 0.5047 - val_loss: 1199.7806 - val_reconstruction_loss: 1179.7566 - val_kl_loss: 13.5514 - val_ssim_loss: 0.3031\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 614.8614 - reconstruction_loss: 607.1765 - kl_loss: 19.0630 - ssim_loss: 0.5089 - val_loss: 1188.5325 - val_reconstruction_loss: 1168.2954 - val_kl_loss: 13.6976 - val_ssim_loss: 0.3093\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 650.2586 - reconstruction_loss: 635.3270 - kl_loss: 19.1706 - ssim_loss: 0.4976 - val_loss: 1177.9744 - val_reconstruction_loss: 1157.5342 - val_kl_loss: 13.8368 - val_ssim_loss: 0.3148\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 684.7931 - reconstruction_loss: 625.9348 - kl_loss: 18.8607 - ssim_loss: 0.5062 - val_loss: 1168.0432 - val_reconstruction_loss: 1147.4231 - val_kl_loss: 13.9605 - val_ssim_loss: 0.3205\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 75s 5s/step - loss: 643.2940 - reconstruction_loss: 609.5591 - kl_loss: 18.7995 - ssim_loss: 0.5122 - val_loss: 1158.4091 - val_reconstruction_loss: 1137.6230 - val_kl_loss: 14.0744 - val_ssim_loss: 0.3255\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 627.7085 - reconstruction_loss: 591.2154 - kl_loss: 19.0095 - ssim_loss: 0.5168 - val_loss: 1148.4758 - val_reconstruction_loss: 1127.5194 - val_kl_loss: 14.1914 - val_ssim_loss: 0.3307\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 640.5547 - reconstruction_loss: 575.0150 - kl_loss: 19.5087 - ssim_loss: 0.5236 - val_loss: 1138.5559 - val_reconstruction_loss: 1117.4144 - val_kl_loss: 14.3184 - val_ssim_loss: 0.3358\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 75s 5s/step - loss: 646.9727 - reconstruction_loss: 575.9863 - kl_loss: 19.9694 - ssim_loss: 0.5225 - val_loss: 1129.0909 - val_reconstruction_loss: 1107.7607 - val_kl_loss: 14.4474 - val_ssim_loss: 0.3408\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 590.4419 - reconstruction_loss: 568.7903 - kl_loss: 20.2495 - ssim_loss: 0.5305 - val_loss: 1120.3218 - val_reconstruction_loss: 1098.7955 - val_kl_loss: 14.5813 - val_ssim_loss: 0.3456\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 616.6519 - reconstruction_loss: 565.9945 - kl_loss: 20.8224 - ssim_loss: 0.5299 - val_loss: 1111.8242 - val_reconstruction_loss: 1090.0959 - val_kl_loss: 14.7191 - val_ssim_loss: 0.3502\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 75s 5s/step - loss: 619.6977 - reconstruction_loss: 565.9659 - kl_loss: 21.2365 - ssim_loss: 0.5328 - val_loss: 1103.7676 - val_reconstruction_loss: 1081.8308 - val_kl_loss: 14.8609 - val_ssim_loss: 0.3546\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 633.8568 - reconstruction_loss: 579.8438 - kl_loss: 21.6959 - ssim_loss: 0.5297 - val_loss: 1095.5123 - val_reconstruction_loss: 1073.3746 - val_kl_loss: 14.9979 - val_ssim_loss: 0.3590\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 628.4360 - reconstruction_loss: 580.6711 - kl_loss: 21.4142 - ssim_loss: 0.5260 - val_loss: 1087.9902 - val_reconstruction_loss: 1065.6683 - val_kl_loss: 15.1235 - val_ssim_loss: 0.3631\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 611.8958 - reconstruction_loss: 575.5433 - kl_loss: 21.2800 - ssim_loss: 0.5261 - val_loss: 1080.5372 - val_reconstruction_loss: 1058.0388 - val_kl_loss: 15.2437 - val_ssim_loss: 0.3669\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 592.6754 - reconstruction_loss: 560.5685 - kl_loss: 21.1889 - ssim_loss: 0.5358 - val_loss: 1073.3235 - val_reconstruction_loss: 1050.6572 - val_kl_loss: 15.3582 - val_ssim_loss: 0.3708\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 597.0242 - reconstruction_loss: 544.7813 - kl_loss: 21.5532 - ssim_loss: 0.5410 - val_loss: 1066.6204 - val_reconstruction_loss: 1043.7792 - val_kl_loss: 15.4772 - val_ssim_loss: 0.3744\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 571.2931 - reconstruction_loss: 540.6161 - kl_loss: 22.1695 - ssim_loss: 0.5472 - val_loss: 1060.2173 - val_reconstruction_loss: 1037.1866 - val_kl_loss: 15.6058 - val_ssim_loss: 0.3779\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 586.9118 - reconstruction_loss: 537.9885 - kl_loss: 22.5559 - ssim_loss: 0.5464 - val_loss: 1053.5741 - val_reconstruction_loss: 1030.3534 - val_kl_loss: 15.7349 - val_ssim_loss: 0.3814\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 553.4364 - reconstruction_loss: 542.0919 - kl_loss: 22.9476 - ssim_loss: 0.5466 - val_loss: 1047.0332 - val_reconstruction_loss: 1023.6169 - val_kl_loss: 15.8676 - val_ssim_loss: 0.3849\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 599.1327 - reconstruction_loss: 547.8904 - kl_loss: 23.4775 - ssim_loss: 0.5475 - val_loss: 1040.8174 - val_reconstruction_loss: 1017.2020 - val_kl_loss: 16.0026 - val_ssim_loss: 0.3883\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 75s 5s/step - loss: 596.9868 - reconstruction_loss: 535.1694 - kl_loss: 23.6857 - ssim_loss: 0.5472 - val_loss: 1034.7095 - val_reconstruction_loss: 1010.9019 - val_kl_loss: 16.1329 - val_ssim_loss: 0.3915\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 492.9564 - reconstruction_loss: 526.1927 - kl_loss: 23.4367 - ssim_loss: 0.5566 - val_loss: 1028.6886 - val_reconstruction_loss: 1004.7021 - val_kl_loss: 16.2543 - val_ssim_loss: 0.3948\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 596.9096 - reconstruction_loss: 523.3404 - kl_loss: 23.7854 - ssim_loss: 0.5550 - val_loss: 1023.0406 - val_reconstruction_loss: 998.8619 - val_kl_loss: 16.3844 - val_ssim_loss: 0.3979\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 75s 5s/step - loss: 520.8057 - reconstruction_loss: 517.9149 - kl_loss: 24.0594 - ssim_loss: 0.5516 - val_loss: 1017.4450 - val_reconstruction_loss: 993.0834 - val_kl_loss: 16.5083 - val_ssim_loss: 0.4009\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 526.6195 - reconstruction_loss: 516.7214 - kl_loss: 24.1387 - ssim_loss: 0.5593 - val_loss: 1011.9083 - val_reconstruction_loss: 987.3622 - val_kl_loss: 16.6333 - val_ssim_loss: 0.4038\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 542.2562 - reconstruction_loss: 512.0564 - kl_loss: 24.4973 - ssim_loss: 0.5637 - val_loss: 1006.7400 - val_reconstruction_loss: 982.0045 - val_kl_loss: 16.7614 - val_ssim_loss: 0.4066\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 537.7327 - reconstruction_loss: 521.1212 - kl_loss: 24.8909 - ssim_loss: 0.5589 - val_loss: 1001.8129 - val_reconstruction_loss: 976.8925 - val_kl_loss: 16.8864 - val_ssim_loss: 0.4092\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 578.3499 - reconstruction_loss: 511.2765 - kl_loss: 25.0166 - ssim_loss: 0.5620 - val_loss: 996.7148 - val_reconstruction_loss: 971.6116 - val_kl_loss: 17.0102 - val_ssim_loss: 0.4120\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 75s 5s/step - loss: 550.2240 - reconstruction_loss: 512.4743 - kl_loss: 25.1752 - ssim_loss: 0.5602 - val_loss: 991.7263 - val_reconstruction_loss: 966.4372 - val_kl_loss: 17.1359 - val_ssim_loss: 0.4148\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 537.5130 - reconstruction_loss: 507.2399 - kl_loss: 25.5917 - ssim_loss: 0.5676 - val_loss: 987.0383 - val_reconstruction_loss: 961.5620 - val_kl_loss: 17.2624 - val_ssim_loss: 0.4173\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 496.0567 - reconstruction_loss: 499.4345 - kl_loss: 25.9054 - ssim_loss: 0.5712 - val_loss: 982.2318 - val_reconstruction_loss: 956.5646 - val_kl_loss: 17.3915 - val_ssim_loss: 0.4200\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 545.2300 - reconstruction_loss: 495.9293 - kl_loss: 26.3470 - ssim_loss: 0.5696 - val_loss: 977.5293 - val_reconstruction_loss: 951.6679 - val_kl_loss: 17.5227 - val_ssim_loss: 0.4225\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 549.3835 - reconstruction_loss: 496.7052 - kl_loss: 26.4841 - ssim_loss: 0.5684 - val_loss: 973.1234 - val_reconstruction_loss: 947.0760 - val_kl_loss: 17.6483 - val_ssim_loss: 0.4249\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 535.6625 - reconstruction_loss: 500.6592 - kl_loss: 26.6366 - ssim_loss: 0.5674 - val_loss: 968.8538 - val_reconstruction_loss: 942.6169 - val_kl_loss: 17.7761 - val_ssim_loss: 0.4273\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 561.3972 - reconstruction_loss: 493.6500 - kl_loss: 26.9362 - ssim_loss: 0.5749 - val_loss: 964.5148 - val_reconstruction_loss: 938.0884 - val_kl_loss: 17.9040 - val_ssim_loss: 0.4297\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 552.6774 - reconstruction_loss: 489.3762 - kl_loss: 27.1518 - ssim_loss: 0.5720 - val_loss: 960.4706 - val_reconstruction_loss: 933.8577 - val_kl_loss: 18.0300 - val_ssim_loss: 0.4321\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 531.9620 - reconstruction_loss: 476.5196 - kl_loss: 27.5516 - ssim_loss: 0.5786 - val_loss: 956.1127 - val_reconstruction_loss: 929.3054 - val_kl_loss: 18.1611 - val_ssim_loss: 0.4345\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 519.1039 - reconstruction_loss: 483.0423 - kl_loss: 27.8077 - ssim_loss: 0.5782 - val_loss: 952.1580 - val_reconstruction_loss: 925.1631 - val_kl_loss: 18.2877 - val_ssim_loss: 0.4367\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 509.9397 - reconstruction_loss: 482.6733 - kl_loss: 27.7331 - ssim_loss: 0.5752 - val_loss: 948.2612 - val_reconstruction_loss: 921.0804 - val_kl_loss: 18.4131 - val_ssim_loss: 0.4389\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 553.7068 - reconstruction_loss: 487.2325 - kl_loss: 28.1823 - ssim_loss: 0.5786 - val_loss: 944.4661 - val_reconstruction_loss: 917.0990 - val_kl_loss: 18.5387 - val_ssim_loss: 0.4411\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 518.4850 - reconstruction_loss: 479.4894 - kl_loss: 28.1127 - ssim_loss: 0.5793 - val_loss: 940.7529 - val_reconstruction_loss: 913.2057 - val_kl_loss: 18.6601 - val_ssim_loss: 0.4431\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 528.0859 - reconstruction_loss: 468.0932 - kl_loss: 28.5625 - ssim_loss: 0.5839 - val_loss: 937.0631 - val_reconstruction_loss: 909.3260 - val_kl_loss: 18.7881 - val_ssim_loss: 0.4451\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 501.2388 - reconstruction_loss: 467.8765 - kl_loss: 29.0067 - ssim_loss: 0.5841 - val_loss: 933.4718 - val_reconstruction_loss: 905.5461 - val_kl_loss: 18.9152 - val_ssim_loss: 0.4471\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 503.0334 - reconstruction_loss: 466.0672 - kl_loss: 29.1748 - ssim_loss: 0.5867 - val_loss: 930.2180 - val_reconstruction_loss: 902.1052 - val_kl_loss: 19.0411 - val_ssim_loss: 0.4490\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 542.3054 - reconstruction_loss: 477.5253 - kl_loss: 29.3454 - ssim_loss: 0.5823 - val_loss: 926.6337 - val_reconstruction_loss: 898.3309 - val_kl_loss: 19.1692 - val_ssim_loss: 0.4510\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 493.8542 - reconstruction_loss: 467.1294 - kl_loss: 29.8654 - ssim_loss: 0.5868 - val_loss: 923.3221 - val_reconstruction_loss: 894.8344 - val_kl_loss: 19.2938 - val_ssim_loss: 0.4530\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 539.7483 - reconstruction_loss: 461.3907 - kl_loss: 29.7220 - ssim_loss: 0.5894 - val_loss: 919.6824 - val_reconstruction_loss: 891.0128 - val_kl_loss: 19.4164 - val_ssim_loss: 0.4549\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 507.4076 - reconstruction_loss: 455.2320 - kl_loss: 29.6373 - ssim_loss: 0.5910 - val_loss: 916.2401 - val_reconstruction_loss: 887.3953 - val_kl_loss: 19.5345 - val_ssim_loss: 0.4569\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 492.4736 - reconstruction_loss: 452.4100 - kl_loss: 29.8260 - ssim_loss: 0.5912 - val_loss: 912.7256 - val_reconstruction_loss: 883.7023 - val_kl_loss: 19.6549 - val_ssim_loss: 0.4589\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 478.6534 - reconstruction_loss: 453.7986 - kl_loss: 30.4427 - ssim_loss: 0.5949 - val_loss: 909.4172 - val_reconstruction_loss: 880.2076 - val_kl_loss: 19.7802 - val_ssim_loss: 0.4608\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 522.9666 - reconstruction_loss: 453.1156 - kl_loss: 30.9147 - ssim_loss: 0.5950 - val_loss: 906.4903 - val_reconstruction_loss: 877.0981 - val_kl_loss: 19.9031 - val_ssim_loss: 0.4625\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 533.4150 - reconstruction_loss: 460.3809 - kl_loss: 30.6495 - ssim_loss: 0.5925 - val_loss: 903.3691 - val_reconstruction_loss: 873.8033 - val_kl_loss: 20.0200 - val_ssim_loss: 0.4643\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 516.7234 - reconstruction_loss: 458.5410 - kl_loss: 30.5783 - ssim_loss: 0.5944 - val_loss: 900.2590 - val_reconstruction_loss: 870.5219 - val_kl_loss: 20.1355 - val_ssim_loss: 0.4660\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 519.5411 - reconstruction_loss: 444.8818 - kl_loss: 30.8825 - ssim_loss: 0.5990 - val_loss: 897.2267 - val_reconstruction_loss: 867.3148 - val_kl_loss: 20.2530 - val_ssim_loss: 0.4677\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 525.4426 - reconstruction_loss: 442.5792 - kl_loss: 31.3733 - ssim_loss: 0.6005 - val_loss: 894.1231 - val_reconstruction_loss: 864.0321 - val_kl_loss: 20.3735 - val_ssim_loss: 0.4693\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 493.6305 - reconstruction_loss: 447.7535 - kl_loss: 31.4286 - ssim_loss: 0.5962 - val_loss: 891.2068 - val_reconstruction_loss: 860.9457 - val_kl_loss: 20.4880 - val_ssim_loss: 0.4708\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 495.5330 - reconstruction_loss: 431.3177 - kl_loss: 31.4187 - ssim_loss: 0.6025 - val_loss: 888.2082 - val_reconstruction_loss: 857.7753 - val_kl_loss: 20.6035 - val_ssim_loss: 0.4725\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 505.2137 - reconstruction_loss: 431.0199 - kl_loss: 31.7562 - ssim_loss: 0.6061 - val_loss: 885.1985 - val_reconstruction_loss: 854.5919 - val_kl_loss: 20.7206 - val_ssim_loss: 0.4742\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 506.6659 - reconstruction_loss: 430.0132 - kl_loss: 32.1964 - ssim_loss: 0.6047 - val_loss: 882.1887 - val_reconstruction_loss: 851.4049 - val_kl_loss: 20.8397 - val_ssim_loss: 0.4759\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 487.2290 - reconstruction_loss: 422.7089 - kl_loss: 32.6252 - ssim_loss: 0.6118 - val_loss: 879.2993 - val_reconstruction_loss: 848.3366 - val_kl_loss: 20.9601 - val_ssim_loss: 0.4775\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 475.4460 - reconstruction_loss: 425.0558 - kl_loss: 32.9283 - ssim_loss: 0.6092 - val_loss: 876.5204 - val_reconstruction_loss: 845.3779 - val_kl_loss: 21.0809 - val_ssim_loss: 0.4791\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 535.1113 - reconstruction_loss: 426.2342 - kl_loss: 33.1684 - ssim_loss: 0.6114 - val_loss: 873.9299 - val_reconstruction_loss: 842.6104 - val_kl_loss: 21.1999 - val_ssim_loss: 0.4805\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 463.3975 - reconstruction_loss: 422.7565 - kl_loss: 33.2734 - ssim_loss: 0.6132 - val_loss: 871.1948 - val_reconstruction_loss: 839.6991 - val_kl_loss: 21.3184 - val_ssim_loss: 0.4820\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 476.0966 - reconstruction_loss: 422.2020 - kl_loss: 33.5043 - ssim_loss: 0.6114 - val_loss: 868.7512 - val_reconstruction_loss: 837.0770 - val_kl_loss: 21.4382 - val_ssim_loss: 0.4833\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 517.8970 - reconstruction_loss: 465.3997 - kl_loss: 33.4495 - ssim_loss: 0.6026 - val_loss: 866.2109 - val_reconstruction_loss: 834.3652 - val_kl_loss: 21.5535 - val_ssim_loss: 0.4847\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 80s 6s/step - loss: 517.1423 - reconstruction_loss: 431.8158 - kl_loss: 33.5699 - ssim_loss: 0.6087 - val_loss: 863.7163 - val_reconstruction_loss: 831.7021 - val_kl_loss: 21.6667 - val_ssim_loss: 0.4860\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 449.4852 - reconstruction_loss: 431.0364 - kl_loss: 33.1186 - ssim_loss: 0.6082 - val_loss: 861.1821 - val_reconstruction_loss: 829.0107 - val_kl_loss: 21.7725 - val_ssim_loss: 0.4875\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 487.0859 - reconstruction_loss: 419.6099 - kl_loss: 33.0139 - ssim_loss: 0.6148 - val_loss: 858.6316 - val_reconstruction_loss: 826.3036 - val_kl_loss: 21.8778 - val_ssim_loss: 0.4889\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 463.6536 - reconstruction_loss: 412.6257 - kl_loss: 33.4279 - ssim_loss: 0.6169 - val_loss: 856.2263 - val_reconstruction_loss: 823.7367 - val_kl_loss: 21.9865 - val_ssim_loss: 0.4904\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 452.7401 - reconstruction_loss: 408.2215 - kl_loss: 33.9752 - ssim_loss: 0.6208 - val_loss: 853.7332 - val_reconstruction_loss: 821.0784 - val_kl_loss: 22.0976 - val_ssim_loss: 0.4917\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 464.6433 - reconstruction_loss: 413.1416 - kl_loss: 34.3867 - ssim_loss: 0.6180 - val_loss: 851.3349 - val_reconstruction_loss: 818.5140 - val_kl_loss: 22.2092 - val_ssim_loss: 0.4931\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 491.0051 - reconstruction_loss: 415.5254 - kl_loss: 34.0252 - ssim_loss: 0.6197 - val_loss: 848.8929 - val_reconstruction_loss: 815.9183 - val_kl_loss: 22.3126 - val_ssim_loss: 0.4944\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 429.0415 - reconstruction_loss: 409.5576 - kl_loss: 34.0631 - ssim_loss: 0.6213 - val_loss: 846.4220 - val_reconstruction_loss: 813.2907 - val_kl_loss: 22.4180 - val_ssim_loss: 0.4958\n",
      "Epoch 99/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 452.0011 - reconstruction_loss: 404.7980 - kl_loss: 34.5067 - ssim_loss: 0.6213 - val_loss: 843.9871 - val_reconstruction_loss: 810.6932 - val_kl_loss: 22.5273 - val_ssim_loss: 0.4972\n",
      "Epoch 100/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 394.4271 - reconstruction_loss: 396.1297 - kl_loss: 34.9199 - ssim_loss: 0.6256 - val_loss: 841.5875 - val_reconstruction_loss: 808.1337 - val_kl_loss: 22.6349 - val_ssim_loss: 0.4985\n",
      "Epoch 101/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 455.4013 - reconstruction_loss: 395.9623 - kl_loss: 35.1046 - ssim_loss: 0.6282 - val_loss: 839.1957 - val_reconstruction_loss: 805.5802 - val_kl_loss: 22.7436 - val_ssim_loss: 0.4999\n",
      "Epoch 102/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 413.3765 - reconstruction_loss: 394.2583 - kl_loss: 35.3224 - ssim_loss: 0.6279 - val_loss: 836.8521 - val_reconstruction_loss: 803.0750 - val_kl_loss: 22.8522 - val_ssim_loss: 0.5012\n",
      "Epoch 103/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 430.9313 - reconstruction_loss: 395.8675 - kl_loss: 35.5383 - ssim_loss: 0.6257 - val_loss: 834.5551 - val_reconstruction_loss: 800.6182 - val_kl_loss: 22.9596 - val_ssim_loss: 0.5025\n",
      "Epoch 104/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 518.8001 - reconstruction_loss: 391.8881 - kl_loss: 35.6054 - ssim_loss: 0.6294 - val_loss: 832.2932 - val_reconstruction_loss: 798.1956 - val_kl_loss: 23.0676 - val_ssim_loss: 0.5038\n",
      "Epoch 105/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 407.7846 - reconstruction_loss: 392.1104 - kl_loss: 35.9086 - ssim_loss: 0.6312 - val_loss: 830.1720 - val_reconstruction_loss: 795.9145 - val_kl_loss: 23.1750 - val_ssim_loss: 0.5050\n",
      "Epoch 106/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 428.1485 - reconstruction_loss: 389.5764 - kl_loss: 36.0339 - ssim_loss: 0.6297 - val_loss: 828.0106 - val_reconstruction_loss: 793.5943 - val_kl_loss: 23.2816 - val_ssim_loss: 0.5062\n",
      "Epoch 107/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 436.3007 - reconstruction_loss: 386.8034 - kl_loss: 36.1656 - ssim_loss: 0.6291 - val_loss: 825.7703 - val_reconstruction_loss: 791.1955 - val_kl_loss: 23.3881 - val_ssim_loss: 0.5075\n",
      "Epoch 108/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 453.4314 - reconstruction_loss: 385.0212 - kl_loss: 36.3898 - ssim_loss: 0.6344 - val_loss: 823.5981 - val_reconstruction_loss: 788.8636 - val_kl_loss: 23.4953 - val_ssim_loss: 0.5087\n",
      "Epoch 109/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 471.4000 - reconstruction_loss: 387.2867 - kl_loss: 36.5729 - ssim_loss: 0.6343 - val_loss: 821.4851 - val_reconstruction_loss: 786.5958 - val_kl_loss: 23.5994 - val_ssim_loss: 0.5099\n",
      "Epoch 110/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 457.2974 - reconstruction_loss: 386.1553 - kl_loss: 36.4101 - ssim_loss: 0.6347 - val_loss: 819.6058 - val_reconstruction_loss: 784.5661 - val_kl_loss: 23.7004 - val_ssim_loss: 0.5111\n",
      "Epoch 111/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 448.7227 - reconstruction_loss: 385.4869 - kl_loss: 36.3362 - ssim_loss: 0.6344 - val_loss: 817.6092 - val_reconstruction_loss: 782.4181 - val_kl_loss: 23.8020 - val_ssim_loss: 0.5122\n",
      "Epoch 112/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 428.2899 - reconstruction_loss: 386.7878 - kl_loss: 36.4376 - ssim_loss: 0.6335 - val_loss: 815.6014 - val_reconstruction_loss: 780.2662 - val_kl_loss: 23.8988 - val_ssim_loss: 0.5133\n",
      "Epoch 113/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 448.9224 - reconstruction_loss: 383.0476 - kl_loss: 36.1468 - ssim_loss: 0.6345 - val_loss: 813.5512 - val_reconstruction_loss: 778.0712 - val_kl_loss: 23.9961 - val_ssim_loss: 0.5145\n",
      "Epoch 114/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 430.8885 - reconstruction_loss: 379.6360 - kl_loss: 36.6089 - ssim_loss: 0.6366 - val_loss: 811.5295 - val_reconstruction_loss: 775.9026 - val_kl_loss: 24.0949 - val_ssim_loss: 0.5156\n",
      "Epoch 115/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 396.9827 - reconstruction_loss: 379.6061 - kl_loss: 37.0601 - ssim_loss: 0.6371 - val_loss: 809.5377 - val_reconstruction_loss: 773.7629 - val_kl_loss: 24.1942 - val_ssim_loss: 0.5168\n",
      "Epoch 116/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 401.2893 - reconstruction_loss: 381.8881 - kl_loss: 37.1302 - ssim_loss: 0.6371 - val_loss: 807.6901 - val_reconstruction_loss: 771.7687 - val_kl_loss: 24.2926 - val_ssim_loss: 0.5179\n",
      "Epoch 117/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 422.3047 - reconstruction_loss: 373.9171 - kl_loss: 37.2407 - ssim_loss: 0.6395 - val_loss: 805.6840 - val_reconstruction_loss: 769.6154 - val_kl_loss: 24.3916 - val_ssim_loss: 0.5190\n",
      "Epoch 118/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 377.6887 - reconstruction_loss: 372.1413 - kl_loss: 37.5463 - ssim_loss: 0.6423 - val_loss: 803.8347 - val_reconstruction_loss: 767.6187 - val_kl_loss: 24.4906 - val_ssim_loss: 0.5201\n",
      "Epoch 119/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 465.1409 - reconstruction_loss: 370.5943 - kl_loss: 37.7501 - ssim_loss: 0.6441 - val_loss: 801.9393 - val_reconstruction_loss: 765.5767 - val_kl_loss: 24.5890 - val_ssim_loss: 0.5211\n",
      "Epoch 120/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 451.5143 - reconstruction_loss: 370.8652 - kl_loss: 37.7321 - ssim_loss: 0.6444 - val_loss: 800.1355 - val_reconstruction_loss: 763.6263 - val_kl_loss: 24.6874 - val_ssim_loss: 0.5221\n",
      "Epoch 121/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 475.9145 - reconstruction_loss: 382.2936 - kl_loss: 37.7758 - ssim_loss: 0.6376 - val_loss: 798.3317 - val_reconstruction_loss: 761.6811 - val_kl_loss: 24.7823 - val_ssim_loss: 0.5231\n",
      "Epoch 122/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 426.6251 - reconstruction_loss: 380.8243 - kl_loss: 37.4716 - ssim_loss: 0.6404 - val_loss: 796.5020 - val_reconstruction_loss: 759.7165 - val_kl_loss: 24.8730 - val_ssim_loss: 0.5242\n",
      "Epoch 123/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 369.1965 - reconstruction_loss: 371.5417 - kl_loss: 37.4129 - ssim_loss: 0.6443 - val_loss: 794.8051 - val_reconstruction_loss: 757.8861 - val_kl_loss: 24.9627 - val_ssim_loss: 0.5252\n",
      "Epoch 124/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 417.5419 - reconstruction_loss: 378.6608 - kl_loss: 37.2714 - ssim_loss: 0.6409 - val_loss: 792.9980 - val_reconstruction_loss: 755.9487 - val_kl_loss: 25.0503 - val_ssim_loss: 0.5262\n",
      "Epoch 125/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 468.9890 - reconstruction_loss: 368.9264 - kl_loss: 37.4276 - ssim_loss: 0.6453 - val_loss: 791.1846 - val_reconstruction_loss: 754.0039 - val_kl_loss: 25.1385 - val_ssim_loss: 0.5273\n",
      "Epoch 126/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 400.6639 - reconstruction_loss: 365.5432 - kl_loss: 37.5191 - ssim_loss: 0.6464 - val_loss: 789.3824 - val_reconstruction_loss: 752.0717 - val_kl_loss: 25.2259 - val_ssim_loss: 0.5283\n",
      "Epoch 127/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 407.2318 - reconstruction_loss: 362.0583 - kl_loss: 37.6792 - ssim_loss: 0.6463 - val_loss: 787.6407 - val_reconstruction_loss: 750.1982 - val_kl_loss: 25.3144 - val_ssim_loss: 0.5293\n",
      "Epoch 128/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 398.6167 - reconstruction_loss: 360.6980 - kl_loss: 38.0456 - ssim_loss: 0.6491 - val_loss: 785.9235 - val_reconstruction_loss: 748.3492 - val_kl_loss: 25.4029 - val_ssim_loss: 0.5303\n",
      "Epoch 129/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 399.3180 - reconstruction_loss: 359.7568 - kl_loss: 38.0089 - ssim_loss: 0.6519 - val_loss: 784.1909 - val_reconstruction_loss: 746.4878 - val_kl_loss: 25.4895 - val_ssim_loss: 0.5313\n",
      "Epoch 130/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 421.4658 - reconstruction_loss: 359.2380 - kl_loss: 38.0235 - ssim_loss: 0.6483 - val_loss: 782.4607 - val_reconstruction_loss: 744.6283 - val_kl_loss: 25.5763 - val_ssim_loss: 0.5322\n",
      "Epoch 131/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 427.9250 - reconstruction_loss: 358.9387 - kl_loss: 38.1921 - ssim_loss: 0.6530 - val_loss: 780.7758 - val_reconstruction_loss: 742.8156 - val_kl_loss: 25.6621 - val_ssim_loss: 0.5332\n",
      "Epoch 132/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 421.8704 - reconstruction_loss: 363.1929 - kl_loss: 38.2462 - ssim_loss: 0.6495 - val_loss: 779.1805 - val_reconstruction_loss: 741.0953 - val_kl_loss: 25.7461 - val_ssim_loss: 0.5341\n",
      "Epoch 133/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 381.9881 - reconstruction_loss: 370.1089 - kl_loss: 38.2103 - ssim_loss: 0.6499 - val_loss: 777.9065 - val_reconstruction_loss: 739.6981 - val_kl_loss: 25.8289 - val_ssim_loss: 0.5351\n",
      "Epoch 134/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 421.3499 - reconstruction_loss: 370.9721 - kl_loss: 38.1153 - ssim_loss: 0.6456 - val_loss: 776.3975 - val_reconstruction_loss: 738.0687 - val_kl_loss: 25.9098 - val_ssim_loss: 0.5360\n",
      "Epoch 135/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 386.9501 - reconstruction_loss: 364.4961 - kl_loss: 38.0052 - ssim_loss: 0.6482 - val_loss: 774.8469 - val_reconstruction_loss: 736.4010 - val_kl_loss: 25.9884 - val_ssim_loss: 0.5369\n",
      "Epoch 136/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 421.9214 - reconstruction_loss: 356.3404 - kl_loss: 38.0217 - ssim_loss: 0.6511 - val_loss: 773.2509 - val_reconstruction_loss: 734.6855 - val_kl_loss: 26.0687 - val_ssim_loss: 0.5378\n",
      "Epoch 137/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 419.4220 - reconstruction_loss: 352.8257 - kl_loss: 38.3671 - ssim_loss: 0.6544 - val_loss: 771.6489 - val_reconstruction_loss: 732.9628 - val_kl_loss: 26.1498 - val_ssim_loss: 0.5387\n",
      "Epoch 138/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 438.0525 - reconstruction_loss: 350.5580 - kl_loss: 38.5793 - ssim_loss: 0.6549 - val_loss: 770.0733 - val_reconstruction_loss: 731.2657 - val_kl_loss: 26.2314 - val_ssim_loss: 0.5396\n",
      "Epoch 139/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 395.3632 - reconstruction_loss: 347.4135 - kl_loss: 39.0802 - ssim_loss: 0.6551 - val_loss: 768.5221 - val_reconstruction_loss: 729.5893 - val_kl_loss: 26.3154 - val_ssim_loss: 0.5405\n",
      "Epoch 140/300\n",
      "15/15 [==============================] - 74s 5s/step - loss: 404.4530 - reconstruction_loss: 344.5605 - kl_loss: 39.3017 - ssim_loss: 0.6578 - val_loss: 766.9947 - val_reconstruction_loss: 727.9397 - val_kl_loss: 26.3975 - val_ssim_loss: 0.5413\n",
      "Epoch 141/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 393.9880 - reconstruction_loss: 347.1460 - kl_loss: 39.1381 - ssim_loss: 0.6567 - val_loss: 765.4787 - val_reconstruction_loss: 726.3029 - val_kl_loss: 26.4787 - val_ssim_loss: 0.5422\n",
      "Epoch 142/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 396.1452 - reconstruction_loss: 346.3059 - kl_loss: 39.2535 - ssim_loss: 0.6581 - val_loss: 763.9404 - val_reconstruction_loss: 724.6431 - val_kl_loss: 26.5603 - val_ssim_loss: 0.5431\n",
      "Epoch 143/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 405.8756 - reconstruction_loss: 344.8127 - kl_loss: 39.4408 - ssim_loss: 0.6584 - val_loss: 762.4482 - val_reconstruction_loss: 723.0301 - val_kl_loss: 26.6414 - val_ssim_loss: 0.5439\n",
      "Epoch 144/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 461.5373 - reconstruction_loss: 349.8781 - kl_loss: 39.4606 - ssim_loss: 0.6600 - val_loss: 760.9790 - val_reconstruction_loss: 721.4424 - val_kl_loss: 26.7210 - val_ssim_loss: 0.5448\n",
      "Epoch 145/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 398.1891 - reconstruction_loss: 344.9966 - kl_loss: 39.5085 - ssim_loss: 0.6600 - val_loss: 759.5729 - val_reconstruction_loss: 719.9197 - val_kl_loss: 26.7993 - val_ssim_loss: 0.5456\n",
      "Epoch 146/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 396.6998 - reconstruction_loss: 347.7036 - kl_loss: 39.3765 - ssim_loss: 0.6616 - val_loss: 758.1202 - val_reconstruction_loss: 718.3517 - val_kl_loss: 26.8767 - val_ssim_loss: 0.5465\n",
      "Epoch 147/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 393.6562 - reconstruction_loss: 346.1784 - kl_loss: 39.3844 - ssim_loss: 0.6588 - val_loss: 756.7053 - val_reconstruction_loss: 716.8239 - val_kl_loss: 26.9526 - val_ssim_loss: 0.5473\n",
      "Epoch 148/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 392.9131 - reconstruction_loss: 344.7793 - kl_loss: 39.2118 - ssim_loss: 0.6612 - val_loss: 755.2907 - val_reconstruction_loss: 715.3003 - val_kl_loss: 27.0258 - val_ssim_loss: 0.5481\n",
      "Epoch 149/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 423.2340 - reconstruction_loss: 343.1120 - kl_loss: 38.9873 - ssim_loss: 0.6613 - val_loss: 753.8705 - val_reconstruction_loss: 713.7725 - val_kl_loss: 27.0981 - val_ssim_loss: 0.5490\n",
      "Epoch 150/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 380.4056 - reconstruction_loss: 337.3642 - kl_loss: 39.2627 - ssim_loss: 0.6651 - val_loss: 752.4459 - val_reconstruction_loss: 712.2382 - val_kl_loss: 27.1718 - val_ssim_loss: 0.5498\n",
      "Epoch 151/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 437.1717 - reconstruction_loss: 336.5459 - kl_loss: 39.5807 - ssim_loss: 0.6663 - val_loss: 751.0449 - val_reconstruction_loss: 710.7261 - val_kl_loss: 27.2463 - val_ssim_loss: 0.5506\n",
      "Epoch 152/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 379.6237 - reconstruction_loss: 337.1205 - kl_loss: 39.7342 - ssim_loss: 0.6634 - val_loss: 749.7189 - val_reconstruction_loss: 709.2908 - val_kl_loss: 27.3197 - val_ssim_loss: 0.5514\n",
      "Epoch 153/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 393.0125 - reconstruction_loss: 335.7779 - kl_loss: 39.6542 - ssim_loss: 0.6642 - val_loss: 748.3325 - val_reconstruction_loss: 707.7968 - val_kl_loss: 27.3920 - val_ssim_loss: 0.5522\n",
      "Epoch 154/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 401.9869 - reconstruction_loss: 334.2131 - kl_loss: 39.6643 - ssim_loss: 0.6676 - val_loss: 746.9921 - val_reconstruction_loss: 706.3479 - val_kl_loss: 27.4648 - val_ssim_loss: 0.5530\n",
      "Epoch 155/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 397.2644 - reconstruction_loss: 332.6591 - kl_loss: 39.9225 - ssim_loss: 0.6674 - val_loss: 745.6647 - val_reconstruction_loss: 704.9111 - val_kl_loss: 27.5383 - val_ssim_loss: 0.5537\n",
      "Epoch 156/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 408.1411 - reconstruction_loss: 330.6490 - kl_loss: 40.2039 - ssim_loss: 0.6691 - val_loss: 744.3451 - val_reconstruction_loss: 703.4817 - val_kl_loss: 27.6120 - val_ssim_loss: 0.5545\n",
      "Epoch 157/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 398.1290 - reconstruction_loss: 340.8471 - kl_loss: 40.2387 - ssim_loss: 0.6651 - val_loss: 743.1696 - val_reconstruction_loss: 702.2002 - val_kl_loss: 27.6832 - val_ssim_loss: 0.5553\n",
      "Epoch 158/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 440.9243 - reconstruction_loss: 347.0959 - kl_loss: 40.0040 - ssim_loss: 0.6605 - val_loss: 741.8847 - val_reconstruction_loss: 700.8132 - val_kl_loss: 27.7517 - val_ssim_loss: 0.5561\n",
      "Epoch 159/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 422.3409 - reconstruction_loss: 333.5687 - kl_loss: 39.6153 - ssim_loss: 0.6661 - val_loss: 740.5838 - val_reconstruction_loss: 699.4122 - val_kl_loss: 27.8190 - val_ssim_loss: 0.5568\n",
      "Epoch 160/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 409.5841 - reconstruction_loss: 328.1083 - kl_loss: 39.7703 - ssim_loss: 0.6721 - val_loss: 739.2952 - val_reconstruction_loss: 698.0211 - val_kl_loss: 27.8879 - val_ssim_loss: 0.5576\n",
      "Epoch 161/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 374.9167 - reconstruction_loss: 325.6099 - kl_loss: 40.1903 - ssim_loss: 0.6699 - val_loss: 738.0228 - val_reconstruction_loss: 696.6449 - val_kl_loss: 27.9576 - val_ssim_loss: 0.5583\n",
      "Epoch 162/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 412.7861 - reconstruction_loss: 327.0069 - kl_loss: 40.3410 - ssim_loss: 0.6732 - val_loss: 736.7396 - val_reconstruction_loss: 695.2584 - val_kl_loss: 28.0270 - val_ssim_loss: 0.5591\n",
      "Epoch 163/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 370.9491 - reconstruction_loss: 325.2822 - kl_loss: 40.4935 - ssim_loss: 0.6712 - val_loss: 735.4823 - val_reconstruction_loss: 693.8979 - val_kl_loss: 28.0962 - val_ssim_loss: 0.5598\n",
      "Epoch 164/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 391.4532 - reconstruction_loss: 322.1647 - kl_loss: 40.5492 - ssim_loss: 0.6730 - val_loss: 734.2598 - val_reconstruction_loss: 692.5719 - val_kl_loss: 28.1657 - val_ssim_loss: 0.5606\n",
      "Epoch 165/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 383.6189 - reconstruction_loss: 322.6421 - kl_loss: 40.6704 - ssim_loss: 0.6759 - val_loss: 733.0403 - val_reconstruction_loss: 691.2499 - val_kl_loss: 28.2346 - val_ssim_loss: 0.5613\n",
      "Epoch 166/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 356.5921 - reconstruction_loss: 320.9599 - kl_loss: 40.6888 - ssim_loss: 0.6764 - val_loss: 731.8583 - val_reconstruction_loss: 689.9674 - val_kl_loss: 28.3021 - val_ssim_loss: 0.5620\n",
      "Epoch 167/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 390.4295 - reconstruction_loss: 324.1296 - kl_loss: 40.5505 - ssim_loss: 0.6720 - val_loss: 730.6471 - val_reconstruction_loss: 688.6573 - val_kl_loss: 28.3685 - val_ssim_loss: 0.5628\n",
      "Epoch 168/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 393.5745 - reconstruction_loss: 327.4472 - kl_loss: 40.6341 - ssim_loss: 0.6750 - val_loss: 729.5469 - val_reconstruction_loss: 687.4595 - val_kl_loss: 28.4341 - val_ssim_loss: 0.5635\n",
      "Epoch 169/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 340.9759 - reconstruction_loss: 325.5910 - kl_loss: 40.4979 - ssim_loss: 0.6730 - val_loss: 728.3795 - val_reconstruction_loss: 686.1956 - val_kl_loss: 28.4988 - val_ssim_loss: 0.5642\n",
      "Epoch 170/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 411.0453 - reconstruction_loss: 322.9250 - kl_loss: 40.5140 - ssim_loss: 0.6780 - val_loss: 727.1962 - val_reconstruction_loss: 684.9152 - val_kl_loss: 28.5640 - val_ssim_loss: 0.5649\n",
      "Epoch 171/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 361.3223 - reconstruction_loss: 321.4891 - kl_loss: 40.7510 - ssim_loss: 0.6743 - val_loss: 726.0532 - val_reconstruction_loss: 683.6758 - val_kl_loss: 28.6286 - val_ssim_loss: 0.5655\n",
      "Epoch 172/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 367.7222 - reconstruction_loss: 323.6400 - kl_loss: 40.6217 - ssim_loss: 0.6768 - val_loss: 724.9671 - val_reconstruction_loss: 682.4938 - val_kl_loss: 28.6931 - val_ssim_loss: 0.5662\n",
      "Epoch 173/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 429.5653 - reconstruction_loss: 325.4042 - kl_loss: 40.5681 - ssim_loss: 0.6740 - val_loss: 723.8718 - val_reconstruction_loss: 681.3063 - val_kl_loss: 28.7549 - val_ssim_loss: 0.5668\n",
      "Epoch 174/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 332.9325 - reconstruction_loss: 318.2806 - kl_loss: 40.5191 - ssim_loss: 0.6762 - val_loss: 722.7256 - val_reconstruction_loss: 680.0682 - val_kl_loss: 28.8167 - val_ssim_loss: 0.5675\n",
      "Epoch 175/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 392.7079 - reconstruction_loss: 316.7365 - kl_loss: 40.6358 - ssim_loss: 0.6802 - val_loss: 721.5867 - val_reconstruction_loss: 678.8363 - val_kl_loss: 28.8791 - val_ssim_loss: 0.5682\n",
      "Epoch 176/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 372.7022 - reconstruction_loss: 313.5334 - kl_loss: 40.7767 - ssim_loss: 0.6799 - val_loss: 720.4493 - val_reconstruction_loss: 677.6066 - val_kl_loss: 28.9411 - val_ssim_loss: 0.5688\n",
      "Epoch 177/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 376.9475 - reconstruction_loss: 313.6380 - kl_loss: 40.9405 - ssim_loss: 0.6818 - val_loss: 719.3254 - val_reconstruction_loss: 676.3897 - val_kl_loss: 29.0036 - val_ssim_loss: 0.5695\n",
      "Epoch 178/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 413.6189 - reconstruction_loss: 311.1490 - kl_loss: 41.1136 - ssim_loss: 0.6823 - val_loss: 718.2118 - val_reconstruction_loss: 675.1824 - val_kl_loss: 29.0663 - val_ssim_loss: 0.5702\n",
      "Epoch 179/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 354.5741 - reconstruction_loss: 309.3993 - kl_loss: 41.3258 - ssim_loss: 0.6829 - val_loss: 717.1339 - val_reconstruction_loss: 674.0108 - val_kl_loss: 29.1293 - val_ssim_loss: 0.5708\n",
      "Epoch 180/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 346.2739 - reconstruction_loss: 313.5987 - kl_loss: 41.2509 - ssim_loss: 0.6825 - val_loss: 716.0286 - val_reconstruction_loss: 672.8141 - val_kl_loss: 29.1907 - val_ssim_loss: 0.5714\n",
      "Epoch 181/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 368.8768 - reconstruction_loss: 307.6552 - kl_loss: 41.3052 - ssim_loss: 0.6845 - val_loss: 714.9446 - val_reconstruction_loss: 671.6382 - val_kl_loss: 29.2523 - val_ssim_loss: 0.5721\n",
      "Epoch 182/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 372.6393 - reconstruction_loss: 306.8414 - kl_loss: 41.4293 - ssim_loss: 0.6839 - val_loss: 713.8915 - val_reconstruction_loss: 670.4932 - val_kl_loss: 29.3140 - val_ssim_loss: 0.5727\n",
      "Epoch 183/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 394.9042 - reconstruction_loss: 311.7695 - kl_loss: 41.3360 - ssim_loss: 0.6854 - val_loss: 712.8528 - val_reconstruction_loss: 669.3660 - val_kl_loss: 29.3734 - val_ssim_loss: 0.5733\n",
      "Epoch 184/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 368.1182 - reconstruction_loss: 306.9562 - kl_loss: 41.3466 - ssim_loss: 0.6830 - val_loss: 711.8018 - val_reconstruction_loss: 668.2244 - val_kl_loss: 29.4342 - val_ssim_loss: 0.5739\n",
      "Epoch 185/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 346.9560 - reconstruction_loss: 306.6393 - kl_loss: 41.6476 - ssim_loss: 0.6882 - val_loss: 710.7690 - val_reconstruction_loss: 667.1010 - val_kl_loss: 29.4951 - val_ssim_loss: 0.5746\n",
      "Epoch 186/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 321.8181 - reconstruction_loss: 309.9514 - kl_loss: 41.6851 - ssim_loss: 0.6846 - val_loss: 709.7349 - val_reconstruction_loss: 665.9758 - val_kl_loss: 29.5561 - val_ssim_loss: 0.5752\n",
      "Epoch 187/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 388.7386 - reconstruction_loss: 317.7399 - kl_loss: 41.6774 - ssim_loss: 0.6847 - val_loss: 708.7365 - val_reconstruction_loss: 664.8915 - val_kl_loss: 29.6138 - val_ssim_loss: 0.5758\n",
      "Epoch 188/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 372.6111 - reconstruction_loss: 304.7787 - kl_loss: 41.3792 - ssim_loss: 0.6859 - val_loss: 707.7166 - val_reconstruction_loss: 663.7859 - val_kl_loss: 29.6714 - val_ssim_loss: 0.5764\n",
      "Epoch 189/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 350.1834 - reconstruction_loss: 301.2407 - kl_loss: 41.3308 - ssim_loss: 0.6916 - val_loss: 706.6763 - val_reconstruction_loss: 662.6626 - val_kl_loss: 29.7271 - val_ssim_loss: 0.5770\n",
      "Epoch 190/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 379.6006 - reconstruction_loss: 302.4914 - kl_loss: 41.1806 - ssim_loss: 0.6883 - val_loss: 705.6464 - val_reconstruction_loss: 661.5496 - val_kl_loss: 29.7830 - val_ssim_loss: 0.5776\n",
      "Epoch 191/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 404.5261 - reconstruction_loss: 302.7482 - kl_loss: 41.5067 - ssim_loss: 0.6906 - val_loss: 704.6445 - val_reconstruction_loss: 660.4626 - val_kl_loss: 29.8401 - val_ssim_loss: 0.5782\n",
      "Epoch 192/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 358.9256 - reconstruction_loss: 302.0779 - kl_loss: 41.7236 - ssim_loss: 0.6873 - val_loss: 703.7092 - val_reconstruction_loss: 659.4435 - val_kl_loss: 29.8964 - val_ssim_loss: 0.5788\n",
      "Epoch 193/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 363.1170 - reconstruction_loss: 303.4184 - kl_loss: 41.6211 - ssim_loss: 0.6914 - val_loss: 702.7358 - val_reconstruction_loss: 658.3884 - val_kl_loss: 29.9512 - val_ssim_loss: 0.5794\n",
      "Epoch 194/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 355.0692 - reconstruction_loss: 302.1117 - kl_loss: 41.5533 - ssim_loss: 0.6910 - val_loss: 701.8223 - val_reconstruction_loss: 657.3942 - val_kl_loss: 30.0055 - val_ssim_loss: 0.5799\n",
      "Epoch 195/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 418.2411 - reconstruction_loss: 329.3934 - kl_loss: 41.2367 - ssim_loss: 0.6829 - val_loss: 700.8972 - val_reconstruction_loss: 656.3938 - val_kl_loss: 30.0560 - val_ssim_loss: 0.5805\n",
      "Epoch 196/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 425.4853 - reconstruction_loss: 342.1075 - kl_loss: 40.4714 - ssim_loss: 0.6744 - val_loss: 699.9572 - val_reconstruction_loss: 655.3832 - val_kl_loss: 30.1034 - val_ssim_loss: 0.5810\n",
      "Epoch 197/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 414.9801 - reconstruction_loss: 326.7900 - kl_loss: 39.9714 - ssim_loss: 0.6818 - val_loss: 699.0583 - val_reconstruction_loss: 654.4157 - val_kl_loss: 30.1496 - val_ssim_loss: 0.5816\n",
      "Epoch 198/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 349.8317 - reconstruction_loss: 326.5140 - kl_loss: 39.6431 - ssim_loss: 0.6790 - val_loss: 698.1740 - val_reconstruction_loss: 653.4648 - val_kl_loss: 30.1943 - val_ssim_loss: 0.5821\n",
      "Epoch 199/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 410.6492 - reconstruction_loss: 328.4172 - kl_loss: 39.4016 - ssim_loss: 0.6760 - val_loss: 697.4548 - val_reconstruction_loss: 652.6824 - val_kl_loss: 30.2366 - val_ssim_loss: 0.5825\n",
      "Epoch 200/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 400.8558 - reconstruction_loss: 323.3866 - kl_loss: 39.5219 - ssim_loss: 0.6823 - val_loss: 696.5762 - val_reconstruction_loss: 651.7391 - val_kl_loss: 30.2800 - val_ssim_loss: 0.5830\n",
      "Epoch 201/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 384.4031 - reconstruction_loss: 301.6072 - kl_loss: 39.8640 - ssim_loss: 0.6922 - val_loss: 695.6491 - val_reconstruction_loss: 650.7452 - val_kl_loss: 30.3250 - val_ssim_loss: 0.5836\n",
      "Epoch 202/300\n",
      "15/15 [==============================] - 81s 6s/step - loss: 372.5146 - reconstruction_loss: 297.2674 - kl_loss: 40.1902 - ssim_loss: 0.6949 - val_loss: 694.7351 - val_reconstruction_loss: 649.7626 - val_kl_loss: 30.3711 - val_ssim_loss: 0.5841\n",
      "Epoch 203/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 381.7352 - reconstruction_loss: 293.1444 - kl_loss: 40.5943 - ssim_loss: 0.6961 - val_loss: 693.8111 - val_reconstruction_loss: 648.7674 - val_kl_loss: 30.4189 - val_ssim_loss: 0.5847\n",
      "Epoch 204/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 366.6119 - reconstruction_loss: 292.1189 - kl_loss: 41.0833 - ssim_loss: 0.6961 - val_loss: 692.8913 - val_reconstruction_loss: 647.7747 - val_kl_loss: 30.4679 - val_ssim_loss: 0.5852\n",
      "Epoch 205/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 372.7364 - reconstruction_loss: 290.4330 - kl_loss: 41.2149 - ssim_loss: 0.6970 - val_loss: 692.0020 - val_reconstruction_loss: 646.8126 - val_kl_loss: 30.5168 - val_ssim_loss: 0.5857\n",
      "Epoch 206/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 366.7786 - reconstruction_loss: 291.4520 - kl_loss: 41.4141 - ssim_loss: 0.6982 - val_loss: 691.0970 - val_reconstruction_loss: 645.8339 - val_kl_loss: 30.5663 - val_ssim_loss: 0.5863\n",
      "Epoch 207/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 335.8417 - reconstruction_loss: 289.3044 - kl_loss: 41.5311 - ssim_loss: 0.6979 - val_loss: 690.2020 - val_reconstruction_loss: 644.8656 - val_kl_loss: 30.6156 - val_ssim_loss: 0.5868\n",
      "Epoch 208/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 344.3301 - reconstruction_loss: 286.9929 - kl_loss: 41.6207 - ssim_loss: 0.6992 - val_loss: 689.3340 - val_reconstruction_loss: 643.9247 - val_kl_loss: 30.6646 - val_ssim_loss: 0.5873\n",
      "Epoch 209/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 349.8577 - reconstruction_loss: 287.9936 - kl_loss: 41.6299 - ssim_loss: 0.6978 - val_loss: 688.4598 - val_reconstruction_loss: 642.9771 - val_kl_loss: 30.7138 - val_ssim_loss: 0.5879\n",
      "Epoch 210/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 363.9923 - reconstruction_loss: 287.0367 - kl_loss: 41.8557 - ssim_loss: 0.7030 - val_loss: 687.5781 - val_reconstruction_loss: 642.0222 - val_kl_loss: 30.7630 - val_ssim_loss: 0.5884\n",
      "Epoch 211/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 330.0227 - reconstruction_loss: 287.4915 - kl_loss: 41.9330 - ssim_loss: 0.7021 - val_loss: 686.7089 - val_reconstruction_loss: 641.0793 - val_kl_loss: 30.8124 - val_ssim_loss: 0.5889\n",
      "Epoch 212/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 357.3285 - reconstruction_loss: 291.7142 - kl_loss: 41.9011 - ssim_loss: 0.6968 - val_loss: 685.8644 - val_reconstruction_loss: 640.1635 - val_kl_loss: 30.8604 - val_ssim_loss: 0.5894\n",
      "Epoch 213/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 379.7575 - reconstruction_loss: 289.4416 - kl_loss: 41.6824 - ssim_loss: 0.7008 - val_loss: 684.9977 - val_reconstruction_loss: 639.2271 - val_kl_loss: 30.9072 - val_ssim_loss: 0.5899\n",
      "Epoch 214/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 359.6451 - reconstruction_loss: 290.2487 - kl_loss: 41.6237 - ssim_loss: 0.6988 - val_loss: 684.1900 - val_reconstruction_loss: 638.3504 - val_kl_loss: 30.9535 - val_ssim_loss: 0.5904\n",
      "Epoch 215/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 366.5226 - reconstruction_loss: 290.9073 - kl_loss: 41.7131 - ssim_loss: 0.7001 - val_loss: 683.3840 - val_reconstruction_loss: 637.4766 - val_kl_loss: 30.9991 - val_ssim_loss: 0.5909\n",
      "Epoch 216/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 349.9110 - reconstruction_loss: 290.5248 - kl_loss: 41.6504 - ssim_loss: 0.6990 - val_loss: 682.5556 - val_reconstruction_loss: 636.5793 - val_kl_loss: 31.0453 - val_ssim_loss: 0.5914\n",
      "Epoch 217/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 371.6514 - reconstruction_loss: 287.5660 - kl_loss: 41.7972 - ssim_loss: 0.7016 - val_loss: 681.7451 - val_reconstruction_loss: 635.6992 - val_kl_loss: 31.0920 - val_ssim_loss: 0.5919\n",
      "Epoch 218/300\n",
      "15/15 [==============================] - 82s 5s/step - loss: 344.8630 - reconstruction_loss: 283.0126 - kl_loss: 41.9917 - ssim_loss: 0.7011 - val_loss: 680.9350 - val_reconstruction_loss: 634.8204 - val_kl_loss: 31.1382 - val_ssim_loss: 0.5924\n",
      "Epoch 219/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 333.5779 - reconstruction_loss: 280.9272 - kl_loss: 41.9329 - ssim_loss: 0.7042 - val_loss: 680.1294 - val_reconstruction_loss: 633.9463 - val_kl_loss: 31.1842 - val_ssim_loss: 0.5929\n",
      "Epoch 220/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 361.3641 - reconstruction_loss: 280.0317 - kl_loss: 41.9404 - ssim_loss: 0.7047 - val_loss: 679.3024 - val_reconstruction_loss: 633.0511 - val_kl_loss: 31.2299 - val_ssim_loss: 0.5934\n",
      "Epoch 221/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 314.0222 - reconstruction_loss: 279.4354 - kl_loss: 42.1306 - ssim_loss: 0.7056 - val_loss: 678.5114 - val_reconstruction_loss: 632.1912 - val_kl_loss: 31.2761 - val_ssim_loss: 0.5939\n",
      "Epoch 222/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 376.3850 - reconstruction_loss: 280.5867 - kl_loss: 42.1888 - ssim_loss: 0.7075 - val_loss: 677.7046 - val_reconstruction_loss: 631.3157 - val_kl_loss: 31.3223 - val_ssim_loss: 0.5944\n",
      "Epoch 223/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 343.3662 - reconstruction_loss: 281.2147 - kl_loss: 42.2232 - ssim_loss: 0.7041 - val_loss: 676.8994 - val_reconstruction_loss: 630.4434 - val_kl_loss: 31.3673 - val_ssim_loss: 0.5949\n",
      "Epoch 224/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 380.9127 - reconstruction_loss: 280.5997 - kl_loss: 42.0628 - ssim_loss: 0.7048 - val_loss: 676.1043 - val_reconstruction_loss: 629.5830 - val_kl_loss: 31.4112 - val_ssim_loss: 0.5954\n",
      "Epoch 225/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 359.6592 - reconstruction_loss: 280.0500 - kl_loss: 42.1226 - ssim_loss: 0.7057 - val_loss: 675.3309 - val_reconstruction_loss: 628.7432 - val_kl_loss: 31.4557 - val_ssim_loss: 0.5958\n",
      "Epoch 226/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 318.3709 - reconstruction_loss: 280.5078 - kl_loss: 42.0938 - ssim_loss: 0.7062 - val_loss: 674.5445 - val_reconstruction_loss: 627.8913 - val_kl_loss: 31.4997 - val_ssim_loss: 0.5963\n",
      "Epoch 227/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 347.8098 - reconstruction_loss: 280.9023 - kl_loss: 42.0107 - ssim_loss: 0.7055 - val_loss: 673.8411 - val_reconstruction_loss: 627.1239 - val_kl_loss: 31.5426 - val_ssim_loss: 0.5967\n",
      "Epoch 228/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 345.4197 - reconstruction_loss: 283.8083 - kl_loss: 41.8217 - ssim_loss: 0.7070 - val_loss: 673.0848 - val_reconstruction_loss: 626.3049 - val_kl_loss: 31.5847 - val_ssim_loss: 0.5972\n",
      "Epoch 229/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 365.1725 - reconstruction_loss: 281.2889 - kl_loss: 41.7120 - ssim_loss: 0.7056 - val_loss: 672.3486 - val_reconstruction_loss: 625.5079 - val_kl_loss: 31.6256 - val_ssim_loss: 0.5977\n",
      "Epoch 230/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 370.9399 - reconstruction_loss: 281.2515 - kl_loss: 41.6951 - ssim_loss: 0.7068 - val_loss: 671.6021 - val_reconstruction_loss: 624.6992 - val_kl_loss: 31.6673 - val_ssim_loss: 0.5981\n",
      "Epoch 231/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 355.6055 - reconstruction_loss: 286.7329 - kl_loss: 41.9988 - ssim_loss: 0.7042 - val_loss: 670.8580 - val_reconstruction_loss: 623.8929 - val_kl_loss: 31.7090 - val_ssim_loss: 0.5985\n",
      "Epoch 232/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 383.6140 - reconstruction_loss: 278.2105 - kl_loss: 41.8061 - ssim_loss: 0.7070 - val_loss: 670.1270 - val_reconstruction_loss: 623.1010 - val_kl_loss: 31.7500 - val_ssim_loss: 0.5990\n",
      "Epoch 233/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 325.9943 - reconstruction_loss: 276.2884 - kl_loss: 42.1127 - ssim_loss: 0.7111 - val_loss: 669.3961 - val_reconstruction_loss: 622.3076 - val_kl_loss: 31.7919 - val_ssim_loss: 0.5995\n",
      "Epoch 234/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 358.9983 - reconstruction_loss: 285.8523 - kl_loss: 41.9030 - ssim_loss: 0.7087 - val_loss: 668.6863 - val_reconstruction_loss: 621.5377 - val_kl_loss: 31.8324 - val_ssim_loss: 0.5999\n",
      "Epoch 235/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 361.3333 - reconstruction_loss: 291.4160 - kl_loss: 41.7064 - ssim_loss: 0.6996 - val_loss: 668.0024 - val_reconstruction_loss: 620.7947 - val_kl_loss: 31.8721 - val_ssim_loss: 0.6003\n",
      "Epoch 236/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 370.2429 - reconstruction_loss: 290.2690 - kl_loss: 41.2916 - ssim_loss: 0.7020 - val_loss: 667.3086 - val_reconstruction_loss: 620.0456 - val_kl_loss: 31.9091 - val_ssim_loss: 0.6007\n",
      "Epoch 237/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 352.4254 - reconstruction_loss: 280.7496 - kl_loss: 41.2075 - ssim_loss: 0.7077 - val_loss: 666.6331 - val_reconstruction_loss: 619.3123 - val_kl_loss: 31.9480 - val_ssim_loss: 0.6011\n",
      "Epoch 238/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 357.3150 - reconstruction_loss: 277.9935 - kl_loss: 41.6700 - ssim_loss: 0.7122 - val_loss: 665.9689 - val_reconstruction_loss: 618.5885 - val_kl_loss: 31.9881 - val_ssim_loss: 0.6015\n",
      "Epoch 239/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 343.9859 - reconstruction_loss: 278.7750 - kl_loss: 41.8639 - ssim_loss: 0.7066 - val_loss: 665.3066 - val_reconstruction_loss: 617.8679 - val_kl_loss: 32.0270 - val_ssim_loss: 0.6019\n",
      "Epoch 240/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 294.3320 - reconstruction_loss: 275.7723 - kl_loss: 41.8582 - ssim_loss: 0.7096 - val_loss: 664.6173 - val_reconstruction_loss: 617.1221 - val_kl_loss: 32.0651 - val_ssim_loss: 0.6023\n",
      "Epoch 241/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 342.2954 - reconstruction_loss: 271.7247 - kl_loss: 41.7483 - ssim_loss: 0.7138 - val_loss: 663.9152 - val_reconstruction_loss: 616.3639 - val_kl_loss: 32.1027 - val_ssim_loss: 0.6028\n",
      "Epoch 242/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 327.3608 - reconstruction_loss: 269.9489 - kl_loss: 41.9340 - ssim_loss: 0.7125 - val_loss: 663.2089 - val_reconstruction_loss: 615.6000 - val_kl_loss: 32.1415 - val_ssim_loss: 0.6032\n",
      "Epoch 243/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 313.9316 - reconstruction_loss: 269.3324 - kl_loss: 42.1663 - ssim_loss: 0.7140 - val_loss: 662.5259 - val_reconstruction_loss: 614.8588 - val_kl_loss: 32.1806 - val_ssim_loss: 0.6036\n",
      "Epoch 244/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 326.1505 - reconstruction_loss: 268.7800 - kl_loss: 42.1932 - ssim_loss: 0.7159 - val_loss: 661.8386 - val_reconstruction_loss: 614.1135 - val_kl_loss: 32.2195 - val_ssim_loss: 0.6040\n",
      "Epoch 245/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 339.8295 - reconstruction_loss: 264.8466 - kl_loss: 42.4740 - ssim_loss: 0.7159 - val_loss: 661.1357 - val_reconstruction_loss: 613.3509 - val_kl_loss: 32.2596 - val_ssim_loss: 0.6045\n",
      "Epoch 246/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 332.3973 - reconstruction_loss: 263.9700 - kl_loss: 42.6716 - ssim_loss: 0.7173 - val_loss: 660.4496 - val_reconstruction_loss: 612.6055 - val_kl_loss: 32.2995 - val_ssim_loss: 0.6049\n",
      "Epoch 247/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 326.4648 - reconstruction_loss: 265.7530 - kl_loss: 42.6550 - ssim_loss: 0.7179 - val_loss: 659.7582 - val_reconstruction_loss: 611.8562 - val_kl_loss: 32.3383 - val_ssim_loss: 0.6053\n",
      "Epoch 248/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 334.8333 - reconstruction_loss: 264.6786 - kl_loss: 42.4939 - ssim_loss: 0.7183 - val_loss: 659.0793 - val_reconstruction_loss: 611.1194 - val_kl_loss: 32.3772 - val_ssim_loss: 0.6057\n",
      "Epoch 249/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 347.8671 - reconstruction_loss: 268.6753 - kl_loss: 42.5040 - ssim_loss: 0.7168 - val_loss: 658.4263 - val_reconstruction_loss: 610.4077 - val_kl_loss: 32.4166 - val_ssim_loss: 0.6061\n",
      "Epoch 250/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 350.5832 - reconstruction_loss: 267.1777 - kl_loss: 42.6275 - ssim_loss: 0.7181 - val_loss: 657.7760 - val_reconstruction_loss: 609.7001 - val_kl_loss: 32.4551 - val_ssim_loss: 0.6065\n",
      "Epoch 251/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 311.7533 - reconstruction_loss: 265.1827 - kl_loss: 42.5594 - ssim_loss: 0.7155 - val_loss: 657.1346 - val_reconstruction_loss: 609.0030 - val_kl_loss: 32.4925 - val_ssim_loss: 0.6069\n",
      "Epoch 252/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 334.9434 - reconstruction_loss: 261.8023 - kl_loss: 42.4068 - ssim_loss: 0.7214 - val_loss: 656.4764 - val_reconstruction_loss: 608.2896 - val_kl_loss: 32.5295 - val_ssim_loss: 0.6073\n",
      "Epoch 253/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 324.3078 - reconstruction_loss: 263.2954 - kl_loss: 42.2428 - ssim_loss: 0.7178 - val_loss: 655.8602 - val_reconstruction_loss: 607.6178 - val_kl_loss: 32.5668 - val_ssim_loss: 0.6077\n",
      "Epoch 254/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 333.8904 - reconstruction_loss: 270.1591 - kl_loss: 42.0819 - ssim_loss: 0.7167 - val_loss: 655.2509 - val_reconstruction_loss: 606.9565 - val_kl_loss: 32.6018 - val_ssim_loss: 0.6081\n",
      "Epoch 255/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 319.1655 - reconstruction_loss: 265.2573 - kl_loss: 42.0594 - ssim_loss: 0.7167 - val_loss: 654.5876 - val_reconstruction_loss: 606.2405 - val_kl_loss: 32.6371 - val_ssim_loss: 0.6085\n",
      "Epoch 256/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 299.8008 - reconstruction_loss: 261.3658 - kl_loss: 42.2809 - ssim_loss: 0.7214 - val_loss: 653.9545 - val_reconstruction_loss: 605.5549 - val_kl_loss: 32.6724 - val_ssim_loss: 0.6089\n",
      "Epoch 257/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 359.6894 - reconstruction_loss: 263.6577 - kl_loss: 42.2519 - ssim_loss: 0.7207 - val_loss: 653.3351 - val_reconstruction_loss: 604.8837 - val_kl_loss: 32.7072 - val_ssim_loss: 0.6093\n",
      "Epoch 258/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 319.1561 - reconstruction_loss: 259.4821 - kl_loss: 42.2849 - ssim_loss: 0.7211 - val_loss: 652.7020 - val_reconstruction_loss: 604.1984 - val_kl_loss: 32.7423 - val_ssim_loss: 0.6097\n",
      "Epoch 259/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 318.1086 - reconstruction_loss: 258.2817 - kl_loss: 42.3439 - ssim_loss: 0.7216 - val_loss: 652.0865 - val_reconstruction_loss: 603.5294 - val_kl_loss: 32.7782 - val_ssim_loss: 0.6101\n",
      "Epoch 260/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 328.2170 - reconstruction_loss: 257.9359 - kl_loss: 42.5742 - ssim_loss: 0.7220 - val_loss: 651.4590 - val_reconstruction_loss: 602.8486 - val_kl_loss: 32.8140 - val_ssim_loss: 0.6105\n",
      "Epoch 261/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 312.3219 - reconstruction_loss: 256.4569 - kl_loss: 42.6208 - ssim_loss: 0.7240 - val_loss: 650.8585 - val_reconstruction_loss: 602.1951 - val_kl_loss: 32.8496 - val_ssim_loss: 0.6108\n",
      "Epoch 262/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 322.1074 - reconstruction_loss: 255.4182 - kl_loss: 42.7023 - ssim_loss: 0.7250 - val_loss: 650.2411 - val_reconstruction_loss: 601.5247 - val_kl_loss: 32.8852 - val_ssim_loss: 0.6112\n",
      "Epoch 263/300\n",
      "15/15 [==============================] - 76s 5s/step - loss: 328.1099 - reconstruction_loss: 257.4505 - kl_loss: 42.6065 - ssim_loss: 0.7251 - val_loss: 649.6613 - val_reconstruction_loss: 600.8932 - val_kl_loss: 32.9199 - val_ssim_loss: 0.6116\n",
      "Epoch 264/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 333.8739 - reconstruction_loss: 257.6080 - kl_loss: 42.5163 - ssim_loss: 0.7235 - val_loss: 649.0492 - val_reconstruction_loss: 600.2286 - val_kl_loss: 32.9551 - val_ssim_loss: 0.6120\n",
      "Epoch 265/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 306.4578 - reconstruction_loss: 254.8138 - kl_loss: 42.8558 - ssim_loss: 0.7244 - val_loss: 648.4567 - val_reconstruction_loss: 599.5828 - val_kl_loss: 32.9910 - val_ssim_loss: 0.6123\n",
      "Epoch 266/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 324.1360 - reconstruction_loss: 254.7707 - kl_loss: 42.9122 - ssim_loss: 0.7255 - val_loss: 647.8594 - val_reconstruction_loss: 598.9341 - val_kl_loss: 33.0255 - val_ssim_loss: 0.6127\n",
      "Epoch 267/300\n",
      "15/15 [==============================] - 77s 5s/step - loss: 331.9582 - reconstruction_loss: 254.2823 - kl_loss: 42.9108 - ssim_loss: 0.7261 - val_loss: 647.2630 - val_reconstruction_loss: 598.2842 - val_kl_loss: 33.0613 - val_ssim_loss: 0.6131\n",
      "Epoch 268/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 302.7813 - reconstruction_loss: 253.1303 - kl_loss: 42.9573 - ssim_loss: 0.7282 - val_loss: 646.6926 - val_reconstruction_loss: 597.6625 - val_kl_loss: 33.0959 - val_ssim_loss: 0.6134\n",
      "Epoch 269/300\n",
      "15/15 [==============================] - 78s 5s/step - loss: 313.8006 - reconstruction_loss: 254.4300 - kl_loss: 42.7151 - ssim_loss: 0.7244 - val_loss: 646.1112 - val_reconstruction_loss: 597.0316 - val_kl_loss: 33.1291 - val_ssim_loss: 0.6138\n",
      "Epoch 270/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 351.4416 - reconstruction_loss: 256.0055 - kl_loss: 42.4899 - ssim_loss: 0.7264 - val_loss: 645.5618 - val_reconstruction_loss: 596.4329 - val_kl_loss: 33.1622 - val_ssim_loss: 0.6142\n",
      "Epoch 271/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 312.8900 - reconstruction_loss: 256.7706 - kl_loss: 42.7068 - ssim_loss: 0.7252 - val_loss: 644.9931 - val_reconstruction_loss: 595.8138 - val_kl_loss: 33.1960 - val_ssim_loss: 0.6145\n",
      "Epoch 272/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 320.1321 - reconstruction_loss: 251.7699 - kl_loss: 42.8875 - ssim_loss: 0.7286 - val_loss: 644.4052 - val_reconstruction_loss: 595.1749 - val_kl_loss: 33.2302 - val_ssim_loss: 0.6149\n",
      "Epoch 273/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 301.8079 - reconstruction_loss: 253.0305 - kl_loss: 42.8145 - ssim_loss: 0.7271 - val_loss: 643.8273 - val_reconstruction_loss: 594.5484 - val_kl_loss: 33.2630 - val_ssim_loss: 0.6152\n",
      "Epoch 274/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 341.7233 - reconstruction_loss: 252.3326 - kl_loss: 42.6231 - ssim_loss: 0.7302 - val_loss: 643.2504 - val_reconstruction_loss: 593.9227 - val_kl_loss: 33.2957 - val_ssim_loss: 0.6156\n",
      "Epoch 275/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 290.1618 - reconstruction_loss: 251.4453 - kl_loss: 42.8259 - ssim_loss: 0.7261 - val_loss: 642.6755 - val_reconstruction_loss: 593.2991 - val_kl_loss: 33.3284 - val_ssim_loss: 0.6159\n",
      "Epoch 276/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 308.6717 - reconstruction_loss: 250.1863 - kl_loss: 42.7336 - ssim_loss: 0.7315 - val_loss: 642.1306 - val_reconstruction_loss: 592.7059 - val_kl_loss: 33.3608 - val_ssim_loss: 0.6163\n",
      "Epoch 277/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 337.2350 - reconstruction_loss: 255.7566 - kl_loss: 42.7915 - ssim_loss: 0.7272 - val_loss: 641.6167 - val_reconstruction_loss: 592.1420 - val_kl_loss: 33.3944 - val_ssim_loss: 0.6166\n",
      "Epoch 278/300\n",
      "15/15 [==============================] - 80s 6s/step - loss: 345.9875 - reconstruction_loss: 255.2523 - kl_loss: 42.7776 - ssim_loss: 0.7270 - val_loss: 641.0892 - val_reconstruction_loss: 591.5693 - val_kl_loss: 33.4247 - val_ssim_loss: 0.6169\n",
      "Epoch 279/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 304.9684 - reconstruction_loss: 259.4186 - kl_loss: 42.3778 - ssim_loss: 0.7230 - val_loss: 640.5851 - val_reconstruction_loss: 591.0190 - val_kl_loss: 33.4558 - val_ssim_loss: 0.6172\n",
      "Epoch 280/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 325.6665 - reconstruction_loss: 255.9698 - kl_loss: 42.6286 - ssim_loss: 0.7292 - val_loss: 640.0552 - val_reconstruction_loss: 590.4449 - val_kl_loss: 33.4854 - val_ssim_loss: 0.6176\n",
      "Epoch 281/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 348.1281 - reconstruction_loss: 253.6426 - kl_loss: 42.0434 - ssim_loss: 0.7294 - val_loss: 639.5211 - val_reconstruction_loss: 589.8683 - val_kl_loss: 33.5140 - val_ssim_loss: 0.6179\n",
      "Epoch 282/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 332.6306 - reconstruction_loss: 252.0071 - kl_loss: 42.1394 - ssim_loss: 0.7287 - val_loss: 639.0168 - val_reconstruction_loss: 589.3209 - val_kl_loss: 33.5430 - val_ssim_loss: 0.6182\n",
      "Epoch 283/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 312.6295 - reconstruction_loss: 250.8142 - kl_loss: 42.3264 - ssim_loss: 0.7291 - val_loss: 638.4721 - val_reconstruction_loss: 588.7318 - val_kl_loss: 33.5728 - val_ssim_loss: 0.6186\n",
      "Epoch 284/300\n",
      "15/15 [==============================] - 81s 6s/step - loss: 344.5426 - reconstruction_loss: 248.8706 - kl_loss: 42.4847 - ssim_loss: 0.7319 - val_loss: 637.9376 - val_reconstruction_loss: 588.1534 - val_kl_loss: 33.6022 - val_ssim_loss: 0.6189\n",
      "Epoch 285/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 328.9620 - reconstruction_loss: 246.8655 - kl_loss: 42.4263 - ssim_loss: 0.7324 - val_loss: 637.4119 - val_reconstruction_loss: 587.5832 - val_kl_loss: 33.6321 - val_ssim_loss: 0.6192\n",
      "Epoch 286/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 290.4040 - reconstruction_loss: 245.0786 - kl_loss: 42.6604 - ssim_loss: 0.7327 - val_loss: 636.8814 - val_reconstruction_loss: 587.0076 - val_kl_loss: 33.6625 - val_ssim_loss: 0.6196\n",
      "Epoch 287/300\n",
      "15/15 [==============================] - 81s 5s/step - loss: 298.4281 - reconstruction_loss: 242.6132 - kl_loss: 42.7646 - ssim_loss: 0.7352 - val_loss: 636.3449 - val_reconstruction_loss: 586.4257 - val_kl_loss: 33.6930 - val_ssim_loss: 0.6199\n",
      "Epoch 288/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 336.0761 - reconstruction_loss: 245.1900 - kl_loss: 42.8031 - ssim_loss: 0.7345 - val_loss: 635.8246 - val_reconstruction_loss: 585.8599 - val_kl_loss: 33.7236 - val_ssim_loss: 0.6202\n",
      "Epoch 289/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 298.1324 - reconstruction_loss: 246.3516 - kl_loss: 43.0721 - ssim_loss: 0.7322 - val_loss: 635.3229 - val_reconstruction_loss: 585.3118 - val_kl_loss: 33.7546 - val_ssim_loss: 0.6205\n",
      "Epoch 290/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 321.6990 - reconstruction_loss: 260.4331 - kl_loss: 42.9955 - ssim_loss: 0.7281 - val_loss: 634.9454 - val_reconstruction_loss: 584.8908 - val_kl_loss: 33.7839 - val_ssim_loss: 0.6208\n",
      "Epoch 291/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 320.4631 - reconstruction_loss: 258.5941 - kl_loss: 42.5565 - ssim_loss: 0.7275 - val_loss: 634.4416 - val_reconstruction_loss: 584.3438 - val_kl_loss: 33.8128 - val_ssim_loss: 0.6211\n",
      "Epoch 292/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 310.5415 - reconstruction_loss: 257.2059 - kl_loss: 42.3414 - ssim_loss: 0.7339 - val_loss: 634.0096 - val_reconstruction_loss: 583.8718 - val_kl_loss: 33.8397 - val_ssim_loss: 0.6215\n",
      "Epoch 293/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 360.1492 - reconstruction_loss: 251.9516 - kl_loss: 42.1270 - ssim_loss: 0.7320 - val_loss: 633.5092 - val_reconstruction_loss: 583.3306 - val_kl_loss: 33.8671 - val_ssim_loss: 0.6218\n",
      "Epoch 294/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 320.1587 - reconstruction_loss: 250.5500 - kl_loss: 42.3528 - ssim_loss: 0.7293 - val_loss: 633.0391 - val_reconstruction_loss: 582.8182 - val_kl_loss: 33.8955 - val_ssim_loss: 0.6221\n",
      "Epoch 295/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 304.2801 - reconstruction_loss: 251.5836 - kl_loss: 42.4816 - ssim_loss: 0.7304 - val_loss: 632.5442 - val_reconstruction_loss: 582.2820 - val_kl_loss: 33.9232 - val_ssim_loss: 0.6224\n",
      "Epoch 296/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 300.7028 - reconstruction_loss: 243.4821 - kl_loss: 42.3423 - ssim_loss: 0.7344 - val_loss: 632.0455 - val_reconstruction_loss: 581.7427 - val_kl_loss: 33.9505 - val_ssim_loss: 0.6227\n",
      "Epoch 297/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 302.9397 - reconstruction_loss: 240.6256 - kl_loss: 42.3402 - ssim_loss: 0.7390 - val_loss: 631.5427 - val_reconstruction_loss: 581.1995 - val_kl_loss: 33.9777 - val_ssim_loss: 0.6230\n",
      "Epoch 298/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 325.1792 - reconstruction_loss: 240.7637 - kl_loss: 42.3653 - ssim_loss: 0.7374 - val_loss: 631.0423 - val_reconstruction_loss: 580.6583 - val_kl_loss: 34.0051 - val_ssim_loss: 0.6233\n",
      "Epoch 299/300\n",
      "15/15 [==============================] - 80s 5s/step - loss: 278.7853 - reconstruction_loss: 239.9524 - kl_loss: 42.4944 - ssim_loss: 0.7378 - val_loss: 630.5540 - val_reconstruction_loss: 580.1284 - val_kl_loss: 34.0330 - val_ssim_loss: 0.6236\n",
      "Epoch 300/300\n",
      "15/15 [==============================] - 79s 5s/step - loss: 304.8646 - reconstruction_loss: 238.3820 - kl_loss: 42.8289 - ssim_loss: 0.7392 - val_loss: 630.0731 - val_reconstruction_loss: 579.6050 - val_kl_loss: 34.0615 - val_ssim_loss: 0.6239\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "#callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001))\n",
    "history = vae.fit(train_dataset, epochs=300, validation_data=validation_dataset,callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Test Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VAE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38d41663-7274-4bdf-a9cf-91cda87ddfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 67ms/step\n",
      "2/2 [==============================] - 2s 1s/step\n",
      "(100, 200, 1)\n",
      "(100, 200)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAACmCAYAAAD+t3eaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB86ElEQVR4nO19e5RlVX3md1913496V3VDd/MSBgIYMbQoCMbGVsCoUdQOQdoYAYMYeSTRmSUNMSORzJrBKBoz40Di+AKT0UQDawGCCEFEhIAg2I0NNN1dXV2P+37fe+aPmm/f75y61d0F3V23uve3Vq2quvfcc/Y5d+/9/X7f77d/2+c4jgMLCwsLCwuLnoN/qRtgYWFhYWFh0R2WpC0sLCwsLHoUlqQtLCwsLCx6FJakLSwsLCwsehSWpC0sLCwsLHoUlqQtLCwsLCx6FJakLSwsLCwsehSWpC0sLCwsLHoUlqQtLCwsLCx6FJakD1Ncf/318Pl8r+izt912G3w+H1544YX92yjBCy+8AJ/Ph9tuu+2AXcPCwqL3sGbNGmzcuHGpm9EzsCS9DPH000/jD//wD7Fy5UqEw2GsWLECF110EZ5++umlbpqFxWGNrVu34uMf/zhe85rXIBaLIRaL4cQTT8QVV1yBJ598cqmbt9/wb//2b7j++uuXuhmHBXy2dvfywj//8z9jw4YNGBgYwEc+8hEcddRReOGFF/C1r30N09PT+Pa3v433vOc9ez1Ps9lEs9lEJBJZdBtarRYajQbC4fAr9sb3hhdeeAFHHXUUbr31VmtVWywL/OAHP8AHPvABBINBXHTRRTj11FPh9/vx7LPP4p//+Z/x4osvYuvWrVi9evVSN/VV4+Mf/zhuueUWHAj6WLNmDc455xyrov1/BJe6ARb7jueffx4XX3wxjj76aDzwwAMYHh427/3pn/4pzjrrLFx88cV48skncfTRR3c9R6lUQjweRzAYRDD4yr7+QCCAQCDwij5rYXEo4vnnn8cHP/hBrF69Gvfeey/Gx8dd73/+85/Hl7/8Zfj9vSlecl6w6D30Zo+x6Iq/+Zu/Qblcxt///d+7CBoAhoaG8NWvfhWlUgk33XQTgE7c+ZlnnsEf/MEfoL+/H2eeeabrPUWlUsEnPvEJDA0NIZlM4vd+7/ewfft2+Hw+l7TVLSa9Zs0aXHDBBXjwwQdx+umnIxKJ4Oijj8Y//uM/uq4xMzODa6+9FieffDISiQRSqRTe8Y534D/+4z/245OysDi4uOmmm1AqlXDrrbfOI2gACAaD+MQnPoEjjzzSvPbss8/ife97HwYGBhCJRPD6178e//Iv/+L6HMfaQw89hKuvvhrDw8OIx+N4z3veg927d8+7zp133omzzjoL8XgcyWQS559//rww2MaNG5FIJPD888/jvPPOQzKZxEUXXQQA+MlPfoILL7wQq1atQjgcxpFHHomrrroKlUrF9flbbrkFAODz+cwP0W63cfPNN+Okk05CJBLB6OgoLrvsMszOzrra4TgO/uqv/gpHHHEEYrEY3vKWt9iQXRdYT3oZ4V//9V+xZs0anHXWWV3ff/Ob34w1a9bghz/8oev1Cy+8EMcddxw+97nP7VGe2rhxI26//XZcfPHFeMMb3oAf//jHOP/88/e5fVu2bMH73vc+fOQjH8Ell1yC//2//zc2btyI0047DSeddBIA4De/+Q2+973v4cILL8RRRx2FXbt24atf/SrOPvtsPPPMM1ixYsU+X8/Colfwgx/8AMceeyzWrl27T8c//fTTeNOb3oSVK1fiU5/6FOLxOG6//Xa8+93vxj/90z/NC1ldeeWV6O/vx6ZNm/DCCy/g5ptvxsc//nF85zvfMcd8/etfxyWXXIL169fj85//PMrlMr7yla/gzDPPxOOPP441a9aYY5vNJtavX48zzzwT/+2//TfEYjEAwB133IFyuYyPfexjGBwcxM9+9jN88YtfxMsvv4w77rgDAHDZZZdhx44duPvuu/H1r3993r1ddtlluO222/DhD38Yn/jEJ7B161Z86UtfwuOPP46HHnoIoVAIAHDdddfhr/7qr3DeeefhvPPOwy9+8Qu87W1vQ71eX9SzP+ThWCwLZLNZB4Dzrne9a4/H/d7v/Z4DwMnn886mTZscAM6GDRvmHcf3iMcee8wB4Hzyk590Hbdx40YHgLNp0ybz2q233uoAcLZu3WpeW716tQPAeeCBB8xrk5OTTjgcdq655hrzWrVadVqtlusaW7dudcLhsPOXf/mXrtcAOLfeeuse79fCYqmRy+UcAM673/3uee/Nzs46u3fvNj/lctlxHMd561vf6px88slOtVo1x7bbbeeNb3yjc9xxx5nXONbWrVvntNtt8/pVV13lBAIBJ5vNOo7jOIVCwclkMs5HP/pR1/UnJiacdDrtev2SSy5xADif+tSn5rWX7VPceOONjs/nc1588UXz2hVXXOF0o4+f/OQnDgDnG9/4huv1u+66y/X65OSk09fX55x//vmu+/rP//k/OwCcSy65ZN65D1dYuXuZoFAoAACSyeQej+P7+XzevHb55Zfv9fx33XUXAOBP/uRPXK9feeWV+9zGE0880eXlDw8P4/jjj8dvfvMb81o4HDZxuVarhenpaSQSCRx//PH4xS9+sc/XsrDoFXCsJRKJee+dc845GB4eNj+33HILZmZm8KMf/Qjvf//7USgUMDU1hampKUxPT2P9+vXYvHkztm/f7jrPpZde6pKUzzrrLLRaLbz44osAgLvvvhvZbBYbNmww55uamkIgEMDatWtx3333zWvbxz72sXmvRaNR83epVMLU1BTe+MY3wnEcPP7443t9FnfccQfS6TTOPfdcVztOO+00JBIJ04577rkH9XodV155peu+PvnJT+71GocbrNy9TEDyJVkvhG5kftRRR+31/C+++CL8fv+8Y4899th9buOqVavmvdbf3++KRbXbbXzhC1/Al7/8ZWzduhWtVsu8Nzg4uM/XsrDoFXCsFYvFee999atfRaFQwK5du/CHf/iHAObCQo7j4DOf+Qw+85nPdD3n5OQkVq5caf73jq3+/n4AMGNr8+bNAIDf/d3f7Xq+VCrl+j8YDOKII46Yd9xLL72E6667Dv/yL/8yL4acy+W6nluxefNm5HI5jIyMdH1/cnISAIxxcdxxx7neHx4eNvdmMQdL0ssE6XQa4+Pje11r+eSTT2LlypWuQanW8YHEQhnfjsTBP/e5z+Ezn/kM/uiP/gif/exnMTAwAL/fj09+8pNot9sHpZ0WFvsTHJu//OUv573HGLUmWbKfX3vttVi/fn3Xc3qN472NLZ7z61//OsbGxuYd513JoYoW0Wq1cO6552JmZgZ/8Rd/gRNOOAHxeBzbt2/Hxo0b92l8ttttjIyM4Bvf+EbX970JrxZ7hyXpZYQLLrgA//N//k88+OCDJktb8ZOf/AQvvPACLrvsskWfe/Xq1Wi329i6davLut2yZcurarMX3/3ud/GWt7wFX/va11yvZ7NZDA0N7ddrWVgcLJx//vn4X//rf+FnP/sZTj/99D0ey+WRoVAI69at2y/XP+aYYwAAIyMjr/icTz31FH7961/jH/7hH/ChD33IvH733XfPO3ah+gjHHHMM7rnnHrzpTW/ao3PAteKbN292LRfdvXv3PA/+cIeNSS8j/Nmf/Rmi0Sguu+wyTE9Pu96bmZnB5Zdfjlgshj/7sz9b9Llp0X/5y192vf7FL37xlTe4CwKBwLwM8zvuuGNeDM7CYjnhz//8zxGLxfBHf/RH2LVr17z3tc+PjIzgnHPOwVe/+lXs3Llz3rHdllbtDevXr0cqlcLnPvc5NBqNV3ROeuvaVsdx8IUvfGHesVxTnc1mXa+///3vR6vVwmc/+9l5n2k2m+b4devWIRQK4Ytf/KLrejfffPNe23m4wXrSywjHHXcc/uEf/gEXXXQRTj755HkVx6ampvCtb33LWNWLwWmnnYb3vve9uPnmmzE9PW2WYP36178GsLDlvFhccMEF+Mu//Et8+MMfxhvf+EY89dRT+MY3vrFg8RULi+WA4447Dt/85jexYcMGHH/88abimOM42Lp1K775zW/C7/ebOPAtt9yCM888EyeffDI++tGP4uijj8auXbvw8MMP4+WXX1503YBUKoWvfOUruPjii/G6170OH/zgBzE8PIyXXnoJP/zhD/GmN70JX/rSl/Z4jhNOOAHHHHMMrr32Wmzfvh2pVAr/9E//1NWzPe200wAAn/jEJ7B+/XoEAgF88IMfxNlnn43LLrsMN954I5544gm87W1vQygUwubNm3HHHXfgC1/4At73vvdheHgY1157LW688UZccMEFOO+88/D444/jzjvvtIqaF0uVVm7xyvHkk086GzZscMbHx51QKOSMjY05GzZscJ566inXcVxmtXv37nnn8C7BchzHKZVKzhVXXOEMDAw4iUTCefe73+0899xzDgDnr//6r81xCy3BOv/88+dd5+yzz3bOPvts83+1WnWuueYaZ3x83IlGo86b3vQm5+GHH553nF2CZbEcsWXLFudjH/uYc+yxxzqRSMSJRqPOCSec4Fx++eXOE0884Tr2+eefdz70oQ85Y2NjTigUclauXOlccMEFzne/+11zDMfao48+6vrsfffd5wBw7rvvvnmvr1+/3kmn004kEnGOOeYYZ+PGjc7Pf/5zc8wll1zixOPxru1/5plnnHXr1jmJRMIZGhpyPvrRjzr/8R//MW8sNptN58orr3SGh4cdn883by75+7//e+e0005zotGok0wmnZNPPtn58z//c2fHjh3mmFar5dxwww1mLjjnnHOcX/7yl87q1avtEiyBrd1tsUc88cQT+O3f/m38n//zf0xVIgsLCwuLgwMbk7Yw0NJ/xM033wy/3483v/nNS9AiCwsLi8MbNiZtYXDTTTfhsccew1ve8hYEg0HceeeduPPOO3HppZe6ag5bWFhYWBwcWLnbwuDuu+/GDTfcgGeeeQbFYhGrVq3CxRdfjP/yX/7LK94xy8LCwsLileOAyd233HIL1qxZg0gkgrVr1+JnP/vZgbqUxX7CueeeiwcffBAzMzOo1+vYsmULNm3aZAn6MIYdxxYWS4sDQtLf+c53cPXVV2PTpk34xS9+gVNPPRXr1683JeEsLCx6H3YcW1gsPQ6I3L127Vr8zu/8jlmX1263ceSRR+LKK6/Epz71qf19OQsLiwMAO44tLJYe+13HrNfreOyxx/DpT3/avOb3+7Fu3To8/PDDe/18u93Gjh07kEwm91sBDQuLQwmO46BQKGDFihXz6i/vL7zacQzYsWxhsSfs6zje7yQ9NTWFVquF0dFR1+ujo6N49tln5x1fq9VQq9XM/9u3b8eJJ564v5tlYXHIYdu2bV13MtofWOw4BuxYtrB4JdjbOF7yjKAbb7wRN9xww1I3w8Ji2WFve4sfbCw0ls877zw4joN2u41Wq4VarYZyuYx6vY5qtWpeb7VaaLfbaDQaqNfrcBzHvMbPO47j+gGw4G8Li+WAvY3j/a6VDQ0NIRAIzCsyv2vXrq5bqH36059GLpczP9u2bQMA/OhHP9rfTbOwOKRwICXkxY5jYOGxHIvFkE6nMTIyguHhYaTTaSSTScTjcSSTSSSTSSQSCcRiMUSjUYTDYYRCIfj9foRCIQQCAfj9fvj9/q73zNf0N38sLHode+un+52k+/r6cNppp+Hee+81r7Xbbdx7770444wz5h0fDoeRSqVcP8CcdfHwww/j3//93xfcc9XCwuLAYLHjGFh4LI+NjeGoo47C+Pg4VqxYgSOOOAKjo6MYHR3FyMgIUqkUhoaGkEwmEYvFEA6HEY1GDWEHg0FD2oFAYEEC9nrQ1qO2OBRwQOTuq6++Gpdccgle//rX4/TTT8fNN9+MUqmED3/4w/t8Dm5pWKvV8PnPfx5XXXUVJicnXfucWlhYHDjsj3EMAOl0GqFQCD6fzxBtKBRCrVZDPp9HNBpFpVJBMBhEvV5HJBLBzMwMIpEIqtUqHMdBs9kEADQaDfj9frTbbfj9fiN7K2mTnH0+nyVqi2WPA0LSH/jAB7B7925cd911mJiYwGtf+1rcdddd85JQ9oT+/n4AcwkswFzCyvj4OP793/8d09PTeOc733kgmm5hYfH/sT/GMTA3lvv6+hAIBNBqtRCLxZDL5dBoNBAIBNBut1EsFlGr1dBoNFAul9Fut9FsNo3MXavVDFH7fD40m01D0O1221yLhG2J2uJQQc+VBc3n80in08jlckgmk6jX6ygUCigWi4jFYiiXy9i1axfe8IY3LHVTLSyWFLlczkjKvQiO5b/9279Ff3+/IdB6vY5Go4FWq4VCoYB6vW6SyUqlEgqFArLZLKrVKiqVCorFIqrVKqrVKprNpiFsJpW12234fD7zN7BwElmPTXcWFnsdx0ue3b0n+Hw+hMNhhMNh+P1+RCIR1Ot1DA0NYceOHSiVSigWi3jd615nB5+FRY8iHo8jkUig1WqZ2DIwtxY7k8mg0Wig0WgYgp6enkY8HkepVEI+n0c4HEYul0MwGESxWDSk7Pf7XdnfBN9XGdx61hbLFT1N0oqBgQEAc5miRLVaxezsLLZs2YJyuYxTTz3VJX1ZWFgsPdLpNGKxmIlFA3OFUShZ0zuuVqsol8tIJpPYuXMn4vE4gsEg+vr6zGccxzHyN8EYNQmYxwHdPWdL1BbLCcuGpLshEolgfHwcwFwhhenpadRqNezevRuvfe1r0Wq1lriFFhYWXILl9/sN4YZCITM+uXa60Wggn8+jr68PPp8PlUoFrVYLPp/PHOvz+cyGL5S4uZ6ax3DdtReWmC2WI5Y1SSsoizOR5IknnsCOHTtw3nnnWbK2sFhCRKNRswaaMrUSb6vVQiQSQblcBtDxmGu1GoLBIAqFAiYnJ5FKpTA5OYlqtWqSx/jTaDRMYpmX2NXLXoioLYFb9CoOGZImfD4fxsfHMTY2huHhYdx///247rrrcP/999uBaGGxBIjH48aT1pg0k7/4dygUQl9fHyKRCPr6+tBoNBAMBhGPx11rpHO5HAKBgJHI6/W6qV7mOA4ajQZ8Pp/JJleC7kbU3iVcfM3CohdwyJE04fP5kE6ncdJJJ+ErX/kKXnrpJWSzWTQaDWzcuBGNRmOpm2hhcVggkUggEom41ko7jmOWXzGm3G630dfXh3A4jEgkgmKxaJJH+XoymUQqlcLMzAzK5TKy2axZY+1drtVqtVxZ4Lpcy5sF7v3bxq0tegWHLEkDczHrSCSCTCaDoaEhbNu2Dc1m05YLtLA4iAiFQmaFBkkZ6BQs4nhstVombl2pVMzng8EgotEoEokEJicnkclkkEqlMDExgXQ6jZmZGdTrdZTLZRQKBRPfrlarqNVqrqVaJF6NW2tNcKB7JrglbIulwiFN0oTP58Pg4CAcx8HExAQeeeQRTE1N4YILLnBliVpYWOx/0MtlwhczsLVqGAAjaTcaDRcp8vOhUAjtdhvlchnhcBixWAzZbBb9/f2YmJgwBVNKpZIhea1cqDFrxsUZuyZhe2Xx/SmD2+VgFq8EhwVJE4ODg2Yp1/T0NB544AG8/PLLmJ6expVXXmkJ28LiAIKkp5tl6KYYKkcrefn9foTDYZRKJYTDYRSLRSSTSZTLZWQyGZTLZYRCIeRyOUQiEcRiMVSrVRQKBVSrVTQaDZNNrjFwLv/i3/S2u+26pe1/tdBzWKK22BsOOZJWOc0LnRQGBwcRiURMYZRvfOMbSKVSePe7322yTC0sLPYfvPW1OR7pTfN9rqXWJVbtdhvBYNBI34VCAYlEAolEArlcDsBcglpfXx9yuRwqlQoSiQRmZ2dNtTIu1Wo2m2i326jVaub6TDZTb9d7/QMlf1uittgTDjmS9vv9KBaLiEQiAGAktm7HJZNJNBoNpFIppNNpRCIRfP/730e9Xsf73/9+lEqlg9l0C4tDEiQ/LzF7t5YE3IVJgDkyDAaDaDabCAQCJqs7HA6jXC4jHo8jGo0iFAqhXq8jGo1icHDQeNKJRML8zfKjLJ4SDAZNjXCqaFzKRWKm9K7yt8rVbOP+eEaWqC26oWdJ+tVIz/F4HABQKBSMVLZ7926kUikkEgnXsf39/ajX68jn8wgEAhgdHUUgEMADDzyAXC6HUqmEP/iDP0ChUHhV92NhcbiCHqwqXErYXgmZJB4MBl3xar5OBINBNBoNk/lN2bvdbiObzRpPu1gsIhwOm2Syer2OSqXiKkfK5Voke9YW90rw3mVcdvmWxYFGz5L09u3bAQDDw8OL/iyTQbjLDnfVKRQKcBwHyWTSdWw4HMbq1atRKBQQj8fN8qyRkRHk83mceeaZuOeee+yyLQuLVwCVjkmy6oUqYfM9rnP2fpbvcblWvV43e06Hw2HzXjAYxMDAAIrFosn6rlaryGazaLVaKJVK5v9YLGayw+v1OoLBoIll83wA5i3j6nafrwbWm7bohp4l6UcffRS/+c1vMDY2hlWrViGTyRgPGcA869WLZrOJVCqFRqOBdruNdDptMj5Jtox9AXNZoOl0GsBc9icLJLRaLdx0003Ytm0bGo0GPvShD5kYmIWFxd6hY1UzuhfKH+kmjQNzY5SZ3sDcOOUe1KwLHgwGUavVjMzNJLJUKoVKpYJMJmN21SsWiwiFQiZmHY1GUSqVUC6XjZFAeVxLj1KS17Z2wysl3P0po1ssf/QsSU9NTWF6ehrbtm3Djh07kEgkkE6nMTY2hlAoZNZA9/X1mSIJBDt3IBBAtVo15BuPx83yj0AgMO+aPAcTVAKBgIldDwwMoFar4Xvf+x6KxSLq9Tr++I//GLOzswfhaVhYLG94PWd6pd7dqryfCQaDLqlcPW8qZTyW47qvrw+1Wg2BQADhcBiVSgV9fX2mPGk8HjckXalUzNrqSqViCqcUi0Ujt6shEQgEXLUW9lbFzBvH3pfnpAaKJeqlQbf+uFTfRc+SNKuDhUIhNJtN9PX1IRaLYdeuXRgYGMDAwAACgYDZKScUCpm/Wdu3VquZeBTXUC4G/JzGn0ZHR5HNZrF792783d/9HUqlEq655hpL1hYWe0C73TZlPXWdspK2l5i6JZYpKTOO7DgOQqGQIW3OB6w2xph1s9lEqVQyy7S4nCudTmN2dhb1eh2JRALZbNYQNQCTGc62M5ENwLz2LzSR703581Y78/5tyfrwRc+S9M6dOxGNRtFoNDA7O2tKBY6OjiKVSiGZTKLVaiGZTCIajSKdTiMej2NkZMTU7wWA2dlZZLNZRKNRjI2NmcpH+wpvYguNhUAggGOOOQa1Wg1f+tKX0G63cdVVV2Fqamq/PwsLi+WMer3uqvalBUw0hqyZ3d4NMVhGlOucNbbNz4VCIVP/23EcQ64kaf4diUSMd51Op9Fut81Kj2KxiFQqhampKczOzpoNPjShjMaAVxXQtdYAusauvUu4DkSmuMWhhZ4l6V27diEWi5ndbsLhMAKBAHK5HBKJhEkaicViGBwcRCwWw5o1a9ButxGPx40nPTk5ienpafT19WH79u0YGBjA8PCw8cQXC67THBoaQqPRQC6Xw8jICFqtFv7rf/2vmJ2dRSqVwqZNm7B79+4D8GQsLJYXvOuglcxU3vVWAgPml+zULG8tjsLzsTIZM7WpwkWjUdRqNYRCIcRiMZRKJSQSCVNClA5BKpVCX18f/H4/IpEIfD4f+vr6UC6XUalUTIya+SpcwsW2styo934JJWevFL5YafxQhn0OHfQsSTPezA6vSR47duwwHi23uEskEsjn85icnMTIyAj6+/vNOshqtYqZmRlMTk4iGo2iv78f4+PjWLFiBcbGxhZdRSgcDiOVSiGXy2FgYAChUAiTk5PmvABekQFgYXEogmOYPxpf1uxpAC5PGoDLo+6WAc7Pc7MOlb+VREnWtVoNfX19ZpetarVqZPFSqYRSqeSaD5rNpslPoWPAZVwAXMu1VALn+mpVEPieGh3diqR0I/fDydPeH1Xd9hd64Xn3LElThmJSGC1XFhtgoYFyuYy+vj6zNnJ2dhYzMzMYHx/H0NAQHMcxa6GLxSJyuRympqawfft2DA4O4thjj8XIyAgymQxisdg+tY3FFGKxGMrlMmKxGFKplGlLPp/H9ddfj0ajgc9+9rOYnJw8wE/LwqJ3waxonfC0/CbHtzf27I1ZU2ImyetvyuHexCsAJvmMkjozwRuNBiKRiJlTdLctntfv9yMajWJ6etrMN/SoScZcCaIetUrz3g0+1CjhPelrKoF7SeJQ9DAXIuVuycAHC730jHuWpJm1zQFEy5fEzYHG2BMw92ALhYJJDGHMur+/3wwQFijJ5XLYvXs3duzYgdWrV2NsbMzErPv7+9HX17dg5/H7/WadpQ7AsbExk8w2MjKCcrmMG2+8EbVazVjpt9xyi5XBLQ4reEmaY5F7PTNBFOgoUHyPpOT3+w3p0Xv2JljxOJI0qw2qd85dtjiX0PCv1+uu5NJWq2W8ZyaSVSoVlEols4+13+83hVG4rtpxHONt8775Q+fCSz4LxbAXkr8Xmpd6iVj2hsV6ywfLONlTVvdSGUg9S9LVahXBYBA+n8/EkQCYwiTNZtNslsFsToJ1efkeSXt8fBx9fX2YnZ1FLpfDzMwMstksSqUSJiYmMDY2hv7+fsRiMQwNDWFoaMhUKNMvSjeu5zKvRCKBYDDoKu7vOA6OOuoohEIhQ+pXXXUVZmdncdttt1mytjgswMmNyZz0HrmUSWVrEit/ewmNRKsxbG8iqDfZU6/BzzNDm0Y/vWjOI7oJCABD0qlUyhAy6ykUi0UjgddqNVP7n+cnQXOHL++WmQqVw7st4doTSSyW+HqZ1PdknByodu+LR78URN2zJF2pVIy3zHXRTBSjB82kjmazaQoXRKNRU+CACSGFQsFkhw8PDyMQCJgMbQCmCD9314nFYjjyyCPRaDQwMjKCSCRiJDAiEAggkUgYy7nRaJgN5zOZDKLRKJLJJHK5nBmgAHDcccchn8/j8ssvRz6fR71ex3e/+11L2BaHLBjzpXdMb5IKlBJmt6pk3v95HMfUQhnS3ti3Eq+Sn57P7/cb2ZrHa8GTcrmMZrNpsrw53kulkll3HQ6HUavVTFY75XB663weVBNUjVNZvFtC2Z6IeLHk0avS+d6MjQMhg/dSHNyLniVpLVASiUTMQOYSC65/ZP1ePTaRSKBSqZjBRYKORCKIx+MYHh5Go9HA5OQkKpWKGVwcIPzc7t27TfWigYEBU/GMxfkZCyeJU2JjEYVwOGyWbqjFnkgkTJx8dnbWZK3/27/9G6anp5fsmVtYHAhUKhUzvrQ4CclJCwcpgTN+7E2gchzHFBrRcqEqa3fzfnisqmBK0lrJjOuwAZiEs2azaWp+MwZNaTsej5vtNOPxOMrlsiF2JpzpEi4StXrabAcrnHmXd+0vUl1oTfZSycl7O3Zv6sGraXe39uztut0MpgP57HqWpFOpFDKZjEnooNfcbrcRDodRKBTM4AbgilE3Gg0jc+tyCJIka/WmUinUajW0Wi1T35fLNaamppDL5Uxt4IGBAQwNDRmyTqfTZqs7jV+Hw2Ejt3OSCYfDqFarCIVCSCQShrxZfvD444/H7Oys2bnLwuJQQjabNfklHKOhUMiEpLjcSb1jLrlkyIukSUOY8WfujOUlc2DhCVg9cCVuJXAeR1WOS7W49lqJlolkg4ODyGazJtzFEqNK0CR3etjMPKcMzmO83rU3ucyLhdZfdztuIXI50J71vhL0QsrBQu1bCkXAey8Hsg09S9KUnUmuLOlZrVZRq9VMib9QKGSK5vf19QGY2/2KsjcHGTOvKTGRKDkZhEIhzMzMIJ/Po1KpYHp6GrlcDuVyGX6/H7FYDMlkEitXrsTKlStNPC2ZTJpsb8A9uGl1s+SgxqhoeUejUeNlb9y4EcViEbfffjt27ty5lI/fwmK/oVwuI5fLzVu7zNKdVMm0/CeTuFiPm3FkkjRfJ9T7obS90CSvr9F71/gzjWV695FIxHjS0WjUkDQJlMlj5XLZOBBseyQSMR41w3LeWDW9cYbFOGeRvPW+VNrX/xcqs7ovxHGwCG4hD35fPrO/5ei9hQ16Sf7uWZLmukdgbtD4/X5DbMzy5M43gUDAkKCWDeQyCVqrmgTCL1/3qo3H46hWq8jlcqhWqyZrs1qtYnp6GqFQCNPT05iZmcHMzAyGh4fRarUQjUZd3nSxWDQ1ftvttpH62BZmjjLRLJPJIBQKYXx8HI1GA5lMBhMTE2i1WvjhD39oCdtiWSOXyxkZlyTHsUHy1QIkVJloZPPHq6jpmFbo7llK1hrnVRLzJok5juNahqWlQLkVJrPCmeHNFSf8oYzPNdmscqYZ51TcuN0mM8abzaY5r9/vdyWbeYmO90fPm+Cx3u1BvefQ97zP5UBiX+Lr2paDTZx7uv+F2nKgvOmeJml6xho7oldLKzefz7usXXrIPF6TQLhdXTQaNV5sIpFAIBBAsVg0cevx8XG0Wi1TIGV6ehr5fB7FYtFkbdMK1usx45TtoJUdiURMHI0xasrhHFjpdBqZTMb8vXPnTtRqNQwPDyOfz+P73/8+Xn755SX5LiwsXg1mZ2fNREuDmaSjEjMJjERNAmfoiiQWDAZdYSOVgtWTVINdJ3pdBqXZ4roWm+B650AgYEiTyV707HkeJehGo2GMilAoZHbg0+00Sc6qKACdXfp4XmD+NpneteIay9bjFUrS3qQ0/q3XXcqkMq8C0gvYk6FwII2IniVpxms5KEiMjuMgHo8bkg4Gg6ZKkOPMVSbTGFepVDKDuVQqGWud1ngikUA0GjVWfl9fH+LxOMbGxpBMJlEulzE2NoaXXnoJlUoFrVYLhUIB27dvN5a1LhVjMYR2e26/21QqZaoT0ZDgREAvnEvM6GVQKWi328hkMsjn80gmk5ienka73cZdd91l9tu2sOh1lEolQyaVSsWVrEXFiwYsSSiZTJrYNQ12ytDhcNis9CDRUxJXz5wKmZesvQSkSWPqUZJwHcdxkagmtPF9revAJZ8+n8+ogIBbtaMBT2OdBj7v0dsO71pzzn9K4pp8xh+eSxPR1GjZ07abB5qo9yRlvxJpfF+xmPN1M3T098FIHutZki6VSmg0GojH466MSJK2JocVCgUjL+VyOfj9frNvLDt5Npt1VQXi6zMzM6b4fiAQQDQaxcDAgNnIo7+/H+l0GmvWrEG5XEapVMLU1JRJKNu1axcajQbGxsYQj8fnkT7rAzNxpNlsuiqbkdCj0aiRxNLptPEcotEoBgcHMTIyYmLbqVQKmzdvxk9/+lO7oYdFz4MkTXKj2qSkQcKp1+uuJZRcwUGS5v/NZtPEiUnQJEqNY6sRraV6+TcJultBEcZ9VQ6n0cA5iLFnki6XX4XDYeNN87z8nHrture2Jrp61QFv+zWDnWSqNcy7Levifev5vZ70UnvQXuxrgtYrJctXS7IH41n1LEkTTL6ivESPmJ06Ho8b4mUWJQdQuVw2lmmr1TIFUsLhsNmEg3Ehxo2597TP58PAwAAymYypBc6CJI7jmPKAU1NTKBQKhnwHBweRyWQQDAaRSqWMXEeZWwcJY1pcVw10NvDgshXeG3f9KhQKOP3007Fy5UqsWLEC+XweP/nJT6xnbdGzcBzHKEisDkh1yevF0vhmQRASYDweNyqVGsFK0pFIBIFAwCyJVK9aPW1mifP63SRfkqd6wRpy0/XWQEeiJqnzHLrWWhPjgE7pUyVUrUrm8/lQrVZdJUa1jV6C8Urf/OGxC5G/Es1SEPRiZOR9ad+ejn81XvRSoWdJmsVMWNWHVqvGWljghNY3E0m4jzQAI3s1m01XhjcHO2PLHOSUpLPZrBmY27dvRzqdNsckk0lT9q+/v9+QPDf4cBwHQ0NDLktXqxnV63WzTpqZ3ZyMSObeakokaQ7meDyO/v5+zM7O4sknn7QkbdGzoJzNTGZ6nezjJCV6kSrjqlFL0o1EIohGo4jH42ZnK4aamFHN2go0yrmzlbc6oZKbdwLX5DO2BegYFtzAR40LwF0EhXk1rOfAuLwuHSVZ6t4Eeq49rZ3WxDFNSiO6/U3nRMm+29+9glfj4S+GlA+23L+v6FmS5nIFoLOekUkiwBzR5XI5swWdFkdgoge9Z90MntJXqVQyg4jLqNTC5mdZwGBgYMDEyBjb1nPyvLqNHY8B5luynDioEpD0aekzW5xSH0sK8rxMnmu1Wjj77LNx8sknw+fz4aGHHsK2bduW5kuzsOgCJSCOT+/YJtEBHTLhmAdgxifl5Xg8jmKxiHK57KpMyKRQ5q1EIhHzOsc7C6oo2aq0zXYtdC9K6io167ptTWhTL12lZ6Cz1IxESzmcG45wXuNqEc3NUdLVzUWAThKePl/vMi2V2g9WVvcrxf5uV68ko+0LepakAZjKYiQnFj+gJchsbXq81WrVdGzK3PwsS4ES1WrVJJwxnsVEDiZ9MPGjXq/jxRdfNB1bJwOSJS16Ena73UY+nzeVx1TKolxOj4GevuM4pmIajQ96AlQCtIIRt8x87Wtfi1KpBADo7+/Hjh078Oijj2LHjh0H/0uzsPCA41XXFdNwJjnzPY5hyrtcsshxTgLUIiI0ljnGmfzJhMy+vj6zB70atzqeaUxTFl8o41mTvLxZ4Wq0ayxaY8okVo55ki8NCO8abQCuioqaVKq/2TYNH5Codd7hsfrD17pJy/viTXZTIHoZy4mggR4maVrcXC/Iv+nd0jLmXtIsKMACJxoj4iBkcQC/32+Ir1armdKf9Ga5WYZavHp9vq5l/ziQ2u02BgcHUSqVjGzF5SScXFiFiDI7LXCSP71okj7XgWv2KuWtdDptJp9CoYA1a9ZgxYoVGBgYwMTEBJ544gm7ztpiSaHxXeZleOOhXJJEY1e9ahK7jotms2lCUzTK/X6/SdriuKxUKiasxaxwjn0AxhAHOhv1cLxyPPM4tkcT4EhkDFORjFlpUNdp6zk579TrdRNbV+9Yk8D0OTJcwOO9S7G6PXtNjFN4Je6Fst+7EfWeiK6XvfJuxshC6JX29yxJcw00vUbHcQw56a4y7Mhagcjn87nWGrIDk4QpofE4/k+LmH8Xi0XjzfLcjDHRc9U4GwdgsVg0hgQlN2amaodvNpvI5/NmS00aGBqP5n3wvsPhsKk9zjKmat1zLefRRx+N0dFRk+Ver9fx1FNPWcK2OOhQj5WJl95drmiUU/nyeooag9UdqChfc2MLGgH0pGkMc7kj62yrnMx4MucBrvTwxmoJ/q2xaq0WRmPbcRwzd6knrfKyXkeNl24yOg1zbTvPp94/70HbyHbzOeqP3tNCiWSvxPvsZbJW9Hr7epakAZh1zgBcchQHMT1jbqZBAqWVzE7IymH0bDXLtFqtIp1Ou3bYKhaLKBaLRlqKxWKuNY60jh3HQSqVMtvXkcxnZ2dNPJkJaslk0pRDjEQihtBZEpAVliYmJkx2ajweN4VQNMGGygAT0ngtXm9qasoYJCMjI1i9ejVCoRBGRkawc+dO/OpXv7JSuMVBA/srczpoKHN8aS1tjjNC469eZYvkyP5PlSwYDKJWq5lCIfTQudkOCwxRUSPZM3mTBoWSmq5L1s1/lOxI0jScuSxU2865g9C5inMCDXMlaK37zfc4BxJ6Du9SMm9b+brX+NhfhOX1xLu93u39Aw1ev9eJWdGzJM3YMGUrxop0yQWXJ3QbEJp96d0Gj8s/+DmSPOUzrsvm8VodjPKYJruwQAMTvkqlkrlGPB43y7HS6bTZUYuWcCKRQLPZRDabRS6XQ6PRQDKZRDqdRiwWc+3gxYlFs1w5Ofl8PkSjUUSjUdN+x3GQy+XMRiBjY2MYHBzErl27LElbHDRoMpZ6zvzRpCYez+QpoLMrFf8m0WhIiglWAFz5KDyWnjfzTWj4KtmrJ62KFq/F8a0JobwXfo6k6p2DtN36HKiA8RjK31qEhefgShbK/RznvDYVRSVuDal5l17xb297tJ17ksmJbjHpV+tF76skfaDQSyTesyRNaWdgYMAQrcaIOJDj8bhJsqKVq4kWrCwGwJWBTamb5f4oiTHRi9egfE1SpBfOY1nHm3I2ALMEjMVYWCQlk8kgnU5jenrarPukPMaqaJVKBbOzsybxjPW9k8kkhoaGEI/HjbFCg4XeNgd6KpVCu93ZQrNQKLiI+6STTsLw8DDq9Tqef/55TExMLME3bHG4wSu98reOafZpEg37tG7CocoSiUxjsyQ4euxMRuN4p2eqVck0zkuy02VVHKc0xvnD+USJlp49701j0Ty/JoYp6I2zXZFIxIx1hvTYNjopfE7q0fM1YH45UK+E7U2UU4LuRpR787i9YYK9HbuY1w9HLIqkr7/+etxwww2u144//ng8++yzAOak42uuuQbf/va3UavVsH79enz5y1/G6OjoohvGAcSiI5Sn6UU7TmetM4+NRqPw+/1GOmZHZ2IXY1QAXNWJKJNptiUzvjmY2JF5XiaFMOucHrkuM6nVasjn86ajplIpUys8mUxiYGAAw8PD6Ovrw+DgIFKpFGZmZlAsFuE4nTrHbF8ymTRJMMxu5X1oBSRmsubzeeNdFwoFUwXp6KOPxqpVq8z2epOTk3jxxRdtvPowwsEcy0qm/J/oNoF7JWESMscuAEPmXqOdP61WyyVhs9gQ/+fuc6xq1m7PlfElUZO4vYlg9LI5D/F+lKQ1fq4qgZcAu3mknG80l4Vrpzk/sS6Eqgd6bd14RJ+ZXl+fsXrWmsjnxb56l97ksz39fbCwFNfcX1i0J33SSSfhnnvu6Zwg2DnFVVddhR/+8Ie44447kE6n8fGPfxy///u/j4ceemjRDeOAYMZ2LBYzHZLJZJSgms0mksmkydrksgsAZrCWSiUTK3Icx1XsQOM+mtxB6UmL4nvlI5I113Xzc2wb5XASNmPnfX19GBoaQi6Xw/DwMEZGRhCNRrFixQqXJ06pHoBZtqWlCFU1YDyMMp3u10tZnBnpmmB25JFHYmhoCC+//DK2b9+O3bt3L/r7slh+OFhjmXIzxwn7rapjTAbV+t30QjX2qv1dJVGvIc1rlctlc07GqjUmrl40pWQ+C5XVtV00+L0xXfWovRnVSs7eBDmV+TlW9f6olHEu0aqKunxT9zigIcF97DkXAPOTxLzytMZtlcw1F2dfveVXS84LxbO7Sez7goWO25/x+P2NRZN0MBjE2NjYvNdzuRy+9rWv4Zvf/CZ+93d/FwBw66234j/9p/+En/70p3jDG96wqOsw61LjxRrP8hISLWN2LCarqFTORBG1fPmedtxoNGpiYkzM0kQvbSOtdSamcaDpumcOfp6HFvDU1JTZWatQKJgypFwCxvrGHJDe/a257pvEDcxVJuvr60M2mzVGCa1z1hKOxWLGQ9fJicYCq6ZNTExg165di+0iFssEB2ssc8xQ8aIRzJUT7N/s617pmT/ss1SzdNLnayRTepRAxyukR9zX14disWjGNr1yluQFOrFvlak512hmOsmYuS5sM+Vuvu8lK7ZPiZrt1IpoWmCJ7STBcwmpevEc55z/eDyXldET5xzEa2vCmZKV939tv75GdIslL0TmC5H1QmS+pzj3npLT9oV8e5WggVdA0ps3b8aKFSsQiURwxhln4MYbb8SqVavw2GOPodFoYN26debYE044AatWrcLDDz+86IGtUhM7FR+ker/0lBkLIgnzPSV0dkzHccyyKcdxzHuUuzT2o0SnnVo9Wr/fb+K/jUbDLPVg8hs3CaGMxgmF3jcTxrLZLIaGhnDEEUcYJYBx8HK5bDJUHccxpUiTyaQhdUpylAG5Pza38+TAVkuexzJsEIlEcMwxxyAUCmH79u144YUXsG3bNkxOTi62q1j0OA7WWGa+CBOjgA4JMr9DpVqSgEq5/NHliZrYBbgreqnnqp46ly/xuoxVU7nTvBWCpMzrcY6hM0By1bYD8z1PoEPsutxKVTy+p3MMP8t5SccwQ3n6DBiOYzhPlT0u4WIeDtuuXjifC+9XiXxP8W2vR04s1kvdGznvzRPX6/Uy+e4rFkXSa9euxW233Ybjjz8eO3fuxA033ICzzjoLv/zlLzExMYG+vj6zJzIxOjq6x8QkLuon8vk8gI6XykIeTObQ2BAHHImGsVh6mzw/rWda7RyM7IyxWMxYpEDHegyHw2bgkOg5sRD04knM3Bggk8nAcRzXJveMXTMOzslDl3tUq1VTuIRtZoa3Fl/RGsi6NIz3MDg4aDLgo9EoSqWSIXZmqzMzlAl6jGNTIovH4xgaGkKtVrMkfYjhYI5lTvbqndJIpIyrMVX9Wz08EohW7iKoYmm8Vydzji8ep4lkHH/MZ/EufdJEUrZHV5XwWt7EM2/1MpIyE9A4n2jMnuTsTYTT6mF8XprhrWofHQAms+ryUCp0Wt9BvwN+Vs+n2fn6o152N+9aib3b733BYgj5UMWiSPod73iH+fuUU07B2rVrsXr1atx+++1GJlosbrzxxnkJLIB7azeSKS1Xxla5Kw4HAj3fQqFgpGZanfS4gTlSYnIZPWZNKKO1zIGhkjE/rzIdM6x9Ph9SqZQra5sDkYOARoPeF68LwGR6RyIRDAwMmHNoZ+W+1nxGasDwXN5CKuVy2ezcRa+8Xq+jWCwaAyeZTCKTyWBychKVSsVklh933HFIp9NoNBrYtm2bTTA7BHAwx7J6pVTIVJUieXaLrXprVtOzJHnQQOW51fsj9HoqgauXqr+VFDlOue6ahjENd/7NMa3jtFsCnMbN1figIsfno2SmhVZ07uH98F41aU7nSO5TwP0CmJOicXfOkyR+3VrXS8peiVy/V2IhIn4lBO0leO/7esyhiFe1BCuTyeA1r3kNtmzZgnPPPRf1eh3ZbNZlge/atatr3Iv49Kc/jauvvtr8n8/nceSRR5r/mdlMqZjeIaVkSt0cSOykQCeGQ2i8WJdq0KqltKxePKGyFsmftb6LxaJZ5hEKhczaZ3Zw3Zye7fIWcKDczEHMQciSn+yQrKZEy50eilYu8sbKGGPnfcXjcQBzsUIuz1JPHgCy2ayR7gcGBgDMJa5t3rzZeFvZbHZxHcaiZ3EgxzINYPU2lXg1Bk2iADqxZCVjNdj5vnp39AJVXSIh832SI4mWISSdY2hUU7FjUioJleNWyZP3qHFroBMLJ9QQUFmfxxI0ODSXhedmWzinEGyPll+lWkAJnBXa9LPqRdMg4eZEGvNWz1rDFAqvoeGFV7beF3JdiKj3JmsfCuT9qki6WCzi+eefx8UXX4zTTjsNoVAI9957L9773vcCAJ577jm89NJLOOOMMxY8h65L9oLxZG98ih6ixoLa7bbZZ5qdhLIuBwxfL5VKZmkDABeBKdk5jmOSXThAaDRQugZgsrp5HCuORaNRJBIJQ4rs3LRwaZXSIueA4MDM5XLIZDJmX+poNDovVs54uGazq+zlHeQ8juu9mdhGC5qDnNWaOEmxpvKJJ56I0dFRbNmyBbt27cKuXbusZ30I4ECOZY4ZlblpWHab5EmoStLah71QSZnnIqlwLDCBSguNeOPgrH1AYuf7vCddFw3AVfCEhq5K3PR4NTatUjbQ8fJJzvo8+Az4eS9Z6/3SuKABAXSyzb0SNZ+Zlilutzu103X5KhU3dQj0unzW+rd+F/viNXcj0j0lgi3m9eVO0MAiSfraa6/FO9/5TqxevRo7duzApk2bEAgEsGHDBqTTaXzkIx/B1VdfjYGBAaRSKVx55ZU444wzFp1oAnQyNkkaasWxxCY9aiU2jXXpmmdNztC11vwsr1MqlVzEzriNSm+Ug9SSbTabKJVKZoLx+XzmGFq1JFpa5jQAaFBwoPAawFy2NgufJBIJkwxCy5gxa64Z1yVhfE8tdyoAfJ81jnldnjsajaJcLpuBS8mM12Up1K1bt+LZZ5+F3+9HNpu1lcyWCQ7mWNb+r16WSrVAx8MkiSsRcdJWg1vJmcfxM5rhzfFA4mFymJe4eA6vZM62asU/fo5jxkueHMvetilpcK4Ih8OujUX4XJQQ6Xzwf7ZLDQJdmtlut03lNT5vva53ExOG5JiIRlWS12DmuioRPLcqAd283W7Q79T7994+92reX45YFEm//PLL2LBhA6anpzE8PIwzzzwTP/3pTzE8PAwA+B//43/A7/fjve99r6sAwitBNBo1Mi/JjOSmVYAozdAy1E6iki87ITs05SpClzXowOWkolIYAFMdjF4wMyopF9NT1UQRPT+lZE4A9Mbb7bZJ3nKcuS0tGV9ut9uGkPX+6GEnk0nXRh0kdl6HbWDMSpNmdFvQRqOBRCKBUqmEUqlkKhtxouPa03K5jGOPPRZDQ0NotVqm7ng+n8fU1NQr+t4tDg4O5limdwbMLw3K19SQ1twPGrFaWYyfo6dK6HEcY7yuevP8DK8HuGtoq6QLwLWhhbddGgcn+VNOVsL0etHeZDK9Ntuj8Xse203eVS+bz0jnNi8005v3wLwWrdio3wsNLF2brTF2tlPP55Wo1TDykqlXAt9fOBTkbp/TY3eQz+eRTqdx6aWXGq+TJEyZmB2Y2Zhc/sSkLFYeA2COBzrWt3eg03PVxAoeywxvSuxa07tQKLiKM7ANJEAApqQn0Fn7TUODJT65HIRtYllQlaZUCeCacG7OQUtXK5ml02njXScSCVM3XKHxM52waNQw2YzbgJLgS6WS2YQkm80im82ava6r1So2b96Mn//85we4p1jkcjmkUqmlbsaC4Fh+29veZnIj2KcZp2YypU7gqprRqFWZmSARc5yqR6l/A3Ct1ABgQls01knwTABVyZvKm6pXrVbLzDNM5uIqEn6W8wlXhugSSZIbxzFXXjCpi0Y6yY5zkNfY4W9vFTQ1xjkudV8CbzEZqn6Ut7kKRNVKTSzTsAWdFPWyvcaEhiH0Ne/P3rAvEvdCcetexd7Gcc/W7q7Vaq7lS7RO1YrjYCF5AzBb1jGjORaLuSw7khk7BXfZ4tItnh+AGZjsyPy8dipOEq1WyyRjaBJJo9FAPp93JbEw9lupVMw6cA5EDgx64pVKxZT/5ACnt86YMauZMcacTqcRiURca7gHBwcxODho6odT3vf7/a5dvgC4DJN4PI5kMolGo2EImxnjXHrGvazL5TIKhQLGx8dx/PHHY2pqCtPT0we131j0JjQOTKOThKzZ2ZpwRAJVORqAi4h4Lu/ErHIx39ecC80uV0+WpOyNvWoyGr1Gjn3N1KZcT+VJr6UZ4zoHcc4h6ekP71fnHPXGVfLmfRN8j0oe1UYSrcbk6UAomXq/P5I05wbOW0q6bBPnTP1eveS8EBZLql6D5VBDz5I0oQPYcRxj8TmOYzxRAGZtLwt/UB7nZ5VMadnSaqXUS4uTnZlLtQAYKZuyEM/bbrfN9eilc+BSlqYkD8x1KF6DnZ3nZIyLRFwqlVAoFMzaUxI1d8dyHMdI236/39QOLxQKmJ2ddRkzfX19SKfTWLFiBcbGxkxlMy0EQ0nfuzRMt+aj0ZNIJFCpVMwmILwfGgVHHHEEtmzZgl/96lfG47Y4PKGJYCQUJl0poXllUcZ71aPVZDP1gEmAnC/UCND6CErwmvHNccjPAJ34N9us+SdAR8ZnG1T+5ZxD71qNESV7TdrSZVBqBHDsdct61+tpW9kmEqLmAajsz+eixouGxZjNTiOD1+T9cgka26iJahqf52+v5+w1BvbkES8EDR14z3EooGdJmtnaAOZ1VnYiJlvRy2anItlqhidBImJcmq/pvtVq1eoSMHrSjI0ze1zlcx24/BwTOFQS0g6ucTNCl4BQ9qOsVKvVjDfLSWh4eBiNRgPFYtHIU1xCwZh3sVhEqVTCzMwMjjzySKxYsQLxeNzIjZxQeF0aKjQSKFc2m519sZkvUCgUXJmpwWAQRx99NPr7+7F9+3b85je/QbvdNsRucfhA1yNrRjEA4+V5ZVFN/uT/XjlXyVOVKm/cV8/P92lg67E8n+arsO1KfkrAalgrYXNsqxJHJ0OlaxoJKvHr+mtiIQ+RROclR35Wnw3bRo9ZDQ8ex3Nq0imfG+dSDRvws2rAeMm4m/ysx3i/I97vQnHrvcH72eUel+5ZkuYGE7oUiJ2KBE2LlMQZj8ddElG73TbScSKRMJ2T5MXEKY33klg1kYRxY3qsvL4mjNBT5oDVoiv0+GlcqFTOEoMaD9YELl6T7dT12bxvbhbCpVgqs7H+OQvzU7LmPXBjEt4Dl5sEg3N7YNMQ4u5bBCcnPtuBgQETw9YJMBaLYXh4GKlUCs1mE7t378aLL76IUqnkktcsDl1oH+Ykz75JolIPmRM4yUzf53vqgXHMqTep7/O8um0tj/F6oUBnzHuzmL0eoxI0f6tcr/FjGifMm+HzAObvCsYxsZDM7SUg/ZxX7vZ61DyvPiOuVuFYp9GgyWh8TWV8vT7gzrxnm/gM1TjS71nhVVIUh/M80bMkzc5C61OXUvA3MNfhSJj0PjlgtRoQAOOF8u9EIoFwOGw6JM/BjsdjSa4+n89Yl9yJS19vNjtba7Lgic/nM8X82V6vZc8scH6Gx7G4CpeBAR1Pnz+VSsWcKxaLIZVKmcIoNBRKpZLZnIPS/OTkJAqFgqn9zYHLJDwmvQBzg4cbevA9TryMbwWDc6VFfT6f2TCEOQRsG42aSCSCiYkJkz3OkILFoQuShUqf3s0wSMRAR/EC3OU4CU1Q8r7HMcbrqoSrnjiVMSVkqmNMPON8ovI55wg15Amu+GAb+T7HCucOKgica7z1Gfj/QgTOz6mH7/X2u73H+9BnpEoH261t47PinEfQiOJzZFuVxDUPQcNq3vwDfY5er3tv8D6TQw09S9IcEPR6gU4iFmVWAC7J2bvfLJdBBINB45kzuYoSOb11XQOtyw3YuWgZa0IHf6sszVixfobeZSgUMjFdXWqichgHVDweNwUY2IZusWu/fy5rVuPq4XAYyWTSyGZMBKN3zozNdntuLSWJmkYBLWZOqpywAoEAYrEYhoaGMDg4iEQigVarZQwAYE4SpzFUq9VcG35Q/UgkElizZg2q1apZW+2t+2xx6EDlXZIVFR/1aGlscxx4E6/Uk+MxlMF5Lh7P3yQmoONxa2EOzTYnIWscnMcBcJGKevxKPhrT5pJQoEPYWsRIx5Y3WUy9WE3G8v6vcr+2AeiQuh6nMr7OOdp2PgO9prZL5ykNEejz1tAX5x6dJ7vd02KgRsShjp4lac2iJmjNsaNxmQI9R1rkxWIRQMeCnZqaMkU7mLBCa5Wxb3Y4rSTGQUOrlFnaAAy5c9JpNpvIZDJmwLFQPyVkkiiTyDSbOhaLmcIhLFyiA5cDptVqmbrcNEh0eQeNBF1OpXF1LslizJ6EXSqVEI/HkUqlzN61GuuiUUASHRgYwMqVKzE2NmYqv/FegsG5et/MBmdIgXFvPn8AZn13IpHA1NQUXnjhhQPZpSyWGOo1qrfFZClds6wTPI/15paoLK2Er7Fmb4ybBoKGsEj+XvkV6MjiXJrF8yjp8Div5Mx+7l1GppnSQCccoONIPWHeu+bG0GjWeLO2h59REleCVEVDQxFqQPC+NATHOVjDDxrKU5LW0J5X+WB7+B3RYFEsxote6PhDQSbvWZJmZ+XgoffJJCx2dJWbSTpAp9ABB1SpVDKExs6iS404aFSW9vl8qFQqpj3skJFIxBgIumkHP0NSVA+X5y8Wi0gmk2i1WobgaLGTXNmJuSaa59CsUFY/AjpWZTQaNc+HngG9V2CuPrNK2Eyuc5y5DPRsNotoNIp4PG484FqtZjbk4DKvbDaLfD6P6elppFIpQ+5aQCEWi2FwcNBk0OuERLDgCvfFzmazJrzB526x/EFyYD/nWNbkTIaOdDJXA5jwxqI1sUkTnzRh1BsXZRtYildXJdAopgrG9zguSaT8X7OflYi9HrwaC5o0xjbqkkiV5ZWc+b+2S/NovJ6+ytyaaKfQ2LjmAXjLDHPuoWKpxoZCM9/5tybEqjLhfTZep0z7jxeHixcN9DBJA53KOIzbUs7V+Ac7KF+jpKOWOWMmPGe9XjfeHTtpPB438jfgTvYg0fP1QqHgIk6SJs8HwFimzKrmoOXr9OqZkAF0qp4BnSxYtZY1q5Ln0f15eX4OMGaScrLTBDeufebzVMuexg0Tv2iAcOBXq1VMTU2Z/ay5Bps1ytkWxrodxzGFYFSW9MaSfuu3fgvNZhPZbBY7d+5Es9k0WfcWyxfqTZG4NBapZK25F928K81L4blJRvycft7rcVNW52eVMJhkymuq/KtJZ+ppqlHRarVca4dVVmd7ON9w7KtHqTFs/k/DgPfI8J1XytaEOvXkaZR4E1e9UrfmAHEOVQ9Xd9nTMIHjOC6SV8me35cuoyXUaNLviH8v1ivW/nSooWdJmhaqWl4aR2IH4tIHkjgJmjI4Y8wkO69VrlY+lypR9tZKXCQ8ACa2S0+YhM8sdBJosVg0kw8/S6+R3quWIyUpawILpTl61TyG147H4wgEAiZrWwelxutVvo7FYq7lVLw/byIMJwWGE1jAJJ/Po1wuI5vNmomN3oR3bSYNACboVatV8/3wnrVKVL1eRzQaRSaTQblcxgsvvIBWq2XJehlDy2UC7rraGotVQ5oTvpIhf3McK/Eq2bDP83gSnCY2KRnzM1TAOGewXfQeNQ6uMXOeRz/Hcax/0zvnmNC8j26ErOTFMaZytd4jx7HOb3yW+jyUANXL1hiykrQqEnRUNKmNczO/Y3rYNCY4/2mYi8/BS6rd5PaFoAa+zjeHIlH3LEkzPqsxDFrazWbTlOTT7GdK2LocgqSpcVqSQ6vVQqFQQCAQMKU46RE7ztzaaXYoLp1gaUAAZvkUAJMpXSwWjXRG8mOnZ2IWANdabsC94xeVAcpulOb4LDgAdMceSv7A3JaS9Bgo6fGZcskWt/nkM2asnBMgnycnEu4nTSk6m80il8uZWPXU1BSq1SoGBgZMGVQaTpox77XW+flQKGQ2TtFrn3jiiSgWi9i6dauZSGyC2fKCeqYae9UYKklcs7xVDtYEJa+czM/TOyWZ8XUl427xUMAt61It4nX5WU1M0/ireq4af+b1aVDQGVDVS2PPakiodO99Dt2y3vU+Fd65UA0Cr5KhiWxKdnpfbLOej0spvbF1fld6H6p40JHQPqBSP8+/J+iz4Tm07YcCcfcsSdMT1Wxp9apZKYzxYXq6ugyLHiw9XyU5AMazY0fgphH8W5daMJmL565WqygUCojFYqZTMVksHo+j0Wi4kqXYuempczJgJTMOeqoBvC4JSb17YK7eK6uP8TivBco11bx3ZplT5uYGHFrikxMADRv1jGmgtNtzm4DMzs6a4in0QpLJJNLptDEqEokEisUiCoXCPCOI90WDRTNPucEHE/SOPfZYUzJ1YmLCGC4WvQ9VsgAYMgU64SqVqdXzA2AmexKi1gLgBE05Wg1hHec8J4/XOgsci94JnV41ANf1SB7M1FYPW6Vdlbg5jvh5jm8taKJ5LTwH20PjQ4ldZX+V3VU1Uymac4PXe/YaSyRazkNaz4Dt5DVVavfmELBNjHGrt855XNvsjb93+63fj5eg9bVDiah7lqS50xKlEnZSXYKhiVZc7kMPVCUWTui6L2y73XbtDtXf32/kbq6FpleuRRjK5TIqlYrpgLw+E9doVDCxjG0mMWmdX0rOPHerNbeciYklHLSUmn0+n0niYtspH2sGuDdexGSyQCBglqLpUixen9nW9NLj8biR54E55SCRSMBx5mLMAwMDZtkMNwjQbHN6/JygWXxldnYWpVLJSHTtdtsk8XHyokQOzGWBAzBruGmY2Wzw5QESGv8mYeoSQS6XVGMamJ9opYVD+Fs9S5KSrp4gSaonThLSa/DaKvFyTAGdeYNQcuf5vUTN4+hgKKlo6E4NF00G83r/nPdI5io7c9xovFmvr2qAkrbGgb1kzXZq0Rk1ONgOzl/esKLmIOjmJXzW9Lp5T+rpa6KhF7xvwit/K5a7FN6zJK0kqDIZLWDtNPV63ZVZzEHNiYCfI5lqjIixUlrMJKlisejaoo6xY+0cnAiazaZrKRIJWo0IxrU0MSyfz5vOw0HJ67A99F55LyRm7pTD+9Z4Hq1knag0ps3ddlQ6pkGj6yO5wxjQqV3OrTM52YVCIaRSKXNdr/fOuHg4HHYVU6EyQPld5UM+C4YNaGTRQGEymyaqUZ606D3QWNOJV70t9lWgE6/kmGFfUQ+WRi+9Z/ZzkhI/r540r6XyM8erxqP5ebYF6JCxxsPZPpXcvZ6eKmZ6v1pJkOPcG0sHOoRDg5fX0BUqgFsa1xgtw2b6/DQO7ZX+vfehMjzboQllCq0twbmA90UFkAY8NxbyGhEa4uD3o+Srz4TP1xsO6EbW3cIAywk9S9KAO12fpM0BpGTk8/mMt0U5ltIuMEeI/KHkTGmXX2apVDLSr3c9IGPeJCdNKKH1qjIQAGNZUnKnDEfvUTNBNblLPW0AhtiVcClvBwIBs+c2CVaXODHpjDFfPlPeGwexWt7aplarZQYUJxTGjmnohMNhjIyMYHR01Kzf5jp1YG7bTT4Pb/yRyXb07IHOICM5sy1cP+73+43HfuqppwKYKyH761//2hJ1j4IEqGvwacD29fWZ8cb+p3FPGo3NZtOllAEdSVnDJEDHeNb5Q8cO4N432pusRfLmWFSyVLmW40ITW/keCYft4HzAc7G/s4qXzh18Fhyr2nY+Pw2JabxaDRGeS8mbbVCCJDjveD1sHs82qsStxMrPcZ5QJUDj8vyu+D6/V5XutZ3aXr3+4YKeJWnGmDV+ot4xY5kqYwMwRTpouWlMSL08xrW4vpcWKgmX1wE6ljizxRn/Jdl6S/wBnQxVjbdp3Iuva5KFThQah+FyLC1Qwuvr/yqfazyIFjPboLE0eqkcbJTeQqGQiZ+zTXw22WzWTFDpdNo8q7GxMWPI0FsHYM4XjUZRLpdRLBYRDAaN5M22+/1+s/mGNzbFdsRiMdRqNZRKJdMv+vv7ceKJJ+LXv/61MSwsegcqM+t40bFMRYfjUWOiBMcCPUsawJrwpOuteW0vYfN1zVLmPMExwevo9TWpyytpK8GpdMtxw7COFlMCOglr3mWO2udVSiaBaXVAlaa9XiafDe+D5Kjk7JW6NUeH7VHVgs4JDXp1mHhtNaR0HTl/c/tdbhFMuZ+5RHRCukEJWj1mryKwp/eWE3qWpOkNs8ykDjDAvfZSZSrWsuZAoKXO9wC4drDiYKA1z3PSKyRpUe6l56mL/SnjsLNSmmUn5CCl7MsOzwGrmZA6gNmh6/U6crmcK36lnV0lea1Xzs5PUmaCGMt5Mk5Or4bt1BgU26XPmc+A8XaWO43FYujv70coFDK1u/lsWHyFBod6FDS0Wq2WSYRjrF1lwGQyab6Xer2ObDZrnnU6ncaZZ56JbDaLp59+2hg/NhN86aHL+9TLpEqlZEjjWrN8+TeVFA3LEBwn/Fu9Xx3X7Evq1RJK9rwuSV6TpYBOnNsrt5LItP0qr6s3q7KyGgn8nLZFx76qeaqcqRdM54bx3m4Z3vqs9IfPTL1wnWPo4WsejB6rMXy9F/YBJWA1xlUBIfR8fAZqgHQj327xZxuTPgDwfsEkViZzqbesspImPmlxEEqwKgmp7ERCZnKSZlxrPI1WPttHeb1bQRAiFouZSUStYK2fzf+1oIImvmjMnL81Hs7nQNKmuqCTE9uu1cri8Tjq9ToKhYKZTPnc2A5N6OAEx4FPhSKXy6FWq2H37t1GDo/H46YcK5+1SnM0IDjhqNSuMf5Wq2Uy0bVoje5sxkkzmUxifHwcxWIR09PT+NWvfmXObbE0oCSrdQtUPVJCowfLcczP8zfHLgAXYfN/TUQCOiqMxiy7qU2AeyJXBU6JXT1eb8yU90EHQGPZmiilc5tKvErm6v2qB7uQBMxnQ0+7WyY1jQqvw6NSuEr8ek2vp65GhnrpfAZqeKghAcAs49S5RR0cnffVcVDCVsLdVwLWPrCc0LMkTVLmDlFcckUPS+MS/PK4rMhxHJMo5v1CSCzB4FyNacrfTF5iDBboxFaY7c24t0qy3MKxUCiYBAn1skl0lNhZbpOdl9dl1jJ30QI60j0HEOPPAFweuiaW8FmR2HRgO85ctTQASKfTpiIYPWpK1BpmoDcSCoWMB8tzaqIcl7KFQiFkMhmk02lXdTPNKchkMsYY4r1wYtM4ISce3qdXxuZmJfF43Hg74XAYpVLJTISpVAoTExN49tln92PvtFgMisUi4vG4qyCNGo+UghmCYj9Rz4rLIIGOZ83ERZIyx5u3pCXVNP2tkrga1+x7QId0eD2OB29Iiv9rwQ4aIzp+SV5qrHrDcuqp6/+qHKon7P1bjRKvh0u5XA0dnRvUcFBPmc+C7dV4O+difne8V15Hd8xTZUKNMQAmiVQdAj5Htl/zCbQfeX/0Pa/ashzRsyStkgi9NU0o0Bre/EJVKqE8xixQjd2QyNgJSXQc3ASziDXuFQgEMDw8bDoVyY3tUaLhOTmZ0KtkW5LJpFlOROm4XC4b74AePe9Bl6Dx/CR8Tihq3XI5mD4jHWwsZMJzaMyYy8l4Xq9XAMwNcBZO4WQWCAQwOTmJaDSK/v5+DA0NYWhoyFQtYwggGAyarN9CoYBSqWTqhPO50jjgBAjAtMvn6xScGBoaQiQSMXFqvQaNCBpvWkfY4uCA4w/oyJ7qLXqTujh+OJnX63VjUOva3WAwaNbda1KV5qAAMJ9jX6dBwLGh8MagSZYaivLGiLstidL7oVfq9ZABuAic5KZzGPM5+MM5hWEjoDOmtd06/pWc1LNV+Ztzht6H5gyoMqEKhC6t03LNSvyM4bO96i2zwqC2hUqf/nDeofG+UPv5t963zon7g7j183qexZx3MfJ7z5I00Mni42BkB2BclxImB6RmSJIAWP0KgGvyZ+IDJVnALVGnUin4fD5XPe5qterydCmpMyuc7WG7mdXN11S+I+FzSRKlJg5+TggawwYwz9olEakXr5mTSoiMHdOb52CkqsBnoO2jnM/vQbPWuQyMz1a/j1AohFKphEqlgmKxiNHRUSQSCfMeB188Hjcyl8bleB5eT40d3rMaX+p9Me7u9/tRLBYxODiIU045BdVqFZs3bzbP1iv7WRwY6CTJvsUVB6rKaHiJ45STvHq96rlxnGlWuIaEOAa8UqrK2JpEpVnF7G/ax0ikXiWPJKvyMM+tY1Y9Y5W21WNX4ubz0li2Zp6r5O5tH6/D+9VEVbaTz1nj0Bz7HO96rMrz3tixyuP8znWeITjP6flJ9vxfk4RVPdXCKt3uVcnYazAoaWu7F+qzC73XDd5jF0PCe0PPkrR6fEwuabfbSCQS5hg+eMZRSYiUtSh3Uv6mPKN1t1kWVCv5ADDJTNx2US1CkotKNxwgkUgEkUjEVB+j16fWnsaLuV6ZA5VWLicxLWnKOA4lco2Z8Vmp1AV06vDqQOdzADobbVDC5/k5QXDSi0ajGBkZQbM5t5MXt9Zku3K5nPFUOWE2m00UCgVs374dO3fuxOjoKOLxOIaHh13eFRPLSLI0GBgjV0uerzmOYwwQxvu1Kpzf70d/f795Ptyic2BgALt27UK1WsX27dtdE7TFgYFO0rr+n4YlSYH9n2ETkhKNTvZr9kmdCGnsKQF4v9tIJGJUL02aJPmwr3lJUid+zaj2Gnnq0apnyv6o84Cqc/oZvqa5H944cLvddtXM9xo6ejzg3llLX9P20kjgtVVeV6LXMAWfAc9Dz12vrd8rX2d4gt+z1mjge2rQ8L7pMPGzTApVY0WfkZKzGlWKhYh0MQS9r+fsdo19ObZnSVo7Agc2azuTuNlJOEFrFiAXzVMi4URBz1TPQymZlnOlUjEZwyRjxo81TlatVg2hKdFXq1XEYjGzTIRetlrmep/sSOzwPBc7o2ab8nWChMjzMuFNvXjt2CRpVlbjc+B90nDgs6W8DMBI9uxYJGg1YjipNRoNZLNZADBrz9vtNvr7+wF01BAaGBo/5/0mk0mTl6AZ8ErcNIR4v7qEA4CR5IaHhzE7O4tarYZ4PI5gMIhjjz0WW7ZssV71AQaJVb1HkgwA019IsD6fz6wM4Heu6ouej0SvBraufmBoi7FgvYZK7Tp38DzqxfJ4TVzScUljmO/xN8evqkRKiN54tCoG7Ms63plgqvdI45bE4pXs+Tk+P/VWvbK0xrSV5PjMqWTx3Pp5NTAI9ZLZNs7DiUTCkCfna1UHebw3T8C7WoC/1bDw/njb6PW6u6Hbe/tKrPty3LKXu0kiTAZqtVpmwqbMXK/XkUgkXJ2Aa3tVVuIXzcQvermxWMxMFpoRyomgVCqZjslBTjBmHI/HjTfMuAnj6Uyc4HUZVwM6hEsC1yxGTk40PDQ2o1mvNBT4GiuEMY5L1UAHDYuR+Hw+U/BFz0fDpFwuIxAImJg4nz1L+/E7oEfCZV00enSw0KPm9+E4jtnkg99xozG3g084HDZJgyqzA53iFbqlKJ8JY3QMaXglfqAzeWl884QTTkCxWMS2bdtcaoPF/oOSonpHTOIiSWn9fRqrWgCFRqaWDyWxcPL2XldXgCjZcoLk2FBPTklTJWKShyZWUrIl1FMFOlvO8hxKHJrIpfOUF5rUxrCSrmLxeo7afm+bvKV6gc4cqY4RDQq9Np8dz60ETqi3DsD1rLy1zlk7QbcOJWFzjua8y1UsWtKYzhavz7lIZX8vUS/kUS+Ebh71ngh4b8T/StCzJM0BoJ4Vv0Aup1JLGIAZ1CQmlck52PlF0mOMx+OmI7CDacIFLTBK2fTc6AlycDMznJ/3xm2Zgew4jql2RimIkrO385DAWRYUgOmw7HhadEFJnYaFynV9fX1mPTMNCj5HjUWp3MXJlHFvLoOLRCJmqVWhUDAGgib/5PN5Y3iobNZoNIwhEI1GDfGzTXwOqoDwefI74uTH3ALeM9vN50birlarGBkZAQCzxSbbkslkzHOZmpqyNcEPAHTSJ2kCnQ0b6B2qAsLvUSVS9kddgcHvGHCvY2Z/8vk6uSWab8HVG/Sw9XMkVZ1fOO5U0qWBrx6gysJKGJpvAXQ8cK/Xqv2fz0eNGQAmBEXnRZc5ecmUrwHuPbRVJdAYtI5Xr+GgipaqGgoNT3gla/5PA6PdbpslqgRL/9LZKZVKrjZybmNBFF2ipaSt96xhCn4P2u5uHvNCr++JiFXN2F9E3bMkzS8B6GywoFYvl/BwEDEDGoAZlMDcFpKMP5OA2MFKpZKRefV9TfTgEgJuqqFeaD6fN59jrBaAaYeSfz6fN8ScTCZNO7hGWr9QldLS6bQro7VSqRjjg9485UOfz2c6PL1ozaok2ZVKpXlJIRx8+gxIhPRsaeQwE5vtYnYmCZPX4vfCgUPZulKpIJlMIpFIYGBgwBAz26oqAuV5WtCcEIG5CZrfbzKZNAmAuumHWtkAMDw8jFQqZfIGqtUqKpWKSRQsFouGAKxHvX+gJSLVowQ6yV0a1lIC5eTMCng8HujEt/kaSZIkxf5Pz5PjhqCCQ6hcq4aw9ks1AgC3JK7ExT5KcgBgDA5+Xkm6m8en90bJn5/luOdY4eu8B20j/9ZMbT4fDSmqZM+xx+fMZwp0PF6NCfPaaixwjlGpmXMg75FGDUNqVNM0TEhjjfMl+xTnf52b2u22+b4rlco8Q8IbElBHYE+ky/vu9r537t7f6FmSprWk8R1+UdwLWa0m7wBV2YYEobWd6b0RKpexE9MSpwxWLBbnLZdQSxnoWMc8H9dGBwJzO1CR4HWC4JIKyrIqpWvsiW3m0jA+j2q1atYG+3w+sxEGJymSKScpJmrRI2Wci4PYcRzE43Gk02mz/pkeLyVuEi7vORAImJKg9Lj9/s62nSR2TQaiR6/JJ1Qf8vm8ea4qY6o3wQpwNA4KhcK8BBUexx/K7CtXrkSpVML09LRRPmi0nXzyyQCAp556yhL1foBWFaNBq3KvepGalKVEpH0EgKvfcCKnoQl0xiGPZRu836d3swqOSc19YLyTY4hzjGYuk9jVUwc68XEvCZL41Jvzeu5AZ7Mg1ilg/owSE+coEiBlZcAtP7NtHEN0IrwxdHVS+ExpaPH++cz4Pu+N51LDhnkAgLvutoYj9DnoXMTwpdZSYB/Rdms4gmvyGedWY0U/6yVsnqsbYeu1ur1O7KsHvRgy71mSVk+PFhoHJRPI+EOSY6yCnZUlRQF3AgUHlWaC8ouk58cM6mKxaGInPD87Nz10ki8ldXZuJl0lEgljdZI8+D4HdDKZNGTEWGqz2UQ6nTZkyphxJpMxEi4Nh3g8jkAgYHaK4sDyegA8r64f5/+MEdIAoudOa51Gg8a6G42GiW07joNisWi2otRqYBp3VAOHkzPPR2+e7eEyLj4/TgT8vvgcNNbm882tQdfJgWvSadiRLOLxOPr7+1GpVBCNRs31HMfB7/zO7+DRRx81A2oxsSyLDtj/NOYIdIhUiU8nTDXANT6qy5q0PrwSB/uQ5pKQ2AG3h8s+oQoNv2udP9TjUuIjaHQwl4Myvs5hbC/7pqqDXmOf961KGdvCsa3kqJnymmhHo0ela94znxkdC41TA52iKjSU1PDxVib0evtqMGv8nU4Tr83jNLauiWrqyfNZ0lvWTXrIEfx+OI4ZDlDVQ/uB18vWv/cUe97T/3vDYuTwniVpdj4SWjAYNNIwk4Hy+bzLAvb5fIjH46YzcHBq3IWd0OfzuWLJjC1TNqMMyklF63ZzYPJ9DjxmpCoJ0ONkp/X5fCZWSyu51WphenraxNSZ/KUWPmM4+XweO3fuRLPZNJ5rLBYzHivQkQvVWqfhwSVslJw0E5xeLDsQjQB9ftFo1Hj9JHlmS3PCZSigWCyaH8pZTLJj28vlspG3dDkJj2+15vbYnp2dNf0AmFNCaLi0222TgKbGCZ8Jnz2TVFj5ShMJ6aFQqeDgPeecczA9PQ1gzrP2xrIs9g72MfY3zaUgoWrWNPsqVTMlSvZFerUq95KYu3lI2g6t289cB8Cd76Hkq5Op9kGOa843Soicf7xqAO+D5MfX+Fmt5cCxq+oT+x6NW22nkrIa6Jz3NE7PdnhDBpz/VIlUkvca/fSu6cGrwkCDRb873h/bTpLV5FnNFeB8r8Y+1Q8qfLxfOmh8ZhzzqtR4+0Q3qXqh30uFniVp3a0qHo+7kotosWm8VbMdAZjlP4FAwHyem1Qw4YJrg0nKjCl747PA3ADQjEP+z05Zr9dRq9UMcQMwRkU2mzWSlQ5wTkQ6SXEfa67PrlQq6O/vN1YrOyI7HOVbGjUkGF6DkxGtTa5nZlvUoqd0WCqVXBMAJXSup1bZkc93cHAQmUwGqVTK7MZVLpcxPT1tvPt8Po9sNotcLmcGHz15SnRsF++PSXXB4Nwe3xzQlPP5XXIzERo+lUoFpVLJJLkxxMB4nsYCeX9cnkWpNZfLmaV0tVoNb37zm5HL5fDEE09Yol4k1GCkV6NjgWOa40GXCAJwETMVMvWqlKDp1XHsas6HxqkJetsqBeukrkRKsmLbgc46Xb2m93glLVV4dCypR0ui1xCUtku9bs6DXtlYz8vxrO9rHJwGjBrKJGklSJW8NQ7PsUdDXbPeeV0qayRirgbh3MSwFY0A5pXw+9eQBx0LVSL4vWoOgC4zo6HTLQatDpH32e3ttQNN4j1L0tyxiZMq4wu6OxWXN+lORxr7YOJZu91GqVRCsVhENBo1Hjo9Y3YcFsPg59ghmF2oVhw7Hj06LT0IdCxuDjhOPsxEZuYxvW9K1SQp7VD0cDUD05tA471Ws9lEMpk0e7UCHUOGA4kDi4NeOzWXOXnj9jqA+dxmZ2dRKBRMpa/+/n6zcUcsFsPAwID5bprNJmZnZ5HNZlEsFlEoFFxJKrwGJ0Gucc5kMqZoCuPbVCqY3OeVRCl9AXMTJr3/YDCIXC5nrHUAJmNfE2+oylAVYH7BG9/4Rjz44IP7r7Mf4mA/ovesoRI+c6ATu2Y/5Oc0xEEFhl64yrEabmJmsIYq1FtXw5jvaY6FkhRJn+0k4agqpzIwiZZjSZOmeLx63Jp7o+3UeDJJhvMGn4vOCUAnl8erPugKGa8BQsNJnR7+JnFTMSQZqpGgyVvq1PB86iFzXGqmvIYSeD7OSXz2HMtqTKhhx36g/SaRSJiKjuxz+p1reEJzI/aE/UXIh0RMenR01Hw5tJzZERnj1QQUdhp6RPzC6WWx0xYKBZelrVmcrD5GC1YtOcrKat1z0qdHS2jsgx1TPXGtwavxcBI0OzU7udYm1gmE5A10pC7eDxMtOEmw/CkNHJIaY2f0fhn/ZZyc90GDhhNfpVIxHjCNoEKhgKmpKRSLRQwPD5vnxvNTfkokEhgdHTXe9Y4dO4zhw3vn/aTTaZN4xxKjMzMzJnbM4/msg8GgGZxeg4lqAIue8HugOqHZ49zshOdcsWIF8vm8q4ANYb3qPYP9hjKmyrnszxxzNE4JqkAkJ8I7foFOQYtucW0SE/sZ5wyOKZ6PRjS/X44f9ns1HnlflJapSCnp8hxUApUI+FtlbfWmVVL2Gu9UzWg4qmrA56Myr8rMKq3rXMclTRrX1qJKTGjlvKhSO5+BEieNmXa7bTKvNR5NDxqAS+7WBDp+T95cAk1MU/WNoSu9Tz4POmZ8nX1FVRm+5u1H+l3p/3ztQHrTPUvSmhhWKBTMwHYcx5SlpPfHgccHSymF6wspV2qslVDSpUQbi8WQyWTMchzGPBnPbbVahrDZqdhJeF0Sjm70wAQGegE0QHgOdq5gMGjuj5I5JwcmWdD4KJVKZjkaBwENFq7b1vgUAJf3z+fGwcWkMU40fF8VB0qMKl2pylCpVJDNZl0xMYYawuEwkskk+vrmtp5Mp9OIxWIoFosmD4DnVjJtNBpGSk8mk8jlcshms+a75gDk/fEZ6ETCiYYyODCnLtAY4XfHZ8jnx/Xg2qcuvPBCYyTceeedZgK0mA8dF/QctSCHVg/U74GTPEMaOjFrshLHF9AhVT0P+6f2525xcvWUNazF/s57UUOeyg9JhOBY9HqWbKN60d7PkrS919NnqZ+jkUpyVCOgm6zrvVfOEXQYlMQ4rlWG53mZC6DytMb8ee+cJ9Tp0Tmbz4Ljjk4Cv2Odk7whQjWseC/8bpjkSyNF532V+bWfep+1l7CVrA8WUfcsSefzeWN5FotF8yWlUikjc1IqpRxOC41kR9maXz49IA4OfomUkZjtyy/YuyuWWmn0DLXTctBTBgc60piWFWUn5PprTvzsOOoxK8Ex9sxOSGKlt80OzQHMuD7lPw6aZDLpyprkNZiwppmejLOrFEajQHcC46DU5DwSV6lUclnGLGJSKpWM4RMMBpFOp9Hf32/uhcYMr8H7azQaSKfTZlLSUIZKkfQW+CxI/JRFuaRFt9LkIFfpkzKfGiLBYBD9/f3w+/248MIL8fzzz+Oxxx6zRN0F/C7ZL1ksiH2cx5BENe6o/R3oEAIAcyxJin2E45uTMA15fp6fVY+N45jXUiJT1URjthpzVtAA0c+zT6o3qwqMxlK9Url6hEqofF4qyevqFjosKqmrxMx7pyHDZ0nlQkNAbBeflff7Iegxs70aSlBnSK/P4zmn0YBWVUXnU85xlOH1OC0ZyjmdIRTusMf3yQG8Fu/N2ycJJW3vOD8sPWmNM3P5QTgcxszMjOkksVjMEBjQSafnF6IxRw4aEjCzxTn4a7WameSBzpfFpUr84khsuVxuXpu1BKCC52JHozWokh29Px7Pzk9ZiB2YxAXAyDuMLzuOg927d5vsd6/Uwzby3OVy2bxGIycajRoDRBNJKEXx+6hUKmaJA2PCQGc/a50YVHpyHMckkKVSKZOsV6vVDHlSteBn6T0XCgXk83ljKNEj4fesEpuWJs3n86Z9Xq+KioIaZIlEwuU9cTAzpprJZJBIJExoIBgMYnh4GOeeey7uvvtuS9QecEJmHQBd4qTEQWLhxEty1JARxwG/f6odmojGvkeQJOnpUQomvN4xzwF0ln/plowaf6YawL6qHroafT6fzxAoPXx6mNpWVQtoGJJ02W4laPY1v9/vqkrG+YC1CdRIUrKh56oGsNdhoLrH/wmOc00k4+v8rvgcNOTRTdHwqgd0qjinqtPC74XOjxpEJHjOscoFGk5kmIvtpcrJvqREvFCIwvv/YedJk0hJMOyclCybzaZ5+O122yx1omfGiYGWoHc5Fzs1vT8uLQLmHrxuDsHzseNx0PELBToeIs+pmZ6sahaJRAwpseOyLfRWKY9zUNJA4TFAx+qnlM/1xGwTvT92ak3yYMY1iZMVyjg4gc4gUwte5UWNsWmNbXZSnVB4Dk40vDcOAnrADB0wbsxQAJMDaTjoDkYDAwNGVs9kMigUCkZd0Fi1Js/5/X7Mzs4in8+buuu8b8b4tDocJ69UKuU6RzweNzXAy+Wy+XnrW9+KqakpzM7O4sUXXzwQQ2PZgWOXBpV6wkBnUlbvS4mPx+oYUC+VypQavbrESxMItYaAzgeaUER4w2g8B/u7JmjpxK45FUqymhDJPu71RPk81EtViZ+xYBoHBPu8et9MmOJz0hi+eoQac+d8Qc+aJKwhMH02SuQ8ThNO6cXyuajHqmRNQ4qGBA06PnvOkxyTXLWhqh2/Q12+6ff7MTw8bOZmGvEad6eayb7F56T5DOzH+h116+cLvdft2H0l9Z4laa0Uw4dOj0iTRQgeUywWEYlEkMlkXANICVhjSbQC2TmZdMRJgpY6P0vPsht0W0oARrJSKSeRSLgsYKCzhR4HAicyEiFJF3Av2dCBrtYoi/BT7qEHrnKVGi7sjJTi2Unp4evabbZBnwknAgAm+1afqcbP9NmpR8GlX2wnE7bUQk6n0+bctOIZ32aOQDgcNpnpHPTBYBCFQsFcg4YSjTyWFeWmIuwvmv1eLBbNRKLeFo/NZDJmBcL4+DgSiQSSySS2b9+O2dnZhbr5YQOOHfYLypY0/DQRi6EUbwwacO9FzHmAa/xJXiQOqhwAXH1QDQWgk9hGePuqEguvq5K3eoUc1zwWgGsMeuOb3vgn71EJgZ6fjmEawWpc6IoNfp4yOuc7nk8dDX4fJHl1aNQgUKOAcw0/R6OF51KPWUNJ3uvrnKKZ2nz+fr/f7HVAp4v9QZVSzus67wAdj1qdCqpz3nvivaoxzrbSEPF6zt3IdjFkvS/oWZLWjELNmuRA4JdLMI7CTk9PXOOalEji8TiKxaIZnJwo6J0DnV1xmPylHVq9RB6r0i7QIWwORM0c1kxVvse/aYmy0piuH1RLUS1Itl+Txjghkqgo5WtGpc/nMzt90ctV+c3n85n61iwWwueuCWf0wmmVBgIB46Hz/nXgeOOLzC3gJMbJplKpmPugtOzz+UwREi7hCQQ6RWBGRkZMHJI/9JbVCMjlckY657OlvMbvQROL6FGn02nXkrZ4PG7uWUMWwWDQyOKswrZ9+/b9NDqWFzjxK/GoMapxfr7GLGJCxxEJgu+zD1LCpMep8qqSBOBWxki4HEf6vQMdb9B7fY2remVSJXFeSw0FXoN/8xwKDRFxXHAOcpzOXvR8Zhoe4D3y/rUthBojSlhaSKRer5scFJ7L20Z+P5ocpqE7Xp/3wvvQ+2PbvGE5np/GNOdkqmM00LiaRWVsXkPLpAaDQeOFM1zHsatOj6or+rzIS175uxsW8pYXinkvhJ4lae4cBbhjgt2gXnIkEjEJZOxYOniDwaAhaLVCdcBqTIxyN+VlJSWgY6lpZ9Xt4ygHs7NwsqKUzf+1whg7D+NKOlDV+ta4PdBZwqWyMkmb7WCynG77pnIkrUyNwZGA1eumEaOdlp/nPdCb4KTJQagxc803UFmM3zsrCTHbnTIzz83J3OfzmaI1NIJarbl63CygUiwWUalUDDlPTEyYiUyvqfG7RCJhJq1QKGRyEfr7+10lTnVTAFr8/N64TOZwhY4tltKlweo1NqlUaYawJojp5EkDm9+/VzFTb4fHc1KkcabjVgnQG3tWL1g9Pc0R0SxzGrDdPDWg42kriXPcqkeuEzmv7X2f3qrm3ei9qkOg0DmHz5BE7DVe1Hjn98JnzbLA+p5+v5qUp3Mdr6FKCTP5Obb5w++a98V5nZ/jPEKnimSrY5JzbaPRMAop7538wu9DHS4+c1VJ+Tw1dEDo316P22uI7Qt6lqT1gfALVZLW9W7sGMxmBjrbPIZCIfObniIAI2uQvDXerGn+zOzl8ToRcEAlk0lDmJo1zXawbUrYQMe4YAfgwKYkQ0+Rz0DjR2yfdiBgfsKdTgxqLSupqpSmygPvm51aCYyqA58926bErdYyDQR+bxz0fN68X35f+XzeEDcHDwBTJS4Wi6FUKiGXy7kkzmq1ikwmYww8Lqnj8YVCwQzWcDhsYsmaFMf+R4PGW8WO8Wkm2jFOzvg6MEfi1WoVMzMzRprr7+9HqVRCuVzGSy+99ApHxvKDeh78m0QCdKqAKcEyVMPPcUyooUgCoOHMpFC+pwYtrw10lkAB7jrgKqGzHUBndYh6vKqeeRM9FepFalaxxrO1fSrJ83oqx/N+CTVy1Jjgjy7PYrvZRq+nyFAD5wxVL0iobD+NZ45tHuslLi/h6ZzO67NddAToFPAZMKmU4NzHNvI757X5nVDxUmOQ7eJcyGWnBJ1DXVHCtvLZ8f9upNtNAlfPmb/V8dobepakWRYTgHmQnDhJHloGkHKUeixM7AFgZBjtLBw4JGiSBGVWACYD3HEcM5mrFKNxExbY4JdPUmYmOTuaZj+zyhLjJiR+xkfZeSkTBYNBQ1S8dwCuNdskCrVuARipmx2bhE3y5LFsP8+v8jkHJi1dAIbEOclxUPBctIRDoZBZ7sQYMWNplLIajQamp6fNa4xx00tWD6her7sqgYXDYbOzVaPRwNDQEFKplPl+ms0mdu3aZdSCZrOJmZkZs+6efYv9yXHmYtGUrVnIJJ/PG2+cZA8AAwMDxjDixM3rBwJz+24DcyR/yimn4Mknn9y/g6ZHoRO/Sq401KiGUGXRmB4nZDV+vRnYnBg1Bs1+7vV6+RoNAO1PSn7e+KN6WEBnoxqGgVTKVujErOoU2+T1dr0hMjWMdUJn+70eLAlKidhrrPC5qoFOY5pzID+rBKUhRrZNpWo1drRdHA96HT4zzr9ej1pDifxO1ZvmNdUx47PVtmg8X40CnbvZVraJ8xg9cq2z0S0+zWfqDanw9YWwr151z5J0u902ZUGVSLVzMcGE7zP2oFl5JElm7+lSnGBwrjpVo9FAsVh0JR7Qc6fXxzXBjInwvCRiTvwkWQ58Xq+bpa0ZkzQCWJGLkz2vrZnXXqmI19RJRjtvIBAwRUJ4Hlqvaq2r98tnrJIQJw5KSkzG8BY20fgjz6WhAgBm6Ri/U4Ygms25dc98btxEhZuIJJNJ5PN5o1DQ6+ce2TzXyMiIIedYLIZ0Oo1cLodMJgO/329KkzLWxRBDq9UyiWeU5eiNx+Nx5PN5I9uqShMOh5FKpQDMSXbMFOV2nECncAqrob3lLW/Bfffdt1/HTS+Cxgo9OsC9dzMAV78D4DJwGTpRUiZJsu/RA9ZEJV4b6BCHjkM10mlEeJMraQwqsdN4VWImkQGdrHWVv6kWEDwHCUS9Xm9oRM+tY5EESuVKn7fen3p8fL5K3Jy/KEV7jSQ+bz5DHqeyOudjtk+T13y+zg6BNOL13mnQsnIav0MNpem8zvvjd8bxq94vnR/OWXQUOG9y3PJeNHeH6iqNRvZDTdbTfus1uvYmb/P+VdHZE3qOpFVi0iIE3uxOeo2Ae52vdip2ZvUS9Rxq+dBaZ4dqNpvG82EChSZNMfatnY9eXb1eN/IwyYltUImbyW5e+Y7t5HWBzhaaJDa1MFXi4aSmXgeLwWjiF+V3fkatfE4KSsIkLc1u181E2CHpVXOgMrOa984ENhJ2qVTC7OysKwmGFi5lLMag9bn6/X709/e7JjB+N36/H7t378bk5CSOPfZYDA0Nod1um7XX9H51IPE56xI5PvNms+laf85lYap0sIQo9wEPBoMmKU8nMyoinIje8IY3IBAI4KGHHnrFY6VXwfbp5E6jk6BKxB/Km2pgcl21ki+/dxqnSpbqqeu1OYly8tVj1RNXIqSnqBPuQoSnnhonb/XeNTasEzTbQHLmml01KmgQqCGuz4JjktA4PZ+rthHorB/n+Xk8vUj9nujR8345BjlnatKfPmc+D6/crcoGj+FcyWftLVpC5YoEzNc1PEhe0Otpng7bxPoaLNakRp4mBvPelHjVYfTG3NX40f5BqBevOQB7Qs+RNCd0u8bUwmLPKBQKSKfTS92MBcEtPu++++4lbomFRe9ib+PY5/SYOd5ut/Hcc8/hxBNPxLZt24yEuByRz+dx5JFH2vvoERwq9+E4DgqFAlasWDHPg+olZLNZ9Pf346WXXuppY2JvOFT6jb2P3sK+juOe86T9fj9WrlwJYC7BZjl/CYS9j97CoXAfy4H0OPGk0+ll/7yBQ6PfAPY+egn7Mo571wy3sLCwsLA4zGFJ2sLCwsLCokfRkyQdDoexadOmZV+lyd5Hb+FQuY/lgkPledv76C0cKvexr+i5xDELCwsLCwuLOfSkJ21hYWFhYWFhSdrCwsLCwqJnYUnawsLCwsKiR2FJ2sLCwsLCokfRcyR9yy23YM2aNYhEIli7di1+9rOfLXWT9ojrr7/eVTDd5/PhhBNOMO9Xq1VcccUVGBwcRCKRwHvf+17s2rVrCVs8hwceeADvfOc7sWLFCvh8Pnzve99zve84Dq677jqMj48jGo1i3bp12Lx5s+uYmZkZXHTRRUilUshkMvjIRz5ial8fLOztPjZu3Djv+3n729/uOqYX7uNQhB3LBwd2LHfQC/exv9FTJP2d73wHV199NTZt2oRf/OIXOPXUU7F+/XpMTk4uddP2iJNOOgk7d+40Pw8++KB576qrrsK//uu/4o477sCPf/xj7NixA7//+7+/hK2dQ6lUwqmnnopbbrml6/s33XQT/vZv/xZ/93d/h0ceeQTxeBzr1683m14AwEUXXYSnn34ad999N37wgx/ggQcewKWXXnqwbgHA3u8DAN7+9re7vp9vfetbrvd74T4ONdixfPBgx3IHvXAf+x1OD+H00093rrjiCvN/q9VyVqxY4dx4441L2Ko9Y9OmTc6pp57a9b1sNuuEQiHnjjvuMK/96le/cgA4Dz/88EFq4d4BwPm///f/mv/b7bYzNjbm/M3f/I15LZvNOuFw2PnWt77lOI7jPPPMMw4A59FHHzXH3HnnnY7P53O2b99+0Nqu8N6H4zjOJZdc4rzrXe9a8DO9eB+HAuxYXhrYsdxb97E/0DOedL1ex2OPPYZ169aZ1/x+P9atW4eHH354CVu2d2zevBkrVqzA0UcfjYsuuggvvfQSAOCxxx5Do9Fw3dMJJ5yAVatW9fQ9bd26FRMTE652p9NprF271rT74YcfRiaTwetf/3pzzLp16+D3+/HII48c9DbvCffffz9GRkZw/PHH42Mf+5jZnQlYXvexXGDHcu/AjuXevI/FoGdIempqCq1WC6Ojo67XR0dHMTExsUSt2jvWrl2L2267DXfddRe+8pWvYOvWrTjrrLNQKBQwMTGBvr4+ZDIZ12d6/Z7Ytj19FxMTExgZGXG9HwwGMTAw0FP39va3vx3/+I//iHvvvRef//zn8eMf/xjveMc7zL66y+U+lhPsWO4d2LHce/exWPTcLljLDe94xzvM36eccgrWrl2L1atX4/bbb0c0Gl3CllkAwAc/+EHz98knn4xTTjkFxxxzDO6//3689a1vXcKWWfQa7FjubRyuY7lnPOmhoSEEAoF52ZK7du3C2NjYErVq8chkMnjNa16DLVu2YGxsDPV6Hdls1nVMr98T27an72JsbGxeElCz2cTMzExP39vRRx+NoaEhbNmyBcDyvY9ehh3LvQM7lnv/PvaGniHpvr4+nHbaabj33nvNa+12G/feey/OOOOMJWzZ4lAsFvH8889jfHwcp512GkKhkOuennvuObz00ks9fU9HHXUUxsbGXO3O5/N45JFHTLvPOOMMZLNZPPbYY+aYH/3oR2i321i7du1Bb/O+4uWXX8b09DTGx8cBLN/76GXYsdw7sGO59+9jr1jqzDXFt7/9bSccDju33Xab88wzzziXXnqpk8lknImJiaVu2oK45pprnPvvv9/ZunWr89BDDznr1q1zhoaGnMnJScdxHOfyyy93Vq1a5fzoRz9yfv7znztnnHGGc8YZZyxxqx2nUCg4jz/+uPP44487AJz//t//u/P44487L774ouM4jvPXf/3XTiaTcb7//e87Tz75pPOud73LOeqoo5xKpWLO8fa3v9357d/+beeRRx5xHnzwQee4445zNmzY0DP3USgUnGuvvdZ5+OGHna1btzr33HOP87rXvc457rjjnGq12lP3cajBjuWDBzuWD+2x3FMk7TiO88UvftFZtWqV09fX55x++unOT3/606Vu0h7xgQ98wBkfH3f6+vqclStXOh/4wAecLVu2mPcrlYrzJ3/yJ05/f78Ti8Wc97znPc7OnTuXsMVzuO+++xwA834uueQSx3Hmlm585jOfcUZHR51wOOy89a1vdZ577jnXOaanp50NGzY4iUTCSaVSzoc//GGnUCj0zH2Uy2XnbW97mzM8POyEQiFn9erVzkc/+tF5RNEL93Eowo7lgwM7lnvrPvY37FaVFhYWFhYWPYqeiUlbWFhYWFhYuGFJ2sLCwsLCokdhSdrCwsLCwqJHYUnawsLCwsKiR2FJ2sLCwsLCokdhSdrCwsLCwqJHYUnawsLCwsKiR2FJ2sLCwsLCokdhSdrCwsLCwqJHYUnawsLCwsKiR2FJ2sLCwsLCokdhSdrCwsLCwqJH8f8AbZsfvkU5fawAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Executing inference on training images\n",
    "num_test_images = 10\n",
    "random_index = random.randint(0, num_test_images - 1)\n",
    "random_image = next(iter(train_dataset.skip(random_index).take(1)))\n",
    "num_images_to_generate = 1\n",
    "\n",
    "z_mean, _, z = vae.encoder.predict(random_image)\n",
    "generated_image = vae.decoder.predict(z)\n",
    "generated_image = generated_image[0]\n",
    "random_image = random_image[0][...,0]\n",
    "print(generated_image.shape)\n",
    "print(random_image.shape)\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(num_images_to_generate):\n",
    "    plt.subplot(num_images_to_generate, 2, 2*i + 1)\n",
    "    plt.imshow(random_image, cmap='gray')\n",
    "    plt.title('Original')\n",
    "\n",
    "    plt.subplot(num_images_to_generate, 2, 2*i + 2)\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.title('Generated')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"Augmenting dataset with new images produced by VAE\"\"\"\n",
    "\n",
    "lista = []\n",
    "for subdir, dirs, files in os.walk(validation_dir):\n",
    "        files = sorted(files, key=extract_numbers)\n",
    "        print(\"files: \", files)\n",
    "        print(\"subdir: \", subdir)\n",
    "        \n",
    "        for i in range(1, len(files)-1,3):\n",
    "            print(\"file i: \", files[i])\n",
    "            print(\"file i+1: \", files[i+1])\n",
    "            \n",
    "            if files[i].endswith(extension) and files[i+1].endswith(extension):\n",
    "                filepath_i = os.path.join(subdir, files[i])\n",
    "                filepath_ip1 = os.path.join(subdir, files[i+1])\n",
    "            \n",
    "                img_i = Image.open(filepath_i)\n",
    "                img_ip1 = Image.open(filepath_ip1)\n",
    "            \n",
    "                data_i = np.array(img_i)\n",
    "                data_i = data_i / 255.\n",
    "\n",
    "                data_ip1 = np.array(img_ip1)\n",
    "                data_ip1 = data_ip1 / 255.\n",
    "\n",
    "                if data_i.shape == data_ip1.shape:\n",
    "                    data = np.dstack((data_i, data_ip1))\n",
    "                    data = tf.convert_to_tensor(data, dtype=(tf.float32))\n",
    "                    data = tf.expand_dims(data, axis=0)\n",
    "                    print(data.shape)\n",
    "                    z_mean, _, z = vae.encoder.predict(data)\n",
    "                    \n",
    "                    generated_image = vae.decoder.predict(z)\n",
    "                    generated_image = generated_image.astype(np.float32)\n",
    "        \n",
    "        \n",
    "                    generated_image = (generated_image*255.)\n",
    "\n",
    "                    generated_image = generated_image.squeeze()\n",
    "                    generated_image = tf.expand_dims(generated_image, axis=-1)\n",
    "                    generated_image = generated_image.numpy()\n",
    "\n",
    "                    output_filename = os.path.splitext(files[i])[0] + '_generated.png'\n",
    "                    output_path = os.path.join(subdir, output_filename)\n",
    "                    \n",
    "                    generated_image_pil = Image.fromarray(generated_image.squeeze())\n",
    "                    generated_image_pil = generated_image_pil.convert(\"L\")\n",
    "        \n",
    "                    generated_image_pil.save(output_path, format=\"PNG\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
